{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-basic3",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyEQkMNVxPS7",
        "outputId": "5c701f96-44f6-4e9f-8612-af292ab60cc9"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import LSTM\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "#@title Import Statements`\n",
        "!pip install PyGithub\n",
        "\n",
        "# Package Imports\n",
        "import random\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "from urllib.request import urlopen # The default requests package\n",
        "import requests # For making GitHub requests\n",
        "from pprint import pprint # For pretty printing\n",
        "from pathlib import Path # The Path class\n",
        "\n",
        "# For the more advanced requests\n",
        "import base64\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"./PyGithub\");\n",
        "from github import Github\n",
        "from getpass import getpass\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyGithub in /usr/local/lib/python3.7/dist-packages (1.54.1)\n",
            "Requirement already satisfied: pyjwt<2.0 in /usr/local/lib/python3.7/dist-packages (from PyGithub) (1.7.1)\n",
            "Requirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.7/dist-packages (from PyGithub) (2.23.0)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.7/dist-packages (from PyGithub) (1.2.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.14.0->PyGithub) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.14.0->PyGithub) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.14.0->PyGithub) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.14.0->PyGithub) (2020.12.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated->PyGithub) (1.12.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HfS1LmNxiMp"
      },
      "source": [
        "#@title Function Definitions\n",
        "# Recursively Import the Data (AUTOMATIC)\n",
        "\n",
        "def _decode_and_write(file__, path_):\n",
        "    data = file__.decoded_content\n",
        "    data = data.decode('utf-8')[1:]\n",
        "    with open(path_, 'w') as writefile:\n",
        "        writefile.write(data) \n",
        "    data = data.splitlines()\n",
        "    data_rows = []\n",
        "    for count, word in enumerate(data):\n",
        "        if count>0:\n",
        "            data_rows.append(word.split(','))\n",
        "    data = pd.DataFrame(data_rows)\n",
        "    data = data.to_numpy()\n",
        "    return data\n",
        "\n",
        "\n",
        "def import_github(path_name=\"AllLyrics.txt\"):\n",
        "    \"\"\"\n",
        "    Function for importing the github file\n",
        "    path_name: str\n",
        "    output: None\n",
        "    \"\"\"\n",
        "    g = Github(getpass(\"Enter your PAT key \")) # Enter your PAT Key.\n",
        "    username = \"MikeMNelhams\"\n",
        "    main_branch_bool = input(\"Main Branch: Yes or No? \")\n",
        "    yes_synonyms = [\"yes\", \"y\", \"yh\", \"1\", \"true\"]\n",
        "    if main_branch_bool.lower() in yes_synonyms: \n",
        "        branch = \"master\" \n",
        "    else: \n",
        "        branch = \"PROTOTYPE\"\n",
        "\n",
        "    user = g.get_user(username)\n",
        "    r_proj_clone = 0\n",
        "    for repo in g.get_user().get_repos():\n",
        "        if repo.name == \"ai-group-project-Team-JMJM\":\n",
        "            r_proj_clone = repo\n",
        "            break\n",
        "        # To see all the available attributes and methods\n",
        "        print(dir(repo))\n",
        "    if not r_proj_clone:\n",
        "        print(\"ai-group-project-Team-JMJM not found\")\n",
        "        sys.exit()\n",
        "    print(\"Importing Github cleaned text files...\")\n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/CLEAN\", ref=branch)\n",
        "    RAP_DATA = []\n",
        "    for file_ in contents:\n",
        "        path = file_.path\n",
        "        path = str(path) \n",
        "        # Only choose the .txt files\n",
        "        if path[-4:] == '.txt':\n",
        "            # Append the Lyrics\n",
        "            RAP_DATA.append(file_.decoded_content.decode(\"utf-8\")) \n",
        "    \n",
        "    temp_path = Path(path_name)\n",
        "    if temp_path.is_file(): \n",
        "        if os.stat(path_name).st_size == 0:\n",
        "            write_bool2 = True\n",
        "        else: \n",
        "            write_bool2 = False\n",
        "    else: \n",
        "        write_bool2 = True\n",
        "    \n",
        "    if write_bool2: \n",
        "        for lyric in RAP_DATA: \n",
        "            try:\n",
        "                with open(path_name, 'w') as writefile: \n",
        "                    writefile.write(lyric)\n",
        "            except: \n",
        "                print(\"Error, file moved/deleted during write\")\n",
        "        print(\"{} is now up to date!\".format(path_name))\n",
        "    else: \n",
        "        print(\"{} is already up to date!\".format(path_name))\n",
        "    \n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/Other\", ref=branch)\n",
        "    for counter, file_ in enumerate(contents):\n",
        "        path = file_.path\n",
        "        path = str(path) \n",
        "\n",
        "        title_start = path.find('Other')\n",
        "        title_len = path[title_start:].find('.')\n",
        "        path = path[title_start + 6:title_start + title_len + 4]\n",
        "\n",
        "        print(\"Writing file {} {}\".format(counter, path))\n",
        "        temp_path = Path(path)\n",
        "        if temp_path.is_file():\n",
        "            with open(path,'w'): pass # Cheeky way to clear the file if it exists\n",
        "        \n",
        "        # Split the long string into a list of lines, then split by words, then put into a csv, then to numpy array \n",
        "        data = file_.decoded_content\n",
        "        data = data.decode('utf-8')[1:]\n",
        "\n",
        "        with open(path, 'w') as writefile:\n",
        "            writefile.write(data) \n",
        "        print(\"All files now up to date!\")\n",
        "\n",
        "\n",
        "def update_github(write_bool=False, path_name=\"AllLyrics.txt\"):\n",
        "    \"\"\"\n",
        "    Function for updating the github file, by cleaning the lyrics, optional write to txt file. \n",
        "    write_bool: bool\n",
        "    path_name: str\n",
        "    output: None\n",
        "    \"\"\"\n",
        "    g = Github(getpass(\"Enter your PAT key \")) # Enter your PAT Key.\n",
        "    username = \"MikeMNelhams\"\n",
        "    main_branch_bool = input(\"Main Branch: Yes or No? \")\n",
        "    yes_synonyms = [\"yes\", \"y\", \"yh\", \"1\", \"true\"]\n",
        "    if main_branch_bool.lower() in yes_synonyms: \n",
        "        branch = \"master\" \n",
        "    else: \n",
        "        branch = \"PROTOTYPE\"\n",
        "\n",
        "    user = g.get_user(username)\n",
        "    r_proj_clone = 0\n",
        "    for repo in g.get_user().get_repos():\n",
        "        if repo.name == \"ai-group-project-Team-JMJM\":\n",
        "            r_proj_clone = repo\n",
        "            break\n",
        "        # To see all the available attributes and methods\n",
        "        print(dir(repo))\n",
        "    \n",
        "    if not r_proj_clone:\n",
        "        print(\"ai-group-project-Team-JMJM not found\")\n",
        "        sys.exit()\n",
        "\n",
        "    print(\"Importing editing csv files...\")\n",
        "\n",
        "    # Split the long string into a list of lines, then split by words, then put into a csv, then to numpy arr\n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/Other\", ref=branch)\n",
        "    for counter, file_ in enumerate(contents):\n",
        "        path = file_.path \n",
        "        path = str(path)\n",
        "        title_start = path.find('Other')\n",
        "        title_len = path[title_start:].find('.')\n",
        "        name = path[title_start + 6:title_start + title_len + 4]\n",
        "        print(\"Writing file {} {}\".format(counter, name))\n",
        "        if name.lower() == \"censors.csv\":\n",
        "            censors = _decode_and_write(file_, path)\n",
        "        elif name.lower() == \"capitals.csv\":\n",
        "            capitals = _decode_and_write(file_, path)\n",
        "        else: \n",
        "            _decode_and_write(file_, path)\n",
        "    print(\"All editing csv files are up to date!\")\n",
        "\n",
        "    print(\"Importing Github uncleaned text files...\")\n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/UNCLEAN\", ref=branch)\n",
        "\n",
        "    RAP_DATA = []\n",
        "    rap_lyric_names = []\n",
        "\n",
        "    for file_ in contents:\n",
        "        path = file_.path\n",
        "        path = str(path) \n",
        "        # Only choose the .txt files\n",
        "        if path[-4:] == '.txt':\n",
        "            # Append the name\n",
        "            title_start = path.find('UNCLEAN')\n",
        "            title_len = path[title_start:].find('.')\n",
        "            name = path[title_start + 8:title_start + title_len]\n",
        "            if name[-2:] == 'UC':\n",
        "                name = name[:-2]\n",
        "            rap_lyric_names.append(name) \n",
        "\n",
        "        # Append the Lyrics\n",
        "        RAP_DATA.append(file_.decoded_content.decode(\"utf-8\")) \n",
        "        \n",
        "    # Remove the \\ufeff at the beginning O(n)\n",
        "    for count, lyric in enumerate(RAP_DATA): \n",
        "        RAP_DATA[count] = lyric[1:]\n",
        "\n",
        "    # Censor the profanities O(n*m + n*m2) m > m2 xor m2 > m\n",
        "    for count in range(len(RAP_DATA)): \n",
        "        for i in range(len(censors[0:])):\n",
        "            RAP_DATA[count] = RAP_DATA[count].replace(str(censors[i, 0]), str(censors[i, 1]))\n",
        "        for i in range(len(capitals[0:])):\n",
        "            RAP_DATA[count] = RAP_DATA[count].replace(str(capitals[i, 0]), str(capitals[i, 1]))\n",
        "\n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/CLEAN\", ref=branch)\n",
        "    cleaned_names = []\n",
        "    for counter, file_ in enumerate(contents):\n",
        "        path = file_.path\n",
        "        path = str(path) \n",
        "        print(\"File {} \".format(counter + 1) + path)\n",
        "        # Only choose the .txt files\n",
        "        if path[-4:] == '.txt':\n",
        "            # Append the name\n",
        "            title_start = path.find('CLEAN')\n",
        "            title_len = path[title_start:].find('.')\n",
        "        name = path[title_start + 6:title_start + title_len]\n",
        "        if name[-2:] == 'CL':\n",
        "            name = name[:-2]\n",
        "        cleaned_names.append(name) \n",
        "\n",
        "    # ALL OF THE EDITING IS DONE IN THE 'PROTOTYPE BRANCH' to avoid overwriting import changes\n",
        "    # If the (now cleaned) rap_lyrics name is new (not in cleaned_names), then we want to create that as a new file \n",
        "    # If the (now cleaned) rap_lyrics name is NOT new (not in cleaned_names), then we want to update the file\n",
        "    # print(rap_lyric_names)\n",
        "    # print(cleaned_names)\n",
        "    print(\"Commiting files to github...\")\n",
        "    for counter, new_name in enumerate(rap_lyric_names): \n",
        "        if new_name in cleaned_names: \n",
        "            duplicate = r_proj_clone.get_contents(\"RapLyrics/CLEAN/{}CL.txt\".format(new_name), ref=branch)\n",
        "            r_proj_clone.update_file(\"RapLyrics/CLEAN/{}CL.txt\".format(new_name), \"This was uploaded automatically via pipeline\", RAP_DATA[counter], duplicate.sha, branch=branch)\n",
        "        else:\n",
        "            r_proj_clone.create_file(\"RapLyrics/CLEAN/{}CL.txt\".format(new_name), \"This was uploaded automatically via pipeline\", RAP_DATA[counter], branch=branch)\n",
        "\n",
        "    if write_bool: \n",
        "        print(\"Writing text file to: {}\".format(path_name))\n",
        "        with open(path_name, 'w') as writefile:\n",
        "            for lyric in RAP_DATA:\n",
        "                writefile.write(lyric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtfMMwOdxmt_",
        "outputId": "93738fe0-c199-4d38-8c35-3a3927b3dbca"
      },
      "source": [
        "# Import all of Mike's lyrics",
        "import_github()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your PAT key ··········\n",
            "Main Branch: Yes or No? Yes\n",
            "Importing Github cleaned text files...\n",
            "AllLyrics.txt is now up to date!\n",
            "Writing file 0 capitals.csv\n",
            "All files now up to date!\n",
            "Writing file 1 censors.csv\n",
            "All files now up to date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VjURXnfxsKJ"
      },
      "source": [
        "Text = open(\"AllLyrics.txt\", \"r\").read()\n",
        "# turn text to lower case to reduce vocabulary\n",
        "Text = Text.lower()\n",
        "with open(\"AllLyrics.txt\", \"r\") as f:\n",
        "    content = f.readlines()\n",
        "# bars is a list containing each line in dataset in lowercase\n",
        "bars = [x.strip().lower() for x in content]\n",
        "stripped_bars = [word.split() for word in bars]\n",
        "# Vocabulary is a list of all words in the dataset\n",
        "Vocabulary = ''.join([i for i in Text if not i.isdigit()]).replace(\"\\n\",\" \").split(' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLpVvXPQ2rHL"
      },
      "source": [
        "no_of_bars = len(bars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIRyjmQeyaAG"
      },
      "source": [
        "# word_count is a function creating a list of words ranked in order of most used\n",
        "# could think about removing certain words to create more accurate raps as model won't learn well from words used very infrequently\n",
        "def word_count(lyrics):\n",
        "  a = {}\n",
        "  for word in Vocabulary:\n",
        "    if word in a:\n",
        "      a[word] += 1\n",
        "    else:\n",
        "      a[word] = 1\n",
        "  return a\n",
        "word_dict = word_count(Vocabulary)\n",
        "sort_dict = sorted(word_dict.items(), key = lambda x: x[1], reverse = True)\n",
        "# Top 20 words\n",
        "sort_dict1 = sort_dict[:40]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIweRLWJqfax"
      },
      "source": [
        "words = sorted(list(set(Vocabulary)))\n",
        "int_to_word = { i : words[i] for i in range(len(words))}\n",
        "# Need to reverse this at the end to reverse numbers back into words\n",
        "word_to_int = { words[i] : i for i in range(len(words))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzfKleYrygft"
      },
      "source": [
        "# create a function that converts bars into a sequence of unique integers\n",
        "# List of all unique vocabulary in alphabetical order\n",
        "\n",
        "def words_to_integers(bar, Vocabulary):\n",
        "  encode = []\n",
        "  stripped_bar = [word.split() for word in bar]\n",
        "  for i in range(no_of_bars):\n",
        "    seq = []\n",
        "    seq.append([word_to_int[word] for word in stripped_bar[i]])\n",
        "    encode.append(seq)\n",
        "\n",
        "  encode = sum(encode, [])\n",
        "  return encode\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RHaklDv5tZN",
        "outputId": "62562f79-d1ed-4e9e-ba80-b9fff5fb753f"
      },
      "source": [
        "vocab_size = len(words) + 1\n",
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiP3CQKQrIR7"
      },
      "source": [
        "def sentence_to_integer(bar):\n",
        "    stripped_bar = [word.split() for word in [bar]]\n",
        "    stripped_bar = sum(stripped_bar, [])\n",
        "    seq = []\n",
        "    seq.append([word_to_int[word] for word in stripped_bar])\n",
        "    seq = sum(seq, [])\n",
        "    return seq\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2Log92J2ZdU"
      },
      "source": [
        "sequences = []\n",
        "for line in bars:\n",
        "    token_list = sentence_to_integer(line)\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_seq = token_list[:i+1]\n",
        "        sequences.append(n_gram_seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABAKPmzErRT_",
        "outputId": "155b6d1d-515d-4945-afae-3be2d8571477"
      },
      "source": [
        "padding_length = max([len(line) for line in sequences])\n",
        "print(padding_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VXihUw13aAL"
      },
      "source": [
        "def sentence_to_integer(bar):\n",
        "    stripped_bar = [word.split() for word in [bar]]\n",
        "    stripped_bar = sum(stripped_bar, [])\n",
        "    seq = []\n",
        "    seq.append([word_to_int[word] for word in stripped_bar])\n",
        "    seq = sum(seq, [])\n",
        "    return seq\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PV9FBI_EsEQ"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "sequences = np.array(pad_sequences(sequences, maxlen = padding_length, padding = 'pre'))\n",
        "# Remove last word from each line\n",
        "x_train = sequences[:,:-1]\n",
        "# Last word is used as the label\n",
        "y_train = sequences[:,-1]\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes = vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWoLXV1Qr4E9",
        "outputId": "818e40fe-a23c-4f38-ada8-30c429edfbe3"
      },
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout, Bidirectional\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 256, input_length = padding_length - 1))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences = True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(128, return_sequences = True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(256)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(256))\n",
        "model.add(Dense(vocab_size, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 65, 256)           1296896   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 65, 128)           164352    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 65, 128)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 65, 256)           263168    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 65, 256)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 512)               1050624   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5066)              1301962   \n",
            "=================================================================\n",
            "Total params: 4,208,330\n",
            "Trainable params: 4,208,330\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "Ar4UNHRZtBrp",
        "outputId": "94019c14-d8d0-4794-8216-a0c949199c8c"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs = 200, batch_size = 256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 78/160 [=============>................] - ETA: 7s - loss: 0.5981 - accuracy: 0.8363"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-e23e426c7515>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8VUqslB6kMO",
        "outputId": "0d9214d7-cc21-47c7-ae80-fb18da0e7cea"
      },
      "source": [
        "model.save('/content/gdrive/MyDrive/lstm-basic3')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/lstm-basic3/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/lstm-basic3/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "ImBWp2JQtHYW",
        "outputId": "eb75490b-d302-44da-9998-ae224ca6a8ed"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdNEPEyqte-E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBrQuS2jwU9F"
      },
      "source": [
        "new_model = tf.keras.models.load_model('/content/drive/MyDrive/lstm-basic3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO78Ex9O5lF_"
      },
      "source": [
        "def generateraplyrics():\n",
        "  seed_text  = random.choice(bars)\n",
        "  next_words = 100\n",
        "  token_list = sentence_to_integer(seed_text)\n",
        "  token_list = pad_sequences([token_list], maxlen = padding_length - 1, padding = 'pre')\n",
        "  predicted  = new_model.predict_classes(token_list, verbose = 0)\n",
        "  lyrics = int_to_word[predicted[0]]\n",
        "  for _ in range(next_words):\n",
        "      token_list = sentence_to_integer(lyrics)\n",
        "      token_list = pad_sequences([token_list], maxlen = padding_length - 1, padding = 'pre')\n",
        "      predicted  = new_model.predict_classes(token_list, verbose = 0)\n",
        "      lyrics += ' ' + int_to_word[predicted[0]]\n",
        "  return lyrics.capitalize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "ZsQYK-4RxjJB",
        "outputId": "0216eb08-7450-4f32-edb6-580e90540e4b"
      },
      "source": [
        "generateraplyrics()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tight gun totin motherfricker see you chumps on top sky is the limit and you know that you keep on your wall you want you call it if i go to do somethin man im similar to the thriller in manila that line baby we dont want it yo a poop i love you like a lot of a intermission is a benz but he dont get with me what i gotta do is creep my frickin hunger to fight or deep wit the mental fricked in them advancing from duplex to mansion and pure poops still a part of you'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv4PFZPT56Kh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
