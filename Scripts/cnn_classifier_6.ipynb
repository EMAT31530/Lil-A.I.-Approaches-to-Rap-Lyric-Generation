{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn classifier 6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bJXISN-YhE5"
      },
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "from __future__ import print_function\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from keras import utils as np_utils"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx4DD9jdYhrn",
        "outputId": "b0ef84ba-b499-4e2f-f286-3e9aa51df7d5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkgyEH2dYiA0"
      },
      "source": [
        "# upload txt files for our data\n",
        "# All Rock\n",
        "rock1 = open('/content/drive/My Drive/Colab Notebooks/AllRock.txt', 'r').read()\n",
        "rock = ''.join([i for i in rock1 if not i.isdigit()]).replace(\"\\n\", \" \").lower().replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\").replace(\",\", \"\").replace(\"\", \"\").replace(\"'\", \"\").replace(\")\", \"\").replace(\"(\", \"\").split(' ')\n",
        "# All Pop\n",
        "pop1 = open('/content/drive/My Drive/Colab Notebooks/AllPop.txt', 'r').read()\n",
        "pop = ''.join([i for i in pop1 if not i.isdigit()]).replace(\"\\n\", \" \").lower().replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\").replace(\",\", \"\").replace(\"\", \"\").replace(\"'\", \"\").replace(\")\", \"\").replace(\"(\", \"\").split(' ')\n",
        "# All Country\n",
        "country1 = open('/content/drive/My Drive/Colab Notebooks/AllCountry.txt', 'r').read()\n",
        "country = ''.join([i for i in country1 if not i.isdigit()]).replace(\"\\n\", \" \").lower().replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\").replace(\",\", \"\").replace(\"\", \"\").replace(\"'\", \"\").replace(\")\", \"\").replace(\"(\", \"\").split(' ')\n",
        "# All Rap\n",
        "rap1 = open('/content/drive/My Drive/Colab Notebooks/AllLyrics.txt', 'r').read()\n",
        "rap = ''.join([i for i in rap1 if not i.isdigit()]).replace(\"\\n\", \" \").lower().replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\").replace(\",\", \"\").replace(\"\", \"\").replace(\"'\", \"\").replace(\")\", \"\").replace(\"(\", \"\").split(' ')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdKMSVXZYpvn"
      },
      "source": [
        "# create samples of 10 words each for each genre - this is our estimate length of line\n",
        "SONG_LENGTH = 10\n",
        "# Rock\n",
        "Rock = [rock[i*SONG_LENGTH:(i+1)*SONG_LENGTH] for i in range(0,int(len(rock)/int(SONG_LENGTH)))]\n",
        "# Country\n",
        "Country = [country[i*SONG_LENGTH:(i+1)*SONG_LENGTH] for i in range(0,int(len(country)/int(SONG_LENGTH)))]\n",
        "# Pop\n",
        "Pop = [pop[i*SONG_LENGTH:(i+1)*SONG_LENGTH] for i in range(0,int(len(pop)/int(SONG_LENGTH)))]\n",
        "# Rap\n",
        "Rap = [rap[i*SONG_LENGTH:(i+1)*SONG_LENGTH] for i in range(0,int(len(rap)/int(SONG_LENGTH)))]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKsBNcRMYqZW"
      },
      "source": [
        "# joining the strings in the samples\n",
        "ds_rock = [' '.join(Rock[i]) for i in range(len(Rock))]\n",
        "ds_country = [' '.join(Country[i]) for i in range(len(Country))]\n",
        "ds_pop = [' '.join(Pop[i]) for i in range(len(Pop))]\n",
        "ds_rap = [' '.join(Rap[i]) for i in range(len(Rap))]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv9ruqcxYsj6",
        "outputId": "5e60afd5-9660-4bd6-d17c-15d361e8259a"
      },
      "source": [
        "# make a list here where each sample has it's genre number\n",
        "# rock 0, country 1, pop 2, rap 3\n",
        "ds_ro = []\n",
        "genre = 0\n",
        "for sample in ds_rock:\n",
        "  ds_ro.append([genre, sample])\n",
        "\n",
        "ds_co = []\n",
        "genre = 1\n",
        "for sample in ds_country:\n",
        "  ds_co.append([genre, sample])\n",
        "\n",
        "ds_po = []\n",
        "genre = 2\n",
        "for sample in ds_pop:\n",
        "  ds_po.append([genre, sample])\n",
        "\n",
        "ds_ra = []\n",
        "genre = 3\n",
        "for sample in ds_rap:\n",
        "  ds_ra.append([genre, sample])\n",
        "\n",
        "ds = ds_ro+ds_co+ds_po+ds_ra\n",
        "\n",
        "ds = np.array(ds)\n",
        "print('Genres: ', ds[:, 0])\n",
        "print('Lyrics: ', ds[:, 1])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Genres:  ['0' '0' '0' ... '3' '3' '3']\n",
            "Lyrics:  ['yesterday all my troubles seemed so far away now it'\n",
            " 'looks as though theyre here to stay oh i believe'\n",
            " 'in yesterday suddenly im not half the man i used' ...\n",
            " 'kick me when im down but im up again scorchin'\n",
            " 'hot forcin my way up in the door to kill'\n",
            " 'the bullpoop like a matador keep your hands high what']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwefSRjmZII8"
      },
      "source": [
        "x = ds[:, 1]\n",
        "y = ds[:, 0]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2Z-G7-tYzLm"
      },
      "source": [
        " # tokenize here\n",
        "tk = Tokenizer(num_words= 1000, filters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True, split=\" \")\n",
        "tk.fit_on_texts(x)\n",
        "x = tk.texts_to_sequences(x)\n",
        "x = sequence.pad_sequences(x, maxlen=200)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KIKqjP5ZQXF"
      },
      "source": [
        "# classification category\n",
        "labelencoder_Y = LabelEncoder()\n",
        "y = labelencoder_Y.fit_transform(y)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-fY_sS0ZUVs"
      },
      "source": [
        "# one hot encoding \n",
        "y = np_utils.to_categorical(y, num_classes= 4)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf9s-8CeZWlY"
      },
      "source": [
        "np.random.seed(200)\n",
        "indices = np.arange(len(x))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3b1wAVcZYrt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "1e98cb6d-2e0e-4386-d736-e45cfc779814"
      },
      "source": [
        "index_from=3\n",
        "start_char = 1\n",
        "if start_char is not None:\n",
        "  x = [[start_char] + [w + index_from for w in x1] for x1 in x]\n",
        "  elif index_from:\n",
        "x = [[w + index_from for w in x1] for x1 in x]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-b3a1041bec7e>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    elif index_from:\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_BkAm5hZaLy"
      },
      "source": [
        "num_words = None\n",
        "if not num_words:\n",
        "  num_words = max([max(x1) for x1 in x])\n",
        "\n",
        "  oov_char = 2\n",
        "  skip_top = 0\n",
        "\n",
        "  if oov_char is not None:\n",
        "    x = [[w if (skip_top <= w < num_words) else oov_char for w in x1] for x1 in x]\n",
        "  else:\n",
        "    x = [[w for w in x1 if (skip_top <= w < num_words)] for x1 in x]\n",
        "        \n",
        "# split data here\n",
        "test_split = 0.2\n",
        "idx = int(len(x) * (1 - test_split))\n",
        "x_train, y_train = np.array(x[:idx]), np.array(y[:idx])\n",
        "x_test, y_test = np.array(x[idx:]), np.array(y[idx:])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbCQnfsSZcWt",
        "outputId": "06c660b1-671f-4651-9757-ca7b8f919cbf"
      },
      "source": [
        "x_train = sequence.pad_sequences(x_train, maxlen=201)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=201)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (42039, 201)\n",
            "x_test shape: (10510, 201)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k99cO2KhZfH4",
        "outputId": "fc376258-9cce-4940-9133-e262f24517da"
      },
      "source": [
        "max_features = 1000\n",
        "maxlen = 201\n",
        "embedding_dims = 50\n",
        "filters = 250\n",
        "kernel_size = 3\n",
        "hidden_dims = 250\n",
        "\n",
        "\n",
        "# CNN here\n",
        "print('Building model...')\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(max_features,embedding_dims,input_length=maxlen))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# add Convolution1D\n",
        "model.add(Conv1D(filters,kernel_size,padding='valid',activation='relu',strides=1))\n",
        "# max pooling:\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "model.add(Dense(hidden_dims))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(4))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,batch_size=32,epochs=5,validation_data=(x_test, y_test))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building model...\n",
            "Epoch 1/5\n",
            "1314/1314 [==============================] - 53s 40ms/step - loss: 0.9923 - accuracy: 0.6147 - val_loss: 0.8607 - val_accuracy: 0.6598\n",
            "Epoch 2/5\n",
            "1314/1314 [==============================] - 52s 40ms/step - loss: 0.8227 - accuracy: 0.6726 - val_loss: 0.8118 - val_accuracy: 0.6825\n",
            "Epoch 3/5\n",
            "1314/1314 [==============================] - 52s 40ms/step - loss: 0.7569 - accuracy: 0.7074 - val_loss: 0.7790 - val_accuracy: 0.6982\n",
            "Epoch 4/5\n",
            "1314/1314 [==============================] - 52s 40ms/step - loss: 0.7135 - accuracy: 0.7240 - val_loss: 0.7468 - val_accuracy: 0.7127\n",
            "Epoch 5/5\n",
            "1314/1314 [==============================] - 52s 40ms/step - loss: 0.6608 - accuracy: 0.7501 - val_loss: 0.7413 - val_accuracy: 0.7157\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc654a4ba50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vni_9AwmaOq2",
        "outputId": "60bd3ca5-33e6-48b2-9354-d9320d8831eb"
      },
      "source": [
        "accr = model.evaluate(x_test,y_test)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "329/329 [==============================] - 3s 9ms/step - loss: 0.7413 - accuracy: 0.7157\n",
            "Test set\n",
            "  Loss: 0.741\n",
            "  Accuracy: 0.716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTpOlmGqa6Kp"
      },
      "source": [
        "def classify_string(input):\n",
        "  lyric = [str(input)]\n",
        "  seq = tk.texts_to_sequences(lyric)\n",
        "  pred = model.predict(seq)\n",
        "  labels = ['rock', 'country', 'pop', 'rap']\n",
        "  print(labels[np.argmax(pred)])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGxIQstjbBjj"
      },
      "source": [
        "def classify_list(input):\n",
        "  for lyric in input:\n",
        "    classify_string(lyric)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGPXLCrKbD_5",
        "outputId": "6f446a0e-e576-4507-8ea8-73d9a30bb4f9"
      },
      "source": [
        "# markov generated lyrics\n",
        "lyrics = ['Bumpin i meant for you call my ninja like',\n",
        " 'Biz dont take their baby mommas ninja frick you nasty boy you',\n",
        " 'Shifty sticks and pray and flee the frick all of you',\n",
        " 'Glocks but all ill die slow',\n",
        " 'Wondering if im askin blunt sip champagne range rover been outside for',\n",
        " 'And youre so take that crown two pounds you know',\n",
        " 'Publishing i thought i get witcha can i could cop',\n",
        " 'Miss the more cause you in the right one',\n",
        " 'Onyx and them hoes i love',\n",
        " 'Gat call me puff daddy biggie gots ta like',\n",
        " 'Everything around me shit b***** in ya imma stay yappin when',\n",
        " 'Hum all about fingers in the loot im',\n",
        " 'Rollem up heard whos this yeah keep on top sky is',\n",
        " 'Drunk of ninjaz from now drop to',\n",
        " 'Declinin windin like flypaper neighbor slow down',\n",
        " 'Expensive cars i tote my crew i only got enough heart',\n",
        " 'Lame dudes whos next move but the drugs to spit phrases thatll',\n",
        " 'Guy well its cool and your poop so hard to',\n",
        " 'Clap wit my life in ma little nasty boy',\n",
        " 'Dial you should too much better man played',\n",
        " 'Lali like that you frick doin all mcs have']\n",
        "\n",
        "classify_list(lyrics)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 201) for input KerasTensor(type_spec=TensorSpec(shape=(None, 201), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
            "rap\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 201) for input KerasTensor(type_spec=TensorSpec(shape=(None, 201), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (None, 10).\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CR5PqhObFrp",
        "outputId": "f0d0f152-a908-4468-e62c-57bf0e5d35e5"
      },
      "source": [
        "# lstm generated lyrics\n",
        "lyrics2 = ['in the veins hard to explain how i maintain', \n",
        "  'to put my back in the house so i can i wanna flaunt you thats right', \n",
        "  'with the grime of my ninja frick',\n",
        "  'with the ds crept in blastin him you dont want to slit the clits alot',\n",
        "  'used to lick the clits a lot of problems never be the beamer with the goldie sound',\n",
        "  'like a steelo not my steelo oh no thats not my my steelo oh i steelo not my steelo oh no',\n",
        "  'thats not my no steelo bust my no dough day but this sittin bodies not my']\n",
        "\n",
        "classify_list(lyrics2)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "pop\n",
            "rap\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7a4iQ2Ii4ab"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}