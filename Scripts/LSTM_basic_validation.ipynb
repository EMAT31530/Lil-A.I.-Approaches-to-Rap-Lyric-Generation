{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-basic-validation",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGjCDVX-5oBi"
      },
      "source": [
        "LSTM model architecture 1:\n",
        "\n",
        "First working model (previous one didn't produce lyrics correctly) with and Embedding layer, two Bidirectional LSTM layers, 2 dropout layers to avoid overfitting and a dense layer.\n",
        "\n",
        "This is the most basic level, but the results seem fairly good with 84% accuracy after 200 epochs (40mins).\n",
        "\n",
        "Also includes function that outputs most used words in the Vocabulary.\n",
        "\n",
        "Has a basic lyric generator that can be improved. Maybe we can create a loss function which favours rhyme or look at creating bars line by line. The problem with this was bars ending in words like 'i' and 'the' as lines were getting cut short."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyEQkMNVxPS7",
        "outputId": "b75bd0e0-47fc-44b2-cfe2-67d899a838c8"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import LSTM\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "#@title Import Statements`\n",
        "!pip install PyGithub\n",
        "\n",
        "# Package Imports\n",
        "import random\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "from urllib.request import urlopen # The default requests package\n",
        "import requests # For making GitHub requests\n",
        "from pprint import pprint # For pretty printing\n",
        "from pathlib import Path # The Path class\n",
        "\n",
        "# For the more advanced requests\n",
        "import base64\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"./PyGithub\");\n",
        "from github import Github\n",
        "from getpass import getpass\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyGithub\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/44/df78514f2b5f5abaec330596e0fa3273824238399a964d1a7e82fd39990d/PyGithub-1.54.1-py3-none-any.whl (289kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 25.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20kB 15.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 30kB 12.7MB/s eta 0:00:01\r\u001b[K     |████▌                           | 40kB 12.1MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 51kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 61kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 71kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 81kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 92kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 102kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 112kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 122kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 133kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 143kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 153kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 163kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 174kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 184kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 194kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 204kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 215kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 225kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 235kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 245kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 256kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 266kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 276kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 286kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 296kB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.7/dist-packages (from PyGithub) (2.23.0)\n",
            "Collecting pyjwt<2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\n",
            "Collecting deprecated\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/73/994edfcba74443146c84b91921fcc269374354118d4f452fb0c54c1cbb12/Deprecated-1.2.12-py2.py3-none-any.whl\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.14.0->PyGithub) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.14.0->PyGithub) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.14.0->PyGithub) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.14.0->PyGithub) (2020.12.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated->PyGithub) (1.12.1)\n",
            "Installing collected packages: pyjwt, deprecated, PyGithub\n",
            "Successfully installed PyGithub-1.54.1 deprecated-1.2.12 pyjwt-1.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HfS1LmNxiMp"
      },
      "source": [
        "#@title Function Definitions\n",
        "# Recursively Import the Data (AUTOMATIC)\n",
        "\n",
        "def _decode_and_write(file__, path_):\n",
        "    data = file__.decoded_content\n",
        "    data = data.decode('utf-8')[1:]\n",
        "    with open(path_, 'w') as writefile:\n",
        "        writefile.write(data) \n",
        "    data = data.splitlines()\n",
        "    data_rows = []\n",
        "    for count, word in enumerate(data):\n",
        "        if count>0:\n",
        "            data_rows.append(word.split(','))\n",
        "    data = pd.DataFrame(data_rows)\n",
        "    data = data.to_numpy()\n",
        "    return data\n",
        "\n",
        "\n",
        "def import_github(path_name=\"AllLyrics.txt\"):\n",
        "    \"\"\"\n",
        "    Function for importing the github file\n",
        "    path_name: str\n",
        "    output: None\n",
        "    \"\"\"\n",
        "    g = Github(getpass(\"Enter your PAT key \")) # Enter your PAT Key.\n",
        "    username = \"MikeMNelhams\"\n",
        "    main_branch_bool = input(\"Main Branch: Yes or No? \")\n",
        "    yes_synonyms = [\"yes\", \"y\", \"yh\", \"1\", \"true\"]\n",
        "    if main_branch_bool.lower() in yes_synonyms: \n",
        "        branch = \"master\" \n",
        "    else: \n",
        "        branch = \"PROTOTYPE\"\n",
        "\n",
        "    user = g.get_user(username)\n",
        "    r_proj_clone = 0\n",
        "    for repo in g.get_user().get_repos():\n",
        "        if repo.name == \"ai-group-project-Team-JMJM\":\n",
        "            r_proj_clone = repo\n",
        "            break\n",
        "        # To see all the available attributes and methods\n",
        "        print(dir(repo))\n",
        "    if not r_proj_clone:\n",
        "        print(\"ai-group-project-Team-JMJM not found\")\n",
        "        sys.exit()\n",
        "    print(\"Importing Github cleaned text files...\")\n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/CLEAN\", ref=branch)\n",
        "    RAP_DATA = []\n",
        "    for file_ in contents:\n",
        "        path = file_.path\n",
        "        path = str(path) \n",
        "        # Only choose the .txt files\n",
        "        if path[-4:] == '.txt':\n",
        "            # Append the Lyrics\n",
        "            RAP_DATA.append(file_.decoded_content.decode(\"utf-8\")) \n",
        "    \n",
        "    temp_path = Path(path_name)\n",
        "    if temp_path.is_file(): \n",
        "        if os.stat(path_name).st_size == 0:\n",
        "            write_bool2 = True\n",
        "        else: \n",
        "            write_bool2 = False\n",
        "    else: \n",
        "        write_bool2 = True\n",
        "    \n",
        "    if write_bool2: \n",
        "        for lyric in RAP_DATA: \n",
        "            try:\n",
        "                with open(path_name, 'w') as writefile: \n",
        "                    writefile.write(lyric)\n",
        "            except: \n",
        "                print(\"Error, file moved/deleted during write\")\n",
        "        print(\"{} is now up to date!\".format(path_name))\n",
        "    else: \n",
        "        print(\"{} is already up to date!\".format(path_name))\n",
        "    \n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/Other\", ref=branch)\n",
        "    for counter, file_ in enumerate(contents):\n",
        "        path = file_.path\n",
        "        path = str(path) \n",
        "\n",
        "        title_start = path.find('Other')\n",
        "        title_len = path[title_start:].find('.')\n",
        "        path = path[title_start + 6:title_start + title_len + 4]\n",
        "\n",
        "        print(\"Writing file {} {}\".format(counter, path))\n",
        "        temp_path = Path(path)\n",
        "        if temp_path.is_file():\n",
        "            with open(path,'w'): pass # Cheeky way to clear the file if it exists\n",
        "        \n",
        "        # Split the long string into a list of lines, then split by words, then put into a csv, then to numpy array \n",
        "        data = file_.decoded_content\n",
        "        data = data.decode('utf-8')[1:]\n",
        "\n",
        "        with open(path, 'w') as writefile:\n",
        "            writefile.write(data) \n",
        "        print(\"All files now up to date!\")\n",
        "\n",
        "\n",
        "def update_github(write_bool=False, path_name=\"AllLyrics.txt\"):\n",
        "    \"\"\"\n",
        "    Function for updating the github file, by cleaning the lyrics, optional write to txt file. \n",
        "    write_bool: bool\n",
        "    path_name: str\n",
        "    output: None\n",
        "    \"\"\"\n",
        "    g = Github(getpass(\"Enter your PAT key \")) # Enter your PAT Key.\n",
        "    username = \"MikeMNelhams\"\n",
        "    main_branch_bool = input(\"Main Branch: Yes or No? \")\n",
        "    yes_synonyms = [\"yes\", \"y\", \"yh\", \"1\", \"true\"]\n",
        "    if main_branch_bool.lower() in yes_synonyms: \n",
        "        branch = \"master\" \n",
        "    else: \n",
        "        branch = \"PROTOTYPE\"\n",
        "\n",
        "    user = g.get_user(username)\n",
        "    r_proj_clone = 0\n",
        "    for repo in g.get_user().get_repos():\n",
        "        if repo.name == \"ai-group-project-Team-JMJM\":\n",
        "            r_proj_clone = repo\n",
        "            break\n",
        "        # To see all the available attributes and methods\n",
        "        print(dir(repo))\n",
        "    \n",
        "    if not r_proj_clone:\n",
        "        print(\"ai-group-project-Team-JMJM not found\")\n",
        "        sys.exit()\n",
        "\n",
        "    print(\"Importing editing csv files...\")\n",
        "\n",
        "    # Split the long string into a list of lines, then split by words, then put into a csv, then to numpy arr\n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/Other\", ref=branch)\n",
        "    for counter, file_ in enumerate(contents):\n",
        "        path = file_.path \n",
        "        path = str(path)\n",
        "        title_start = path.find('Other')\n",
        "        title_len = path[title_start:].find('.')\n",
        "        name = path[title_start + 6:title_start + title_len + 4]\n",
        "        print(\"Writing file {} {}\".format(counter, name))\n",
        "        if name.lower() == \"censors.csv\":\n",
        "            censors = _decode_and_write(file_, path)\n",
        "        elif name.lower() == \"capitals.csv\":\n",
        "            capitals = _decode_and_write(file_, path)\n",
        "        else: \n",
        "            _decode_and_write(file_, path)\n",
        "    print(\"All editing csv files are up to date!\")\n",
        "\n",
        "    print(\"Importing Github uncleaned text files...\")\n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/UNCLEAN\", ref=branch)\n",
        "\n",
        "    RAP_DATA = []\n",
        "    rap_lyric_names = []\n",
        "\n",
        "    for file_ in contents:\n",
        "        path = file_.path\n",
        "        path = str(path) \n",
        "        # Only choose the .txt files\n",
        "        if path[-4:] == '.txt':\n",
        "            # Append the name\n",
        "            title_start = path.find('UNCLEAN')\n",
        "            title_len = path[title_start:].find('.')\n",
        "            name = path[title_start + 8:title_start + title_len]\n",
        "            if name[-2:] == 'UC':\n",
        "                name = name[:-2]\n",
        "            rap_lyric_names.append(name) \n",
        "\n",
        "        # Append the Lyrics\n",
        "        RAP_DATA.append(file_.decoded_content.decode(\"utf-8\")) \n",
        "        \n",
        "    # Remove the \\ufeff at the beginning O(n)\n",
        "    for count, lyric in enumerate(RAP_DATA): \n",
        "        RAP_DATA[count] = lyric[1:]\n",
        "\n",
        "    # Censor the profanities O(n*m + n*m2) m > m2 xor m2 > m\n",
        "    for count in range(len(RAP_DATA)): \n",
        "        for i in range(len(censors[0:])):\n",
        "            RAP_DATA[count] = RAP_DATA[count].replace(str(censors[i, 0]), str(censors[i, 1]))\n",
        "        for i in range(len(capitals[0:])):\n",
        "            RAP_DATA[count] = RAP_DATA[count].replace(str(capitals[i, 0]), str(capitals[i, 1]))\n",
        "\n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/CLEAN\", ref=branch)\n",
        "    cleaned_names = []\n",
        "    for counter, file_ in enumerate(contents):\n",
        "        path = file_.path\n",
        "        path = str(path) \n",
        "        print(\"File {} \".format(counter + 1) + path)\n",
        "        # Only choose the .txt files\n",
        "        if path[-4:] == '.txt':\n",
        "            # Append the name\n",
        "            title_start = path.find('CLEAN')\n",
        "            title_len = path[title_start:].find('.')\n",
        "        name = path[title_start + 6:title_start + title_len]\n",
        "        if name[-2:] == 'CL':\n",
        "            name = name[:-2]\n",
        "        cleaned_names.append(name) \n",
        "\n",
        "    # ALL OF THE EDITING IS DONE IN THE 'PROTOTYPE BRANCH' to avoid overwriting import changes\n",
        "    # If the (now cleaned) rap_lyrics name is new (not in cleaned_names), then we want to create that as a new file \n",
        "    # If the (now cleaned) rap_lyrics name is NOT new (not in cleaned_names), then we want to update the file\n",
        "    # print(rap_lyric_names)\n",
        "    # print(cleaned_names)\n",
        "    print(\"Commiting files to github...\")\n",
        "    for counter, new_name in enumerate(rap_lyric_names): \n",
        "        if new_name in cleaned_names: \n",
        "            duplicate = r_proj_clone.get_contents(\"RapLyrics/CLEAN/{}CL.txt\".format(new_name), ref=branch)\n",
        "            r_proj_clone.update_file(\"RapLyrics/CLEAN/{}CL.txt\".format(new_name), \"This was uploaded automatically via pipeline\", RAP_DATA[counter], duplicate.sha, branch=branch)\n",
        "        else:\n",
        "            r_proj_clone.create_file(\"RapLyrics/CLEAN/{}CL.txt\".format(new_name), \"This was uploaded automatically via pipeline\", RAP_DATA[counter], branch=branch)\n",
        "\n",
        "    if write_bool: \n",
        "        print(\"Writing text file to: {}\".format(path_name))\n",
        "        with open(path_name, 'w') as writefile:\n",
        "            for lyric in RAP_DATA:\n",
        "                writefile.write(lyric)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtfMMwOdxmt_",
        "outputId": "9edeaad0-48fa-46f9-f944-cb6abd6ef6c0"
      },
      "source": [
        "# Import all of Mike's lyrics. PATKEY: 5ae2446bd5828c9e27deb3865118d9e783aa6e15\n",
        "import_github()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your PAT key ··········\n",
            "Main Branch: Yes or No? Yes\n",
            "Importing Github cleaned text files...\n",
            "AllLyrics.txt is now up to date!\n",
            "Writing file 0 capitals.csv\n",
            "All files now up to date!\n",
            "Writing file 1 censors.csv\n",
            "All files now up to date!\n",
            "Writing file 2 censors2.csv\n",
            "All files now up to date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VjURXnfxsKJ"
      },
      "source": [
        "Text = open(\"AllLyrics.txt\", \"r\").read()\n",
        "# turn text to lower case to reduce vocabulary\n",
        "Text = Text.lower()\n",
        "with open(\"AllLyrics.txt\", \"r\") as f:\n",
        "    content = f.readlines()\n",
        "# bars is a list containing each line in dataset in lowercase\n",
        "bars = [x.strip().lower() for x in content]\n",
        "stripped_bars = [word.split() for word in bars]\n",
        "# Vocabulary is a list of all words in the dataset\n",
        "Vocabulary = ''.join([i for i in Text if not i.isdigit()]).replace(\"\\n\",\" \").split(' ')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLpVvXPQ2rHL",
        "outputId": "81521467-bfa3-4751-b38f-024133a67761"
      },
      "source": [
        "# The numbers of bars in our dataset, 5283\n",
        "no_of_bars = len(bars)\n",
        "print(no_of_bars)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5283\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIRyjmQeyaAG"
      },
      "source": [
        "# word_count is a function creating a list of words ranked in order of most used\n",
        "# could think about removing certain words to create more accurate raps as model won't learn well from words used very infrequently\n",
        "def word_count(lyrics):\n",
        "  a = {}\n",
        "  for word in Vocabulary:\n",
        "    if word in a:\n",
        "      a[word] += 1\n",
        "    else:\n",
        "      a[word] = 1\n",
        "  return a\n",
        "word_dict = word_count(Vocabulary)\n",
        "sort_dict = sorted(word_dict.items(), key = lambda x: x[1], reverse = True)\n",
        "# Top 20 words\n",
        "sort_dict1 = sort_dict[:40]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIweRLWJqfax"
      },
      "source": [
        "# Need to create dictionary listing the words in alphabetical order so we can assign unique integers to each word\n",
        "# Neural networks take in integers, not words\n",
        "words = sorted(list(set(Vocabulary)))\n",
        "# Create a dictionary whereby we can convert integers into words\n",
        "word_to_int = { words[i] : i for i in range(len(words))}\n",
        "# Need to reverse this at the end to reverse numbers back into words\n",
        "int_to_word = { i : words[i] for i in range(len(words))}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzfKleYrygft"
      },
      "source": [
        "# create a function that converts bars into a sequence of unique integers\n",
        "def words_to_integers(bar, Vocabulary):\n",
        "  encode = []\n",
        "  # Need to strip bar into single list of words within bar\n",
        "  stripped_bar = [word.split() for word in bar]\n",
        "  for i in range(no_of_bars):\n",
        "    seq = []\n",
        "    seq.append([word_to_int[word] for word in stripped_bar[i]])\n",
        "    encode.append(seq)\n",
        "\n",
        "  encode = sum(encode, [])\n",
        "  return encode"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RHaklDv5tZN",
        "outputId": "1429bfa3-2771-400c-deca-803f71990412"
      },
      "source": [
        "# Number of unique words in our dataset\n",
        "vocab_size = len(words) + 1\n",
        "print(vocab_size)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiP3CQKQrIR7"
      },
      "source": [
        "# Define a function that converts sentences into a sequence of corresponding integers\n",
        "def sentence_to_integer(bar):\n",
        "    stripped_bar = [word.split() for word in [bar]]\n",
        "    stripped_bar = sum(stripped_bar, [])\n",
        "    seq = []\n",
        "    seq.append([word_to_int[word] for word in stripped_bar])\n",
        "    seq = sum(seq, [])\n",
        "    return seq"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2Log92J2ZdU"
      },
      "source": [
        "# Want to convert bars into n-grams of increasing length\n",
        "# So we start with the first two words and create lists of increasing length after adding the next word\n",
        "sequences = []\n",
        "for line in bars:\n",
        "    token_list = sentence_to_integer(line)\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_seq = token_list[:i+1]\n",
        "        sequences.append(n_gram_seq)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABAKPmzErRT_",
        "outputId": "1881526a-256b-4f2c-8e19-9a4ade77d2c0"
      },
      "source": [
        "# We need to pad each line so that each line is of equal length for our model\n",
        "# Thus need to find max length of a bar so we can pad all bars to this length\n",
        "padding_length = max([len(line) for line in sequences])\n",
        "print(padding_length)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PV9FBI_EsEQ"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "sequences = np.array(pad_sequences(sequences, maxlen = padding_length, padding = 'pre'))\n",
        "# Remove last word from each line\n",
        "x_train = sequences[:,:-1]\n",
        "# Last word is used as the label\n",
        "y_train = sequences[:,-1]\n",
        "# one hot encode the the outputs \n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes = vocab_size)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TJHjlEs52pt"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.3, random_state=1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWoLXV1Qr4E9",
        "outputId": "7e8bf03e-edce-46d7-b73f-5d4e6aca58be"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout, Bidirectional\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 256, input_length = padding_length - 1))\n",
        "model.add(Bidirectional(LSTM(128, return_sequences = True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(256)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(vocab_size, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 65, 256)           1296896   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 65, 256)           394240    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 65, 256)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 512)               1050624   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5066)              2598858   \n",
            "=================================================================\n",
            "Total params: 5,340,618\n",
            "Trainable params: 5,340,618\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar4UNHRZtBrp",
        "outputId": "701325f6-bd66-4d4c-b7eb-d39095d1d28a"
      },
      "source": [
        "history = model.fit(x_train, y_train, validation_split=0.15, epochs = 200, batch_size = 256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "96/96 [==============================] - 52s 194ms/step - loss: 7.2109 - accuracy: 0.0410 - val_loss: 6.4740 - val_accuracy: 0.0419\n",
            "Epoch 2/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 6.3294 - accuracy: 0.0505 - val_loss: 6.4133 - val_accuracy: 0.0437\n",
            "Epoch 3/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 6.1550 - accuracy: 0.0544 - val_loss: 6.3770 - val_accuracy: 0.0530\n",
            "Epoch 4/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 5.9794 - accuracy: 0.0662 - val_loss: 6.3316 - val_accuracy: 0.0621\n",
            "Epoch 5/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 5.8446 - accuracy: 0.0700 - val_loss: 6.3027 - val_accuracy: 0.0705\n",
            "Epoch 6/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 5.7104 - accuracy: 0.0760 - val_loss: 6.2626 - val_accuracy: 0.0735\n",
            "Epoch 7/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 5.5372 - accuracy: 0.0892 - val_loss: 6.2267 - val_accuracy: 0.0877\n",
            "Epoch 8/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 5.3969 - accuracy: 0.1036 - val_loss: 6.2059 - val_accuracy: 0.0928\n",
            "Epoch 9/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 5.2692 - accuracy: 0.1133 - val_loss: 6.1722 - val_accuracy: 0.0988\n",
            "Epoch 10/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 5.1249 - accuracy: 0.1266 - val_loss: 6.1443 - val_accuracy: 0.1140\n",
            "Epoch 11/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 5.0435 - accuracy: 0.1342 - val_loss: 6.1328 - val_accuracy: 0.1184\n",
            "Epoch 12/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 4.9011 - accuracy: 0.1491 - val_loss: 6.1239 - val_accuracy: 0.1288\n",
            "Epoch 13/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 4.7949 - accuracy: 0.1585 - val_loss: 6.0944 - val_accuracy: 0.1342\n",
            "Epoch 14/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 4.6832 - accuracy: 0.1720 - val_loss: 6.0584 - val_accuracy: 0.1460\n",
            "Epoch 15/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 4.5524 - accuracy: 0.1870 - val_loss: 6.0551 - val_accuracy: 0.1519\n",
            "Epoch 16/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 4.4391 - accuracy: 0.1950 - val_loss: 6.0334 - val_accuracy: 0.1598\n",
            "Epoch 17/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 4.3584 - accuracy: 0.2076 - val_loss: 6.0354 - val_accuracy: 0.1642\n",
            "Epoch 18/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 4.2446 - accuracy: 0.2155 - val_loss: 6.0317 - val_accuracy: 0.1688\n",
            "Epoch 19/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 4.1359 - accuracy: 0.2251 - val_loss: 6.0086 - val_accuracy: 0.1765\n",
            "Epoch 20/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 4.0333 - accuracy: 0.2454 - val_loss: 6.0193 - val_accuracy: 0.1795\n",
            "Epoch 21/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 3.9641 - accuracy: 0.2483 - val_loss: 6.0200 - val_accuracy: 0.1844\n",
            "Epoch 22/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 3.8566 - accuracy: 0.2624 - val_loss: 6.0221 - val_accuracy: 0.1847\n",
            "Epoch 23/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 3.7685 - accuracy: 0.2747 - val_loss: 6.0220 - val_accuracy: 0.1909\n",
            "Epoch 24/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 3.6900 - accuracy: 0.2863 - val_loss: 6.0272 - val_accuracy: 0.1928\n",
            "Epoch 25/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 3.5777 - accuracy: 0.3010 - val_loss: 6.0309 - val_accuracy: 0.1988\n",
            "Epoch 26/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 3.5063 - accuracy: 0.3104 - val_loss: 6.0448 - val_accuracy: 0.2026\n",
            "Epoch 27/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 3.4294 - accuracy: 0.3234 - val_loss: 6.0401 - val_accuracy: 0.2074\n",
            "Epoch 28/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 3.3593 - accuracy: 0.3360 - val_loss: 6.0461 - val_accuracy: 0.2079\n",
            "Epoch 29/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 3.2766 - accuracy: 0.3433 - val_loss: 6.0623 - val_accuracy: 0.2142\n",
            "Epoch 30/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 3.2032 - accuracy: 0.3599 - val_loss: 6.0538 - val_accuracy: 0.2160\n",
            "Epoch 31/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 3.1335 - accuracy: 0.3728 - val_loss: 6.0708 - val_accuracy: 0.2242\n",
            "Epoch 32/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 3.0491 - accuracy: 0.3869 - val_loss: 6.0817 - val_accuracy: 0.2242\n",
            "Epoch 33/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 3.0197 - accuracy: 0.3833 - val_loss: 6.1065 - val_accuracy: 0.2281\n",
            "Epoch 34/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 2.9463 - accuracy: 0.4014 - val_loss: 6.1077 - val_accuracy: 0.2312\n",
            "Epoch 35/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 2.8716 - accuracy: 0.4116 - val_loss: 6.1228 - val_accuracy: 0.2286\n",
            "Epoch 36/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 2.8105 - accuracy: 0.4241 - val_loss: 6.1472 - val_accuracy: 0.2374\n",
            "Epoch 37/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 2.7575 - accuracy: 0.4319 - val_loss: 6.1669 - val_accuracy: 0.2430\n",
            "Epoch 38/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 2.7003 - accuracy: 0.4387 - val_loss: 6.1612 - val_accuracy: 0.2447\n",
            "Epoch 39/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 2.6713 - accuracy: 0.4494 - val_loss: 6.1943 - val_accuracy: 0.2465\n",
            "Epoch 40/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 2.5972 - accuracy: 0.4626 - val_loss: 6.2082 - val_accuracy: 0.2502\n",
            "Epoch 41/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 2.5589 - accuracy: 0.4690 - val_loss: 6.2249 - val_accuracy: 0.2523\n",
            "Epoch 42/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 2.5306 - accuracy: 0.4710 - val_loss: 6.2398 - val_accuracy: 0.2519\n",
            "Epoch 43/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 2.4422 - accuracy: 0.4890 - val_loss: 6.2574 - val_accuracy: 0.2572\n",
            "Epoch 44/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 2.3855 - accuracy: 0.5017 - val_loss: 6.2691 - val_accuracy: 0.2588\n",
            "Epoch 45/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 2.3785 - accuracy: 0.5017 - val_loss: 6.2980 - val_accuracy: 0.2581\n",
            "Epoch 46/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 2.3077 - accuracy: 0.5112 - val_loss: 6.3110 - val_accuracy: 0.2637\n",
            "Epoch 47/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 2.2640 - accuracy: 0.5207 - val_loss: 6.3300 - val_accuracy: 0.2586\n",
            "Epoch 48/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 2.2351 - accuracy: 0.5278 - val_loss: 6.3593 - val_accuracy: 0.2600\n",
            "Epoch 49/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 2.1793 - accuracy: 0.5374 - val_loss: 6.3773 - val_accuracy: 0.2667\n",
            "Epoch 50/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 2.1694 - accuracy: 0.5335 - val_loss: 6.3869 - val_accuracy: 0.2677\n",
            "Epoch 51/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 2.1363 - accuracy: 0.5473 - val_loss: 6.4146 - val_accuracy: 0.2719\n",
            "Epoch 52/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 2.0603 - accuracy: 0.5597 - val_loss: 6.4399 - val_accuracy: 0.2728\n",
            "Epoch 53/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 2.0454 - accuracy: 0.5639 - val_loss: 6.4745 - val_accuracy: 0.2723\n",
            "Epoch 54/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 1.9904 - accuracy: 0.5739 - val_loss: 6.4635 - val_accuracy: 0.2770\n",
            "Epoch 55/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 1.9754 - accuracy: 0.5685 - val_loss: 6.4969 - val_accuracy: 0.2758\n",
            "Epoch 56/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 1.9619 - accuracy: 0.5792 - val_loss: 6.5214 - val_accuracy: 0.2772\n",
            "Epoch 57/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.9061 - accuracy: 0.5845 - val_loss: 6.5307 - val_accuracy: 0.2830\n",
            "Epoch 58/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.8748 - accuracy: 0.5926 - val_loss: 6.5671 - val_accuracy: 0.2798\n",
            "Epoch 59/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.8519 - accuracy: 0.5956 - val_loss: 6.5907 - val_accuracy: 0.2807\n",
            "Epoch 60/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.8159 - accuracy: 0.6066 - val_loss: 6.5901 - val_accuracy: 0.2807\n",
            "Epoch 61/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.8047 - accuracy: 0.6059 - val_loss: 6.6290 - val_accuracy: 0.2849\n",
            "Epoch 62/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.7684 - accuracy: 0.6127 - val_loss: 6.6713 - val_accuracy: 0.2842\n",
            "Epoch 63/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 1.7218 - accuracy: 0.6254 - val_loss: 6.6746 - val_accuracy: 0.2877\n",
            "Epoch 64/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 1.7041 - accuracy: 0.6271 - val_loss: 6.7057 - val_accuracy: 0.2860\n",
            "Epoch 65/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 1.7001 - accuracy: 0.6250 - val_loss: 6.7370 - val_accuracy: 0.2830\n",
            "Epoch 66/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 1.6638 - accuracy: 0.6352 - val_loss: 6.7430 - val_accuracy: 0.2856\n",
            "Epoch 67/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 1.6517 - accuracy: 0.6355 - val_loss: 6.7654 - val_accuracy: 0.2902\n",
            "Epoch 68/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 1.6178 - accuracy: 0.6407 - val_loss: 6.7922 - val_accuracy: 0.2884\n",
            "Epoch 69/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.6189 - accuracy: 0.6384 - val_loss: 6.8068 - val_accuracy: 0.2947\n",
            "Epoch 70/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.5798 - accuracy: 0.6486 - val_loss: 6.8271 - val_accuracy: 0.2921\n",
            "Epoch 71/200\n",
            "96/96 [==============================] - 17s 175ms/step - loss: 1.5575 - accuracy: 0.6508 - val_loss: 6.8609 - val_accuracy: 0.2916\n",
            "Epoch 72/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.5152 - accuracy: 0.6582 - val_loss: 6.8802 - val_accuracy: 0.2886\n",
            "Epoch 73/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.4933 - accuracy: 0.6662 - val_loss: 6.8942 - val_accuracy: 0.2942\n",
            "Epoch 74/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.4923 - accuracy: 0.6659 - val_loss: 6.9259 - val_accuracy: 0.2912\n",
            "Epoch 75/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 1.4537 - accuracy: 0.6703 - val_loss: 6.9445 - val_accuracy: 0.2953\n",
            "Epoch 76/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.4407 - accuracy: 0.6791 - val_loss: 6.9818 - val_accuracy: 0.2963\n",
            "Epoch 77/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.4260 - accuracy: 0.6788 - val_loss: 6.9863 - val_accuracy: 0.2986\n",
            "Epoch 78/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.4022 - accuracy: 0.6843 - val_loss: 7.0260 - val_accuracy: 0.2986\n",
            "Epoch 79/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.3798 - accuracy: 0.6875 - val_loss: 7.0356 - val_accuracy: 0.2991\n",
            "Epoch 80/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 1.4037 - accuracy: 0.6847 - val_loss: 7.0594 - val_accuracy: 0.3002\n",
            "Epoch 81/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 1.3414 - accuracy: 0.6968 - val_loss: 7.0976 - val_accuracy: 0.2970\n",
            "Epoch 82/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 1.3356 - accuracy: 0.6951 - val_loss: 7.1177 - val_accuracy: 0.3014\n",
            "Epoch 83/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 1.3012 - accuracy: 0.7055 - val_loss: 7.1319 - val_accuracy: 0.3014\n",
            "Epoch 84/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 1.3190 - accuracy: 0.6981 - val_loss: 7.1358 - val_accuracy: 0.3047\n",
            "Epoch 85/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.2661 - accuracy: 0.7134 - val_loss: 7.1709 - val_accuracy: 0.3012\n",
            "Epoch 86/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 1.2742 - accuracy: 0.7051 - val_loss: 7.2002 - val_accuracy: 0.3019\n",
            "Epoch 87/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.2474 - accuracy: 0.7203 - val_loss: 7.2275 - val_accuracy: 0.3021\n",
            "Epoch 88/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 1.2332 - accuracy: 0.7175 - val_loss: 7.2302 - val_accuracy: 0.3056\n",
            "Epoch 89/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.2292 - accuracy: 0.7162 - val_loss: 7.2703 - val_accuracy: 0.3014\n",
            "Epoch 90/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 1.2168 - accuracy: 0.7189 - val_loss: 7.3024 - val_accuracy: 0.3042\n",
            "Epoch 91/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 1.1928 - accuracy: 0.7213 - val_loss: 7.3107 - val_accuracy: 0.3065\n",
            "Epoch 92/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 1.1743 - accuracy: 0.7260 - val_loss: 7.3302 - val_accuracy: 0.3040\n",
            "Epoch 93/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 1.1700 - accuracy: 0.7312 - val_loss: 7.3584 - val_accuracy: 0.3074\n",
            "Epoch 94/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 1.1592 - accuracy: 0.7295 - val_loss: 7.3656 - val_accuracy: 0.3091\n",
            "Epoch 95/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.1267 - accuracy: 0.7373 - val_loss: 7.3907 - val_accuracy: 0.3044\n",
            "Epoch 96/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.1592 - accuracy: 0.7326 - val_loss: 7.4273 - val_accuracy: 0.3074\n",
            "Epoch 97/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.1213 - accuracy: 0.7407 - val_loss: 7.4373 - val_accuracy: 0.3093\n",
            "Epoch 98/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 1.0982 - accuracy: 0.7416 - val_loss: 7.4612 - val_accuracy: 0.3088\n",
            "Epoch 99/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 1.0896 - accuracy: 0.7448 - val_loss: 7.4985 - val_accuracy: 0.3067\n",
            "Epoch 100/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 1.0689 - accuracy: 0.7513 - val_loss: 7.5055 - val_accuracy: 0.3119\n",
            "Epoch 101/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.0688 - accuracy: 0.7491 - val_loss: 7.5106 - val_accuracy: 0.3091\n",
            "Epoch 102/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.0611 - accuracy: 0.7518 - val_loss: 7.5621 - val_accuracy: 0.3077\n",
            "Epoch 103/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.0587 - accuracy: 0.7504 - val_loss: 7.5865 - val_accuracy: 0.3102\n",
            "Epoch 104/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.0284 - accuracy: 0.7566 - val_loss: 7.6175 - val_accuracy: 0.3119\n",
            "Epoch 105/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 1.0497 - accuracy: 0.7528 - val_loss: 7.6265 - val_accuracy: 0.3126\n",
            "Epoch 106/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 1.0122 - accuracy: 0.7579 - val_loss: 7.6417 - val_accuracy: 0.3126\n",
            "Epoch 107/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 1.0014 - accuracy: 0.7667 - val_loss: 7.6680 - val_accuracy: 0.3130\n",
            "Epoch 108/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 0.9858 - accuracy: 0.7685 - val_loss: 7.6810 - val_accuracy: 0.3135\n",
            "Epoch 109/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 0.9891 - accuracy: 0.7659 - val_loss: 7.7236 - val_accuracy: 0.3116\n",
            "Epoch 110/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 0.9463 - accuracy: 0.7719 - val_loss: 7.7531 - val_accuracy: 0.3112\n",
            "Epoch 111/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 0.9703 - accuracy: 0.7707 - val_loss: 7.7185 - val_accuracy: 0.3133\n",
            "Epoch 112/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 0.9687 - accuracy: 0.7661 - val_loss: 7.7543 - val_accuracy: 0.3144\n",
            "Epoch 113/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 0.9415 - accuracy: 0.7766 - val_loss: 7.7811 - val_accuracy: 0.3170\n",
            "Epoch 114/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 0.9370 - accuracy: 0.7749 - val_loss: 7.8182 - val_accuracy: 0.3156\n",
            "Epoch 115/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 0.9434 - accuracy: 0.7747 - val_loss: 7.8289 - val_accuracy: 0.3167\n",
            "Epoch 116/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 0.9119 - accuracy: 0.7819 - val_loss: 7.8226 - val_accuracy: 0.3144\n",
            "Epoch 117/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 0.9172 - accuracy: 0.7776 - val_loss: 7.8539 - val_accuracy: 0.3151\n",
            "Epoch 118/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.8972 - accuracy: 0.7833 - val_loss: 7.8706 - val_accuracy: 0.3165\n",
            "Epoch 119/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 0.8974 - accuracy: 0.7841 - val_loss: 7.9196 - val_accuracy: 0.3179\n",
            "Epoch 120/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 0.8947 - accuracy: 0.7833 - val_loss: 7.9470 - val_accuracy: 0.3170\n",
            "Epoch 121/200\n",
            "96/96 [==============================] - 17s 176ms/step - loss: 0.8717 - accuracy: 0.7872 - val_loss: 7.9552 - val_accuracy: 0.3144\n",
            "Epoch 122/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.8621 - accuracy: 0.7909 - val_loss: 7.9596 - val_accuracy: 0.3198\n",
            "Epoch 123/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.8789 - accuracy: 0.7877 - val_loss: 7.9799 - val_accuracy: 0.3195\n",
            "Epoch 124/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.8707 - accuracy: 0.7869 - val_loss: 8.0169 - val_accuracy: 0.3165\n",
            "Epoch 125/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.8631 - accuracy: 0.7932 - val_loss: 8.0351 - val_accuracy: 0.3191\n",
            "Epoch 126/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.8450 - accuracy: 0.7906 - val_loss: 8.0629 - val_accuracy: 0.3200\n",
            "Epoch 127/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.8284 - accuracy: 0.7988 - val_loss: 8.0968 - val_accuracy: 0.3191\n",
            "Epoch 128/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.8317 - accuracy: 0.7992 - val_loss: 8.0974 - val_accuracy: 0.3207\n",
            "Epoch 129/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.8013 - accuracy: 0.8074 - val_loss: 8.1245 - val_accuracy: 0.3172\n",
            "Epoch 130/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.8179 - accuracy: 0.8006 - val_loss: 8.1619 - val_accuracy: 0.3179\n",
            "Epoch 131/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.8176 - accuracy: 0.7977 - val_loss: 8.1636 - val_accuracy: 0.3193\n",
            "Epoch 132/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.8043 - accuracy: 0.8012 - val_loss: 8.1528 - val_accuracy: 0.3226\n",
            "Epoch 133/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.8032 - accuracy: 0.8037 - val_loss: 8.1921 - val_accuracy: 0.3172\n",
            "Epoch 134/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.7834 - accuracy: 0.8055 - val_loss: 8.2068 - val_accuracy: 0.3179\n",
            "Epoch 135/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.8083 - accuracy: 0.8025 - val_loss: 8.2321 - val_accuracy: 0.3179\n",
            "Epoch 136/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.7784 - accuracy: 0.8058 - val_loss: 8.2307 - val_accuracy: 0.3202\n",
            "Epoch 137/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.7683 - accuracy: 0.8136 - val_loss: 8.2688 - val_accuracy: 0.3202\n",
            "Epoch 138/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.7618 - accuracy: 0.8106 - val_loss: 8.2686 - val_accuracy: 0.3172\n",
            "Epoch 139/200\n",
            "96/96 [==============================] - 17s 179ms/step - loss: 0.7505 - accuracy: 0.8136 - val_loss: 8.3022 - val_accuracy: 0.3174\n",
            "Epoch 140/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.7697 - accuracy: 0.8054 - val_loss: 8.3237 - val_accuracy: 0.3207\n",
            "Epoch 141/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.7544 - accuracy: 0.8126 - val_loss: 8.3466 - val_accuracy: 0.3177\n",
            "Epoch 142/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.7411 - accuracy: 0.8128 - val_loss: 8.3690 - val_accuracy: 0.3200\n",
            "Epoch 143/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.7471 - accuracy: 0.8142 - val_loss: 8.3665 - val_accuracy: 0.3163\n",
            "Epoch 144/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.7416 - accuracy: 0.8159 - val_loss: 8.4149 - val_accuracy: 0.3179\n",
            "Epoch 145/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.7069 - accuracy: 0.8227 - val_loss: 8.4330 - val_accuracy: 0.3226\n",
            "Epoch 146/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.7258 - accuracy: 0.8188 - val_loss: 8.4340 - val_accuracy: 0.3207\n",
            "Epoch 147/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.7185 - accuracy: 0.8182 - val_loss: 8.4625 - val_accuracy: 0.3216\n",
            "Epoch 148/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.7046 - accuracy: 0.8239 - val_loss: 8.4702 - val_accuracy: 0.3216\n",
            "Epoch 149/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.7051 - accuracy: 0.8253 - val_loss: 8.4890 - val_accuracy: 0.3237\n",
            "Epoch 150/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.7024 - accuracy: 0.8259 - val_loss: 8.5111 - val_accuracy: 0.3216\n",
            "Epoch 151/200\n",
            "96/96 [==============================] - 17s 179ms/step - loss: 0.7003 - accuracy: 0.8232 - val_loss: 8.5240 - val_accuracy: 0.3219\n",
            "Epoch 152/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.6980 - accuracy: 0.8234 - val_loss: 8.5368 - val_accuracy: 0.3202\n",
            "Epoch 153/200\n",
            "96/96 [==============================] - 17s 179ms/step - loss: 0.6787 - accuracy: 0.8297 - val_loss: 8.5500 - val_accuracy: 0.3202\n",
            "Epoch 154/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.6824 - accuracy: 0.8294 - val_loss: 8.5798 - val_accuracy: 0.3188\n",
            "Epoch 155/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.6737 - accuracy: 0.8288 - val_loss: 8.5898 - val_accuracy: 0.3247\n",
            "Epoch 156/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.6964 - accuracy: 0.8234 - val_loss: 8.6070 - val_accuracy: 0.3228\n",
            "Epoch 157/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.6709 - accuracy: 0.8302 - val_loss: 8.6196 - val_accuracy: 0.3221\n",
            "Epoch 158/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.6624 - accuracy: 0.8346 - val_loss: 8.6443 - val_accuracy: 0.3202\n",
            "Epoch 159/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.6630 - accuracy: 0.8327 - val_loss: 8.6644 - val_accuracy: 0.3193\n",
            "Epoch 160/200\n",
            "96/96 [==============================] - 17s 179ms/step - loss: 0.6561 - accuracy: 0.8338 - val_loss: 8.6826 - val_accuracy: 0.3216\n",
            "Epoch 161/200\n",
            "96/96 [==============================] - 17s 179ms/step - loss: 0.6628 - accuracy: 0.8286 - val_loss: 8.6693 - val_accuracy: 0.3228\n",
            "Epoch 162/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.6623 - accuracy: 0.8319 - val_loss: 8.6991 - val_accuracy: 0.3223\n",
            "Epoch 163/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.6526 - accuracy: 0.8336 - val_loss: 8.7030 - val_accuracy: 0.3228\n",
            "Epoch 164/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.6225 - accuracy: 0.8424 - val_loss: 8.7235 - val_accuracy: 0.3223\n",
            "Epoch 165/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.6336 - accuracy: 0.8393 - val_loss: 8.7474 - val_accuracy: 0.3200\n",
            "Epoch 166/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.6295 - accuracy: 0.8389 - val_loss: 8.7775 - val_accuracy: 0.3200\n",
            "Epoch 167/200\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.6042 - accuracy: 0.8474 - val_loss: 8.7994 - val_accuracy: 0.3186\n",
            "Epoch 168/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.6279 - accuracy: 0.8389 - val_loss: 8.8225 - val_accuracy: 0.3219\n",
            "Epoch 169/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.6211 - accuracy: 0.8390 - val_loss: 8.8238 - val_accuracy: 0.3247\n",
            "Epoch 170/200\n",
            "96/96 [==============================] - 17s 179ms/step - loss: 0.6065 - accuracy: 0.8473 - val_loss: 8.8428 - val_accuracy: 0.3214\n",
            "Epoch 171/200\n",
            "96/96 [==============================] - 17s 180ms/step - loss: 0.6074 - accuracy: 0.8443 - val_loss: 8.8671 - val_accuracy: 0.3235\n",
            "Epoch 172/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.6277 - accuracy: 0.8392 - val_loss: 8.8647 - val_accuracy: 0.3223\n",
            "Epoch 173/200\n",
            "96/96 [==============================] - 17s 179ms/step - loss: 0.6151 - accuracy: 0.8431 - val_loss: 8.8500 - val_accuracy: 0.3209\n",
            "Epoch 174/200\n",
            "96/96 [==============================] - 17s 180ms/step - loss: 0.6264 - accuracy: 0.8371 - val_loss: 8.9296 - val_accuracy: 0.3209\n",
            "Epoch 175/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.6008 - accuracy: 0.8446 - val_loss: 8.9290 - val_accuracy: 0.3256\n",
            "Epoch 176/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.6225 - accuracy: 0.8430 - val_loss: 8.9086 - val_accuracy: 0.3249\n",
            "Epoch 177/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.6036 - accuracy: 0.8402 - val_loss: 8.9596 - val_accuracy: 0.3216\n",
            "Epoch 178/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.5904 - accuracy: 0.8443 - val_loss: 8.9560 - val_accuracy: 0.3200\n",
            "Epoch 179/200\n",
            "96/96 [==============================] - 17s 179ms/step - loss: 0.6089 - accuracy: 0.8412 - val_loss: 8.9580 - val_accuracy: 0.3219\n",
            "Epoch 180/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.5926 - accuracy: 0.8466 - val_loss: 9.0192 - val_accuracy: 0.3228\n",
            "Epoch 181/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.5873 - accuracy: 0.8477 - val_loss: 9.0526 - val_accuracy: 0.3247\n",
            "Epoch 182/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.5767 - accuracy: 0.8482 - val_loss: 9.0034 - val_accuracy: 0.3244\n",
            "Epoch 183/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.5671 - accuracy: 0.8517 - val_loss: 9.0405 - val_accuracy: 0.3247\n",
            "Epoch 184/200\n",
            "96/96 [==============================] - 17s 180ms/step - loss: 0.5907 - accuracy: 0.8460 - val_loss: 9.0289 - val_accuracy: 0.3228\n",
            "Epoch 185/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.5827 - accuracy: 0.8480 - val_loss: 9.0424 - val_accuracy: 0.3214\n",
            "Epoch 186/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.5703 - accuracy: 0.8515 - val_loss: 9.0699 - val_accuracy: 0.3253\n",
            "Epoch 187/200\n",
            "96/96 [==============================] - 17s 179ms/step - loss: 0.5681 - accuracy: 0.8512 - val_loss: 9.1179 - val_accuracy: 0.3270\n",
            "Epoch 188/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.5736 - accuracy: 0.8478 - val_loss: 9.0911 - val_accuracy: 0.3251\n",
            "Epoch 189/200\n",
            "96/96 [==============================] - 17s 178ms/step - loss: 0.5530 - accuracy: 0.8549 - val_loss: 9.1374 - val_accuracy: 0.3247\n",
            "Epoch 190/200\n",
            "96/96 [==============================] - 17s 179ms/step - loss: 0.5693 - accuracy: 0.8487 - val_loss: 9.1360 - val_accuracy: 0.3253\n",
            "Epoch 191/200\n",
            "96/96 [==============================] - 17s 179ms/step - loss: 0.5593 - accuracy: 0.8516 - val_loss: 9.1396 - val_accuracy: 0.3233\n",
            "Epoch 192/200\n",
            "96/96 [==============================] - 17s 179ms/step - loss: 0.5435 - accuracy: 0.8563 - val_loss: 9.1542 - val_accuracy: 0.3253\n",
            "Epoch 193/200\n",
            "96/96 [==============================] - 17s 179ms/step - loss: 0.5468 - accuracy: 0.8558 - val_loss: 9.1509 - val_accuracy: 0.3247\n",
            "Epoch 194/200\n",
            "96/96 [==============================] - 17s 179ms/step - loss: 0.5584 - accuracy: 0.8525 - val_loss: 9.1821 - val_accuracy: 0.3247\n",
            "Epoch 195/200\n",
            "96/96 [==============================] - 17s 179ms/step - loss: 0.5575 - accuracy: 0.8533 - val_loss: 9.1727 - val_accuracy: 0.3247\n",
            "Epoch 196/200\n",
            "96/96 [==============================] - 17s 179ms/step - loss: 0.5428 - accuracy: 0.8597 - val_loss: 9.2124 - val_accuracy: 0.3256\n",
            "Epoch 197/200\n",
            "96/96 [==============================] - 17s 179ms/step - loss: 0.5496 - accuracy: 0.8569 - val_loss: 9.2239 - val_accuracy: 0.3237\n",
            "Epoch 198/200\n",
            "96/96 [==============================] - 17s 179ms/step - loss: 0.5483 - accuracy: 0.8566 - val_loss: 9.2775 - val_accuracy: 0.3247\n",
            "Epoch 199/200\n",
            "96/96 [==============================] - 17s 179ms/step - loss: 0.5357 - accuracy: 0.8573 - val_loss: 9.2410 - val_accuracy: 0.3237\n",
            "Epoch 200/200\n",
            "96/96 [==============================] - 17s 179ms/step - loss: 0.5426 - accuracy: 0.8564 - val_loss: 9.2750 - val_accuracy: 0.3237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8VUqslB6kMO",
        "outputId": "9ce3e735-afa2-407b-80c7-cb23ce65ac69"
      },
      "source": [
        "# Saving our model\n",
        "model.save('/content/drive/MyDrive/lstm-basic-validation')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/lstm-basic-validation/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/lstm-basic-validation/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ImBWp2JQtHYW",
        "outputId": "e8aa3dd8-66ba-478f-c808-23b029eba4c3"
      },
      "source": [
        "# Plotting a loss curve to see if we need this many epochs\n",
        "# Looks to still be decreasing slowly\n",
        "loss_train = history.history['loss']\n",
        "loss_val = history.history['val_loss']\n",
        "epochs = range(200)\n",
        "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUVfrA8e+bQjpJCJ0ACQhIiwGiIgEpKiIqAqLgoqDY18bqqtjRtcu6iIu6+LOgqGADEetKRxSliSBFgQChhpBKEpgk5/fHmWQDEkggkzuZvJ/nmSd37ty59507k3fOnHuKGGNQSinle/ycDkAppZRnaIJXSikfpQleKaV8lCZ4pZTyUZrglVLKR2mCV0opH6UJXlWIiHwlIqOrelsniUiKiJzvgf0uEJEb3MsjReTbimx7EsdpISK5IuJ/srEeZ99GRE6r6v2q6qUJ3oe5//lLbsUikl/m/sjK7MsYc5ExZmpVb+uNRGSciCw6xvr6InJYRDpVdF/GmPeMMf2rKK4jvpCMMduNMeHGmKKq2L/yPZrgfZj7nz/cGBMObAcuLbPuvZLtRCTAuSi90jSgh4jEH7V+BPCrMWatAzEpVWma4GshEekjIqkicr+I7AHeEpFoEZkjImkikuFeji3znLLVDteKyBIRmeDedquIXHSS28aLyCIRyRGR70RksohMKyfuisT4DxH53r2/b0WkfpnHrxGRbSKSLiIPlXd+jDGpwDzgmqMeGgW8c6I4jor5WhFZUub+BSKyQUSyROTfgJR5rLWIzHPHt19E3hORKPdj7wItgM/dv8DuE5E4d1VKgHubpiIyW0QOiMgfInJjmX2PF5EPReQd97lZJyJJ5Z2Do15DpPt5ae7z97CI+LkfO01EFrpfz34RmeFeLyLyLxHZJyLZIvJrZX75qKqhCb72agzUA1oCN2E/C2+577cA8oF/H+f5ZwMbgfrA88AbIiInse37wE9ADDCePyfVsioS41+A64CGQB3g7wAi0gF41b3/pu7jHTMpu00tG4uItAMS3fFW9lyV7KM+8CnwMPZcbAaSy24CPOOOrz3QHHtOMMZcw5G/wp4/xiGmA6nu5w8DnhaRfmUeH+TeJgqYXZGY3V4GIoFWQG/sF9117sf+AXwLRGPP58vu9f2Bc4G27udeCaRX8Hiqqhhj9FYLbkAKcL57uQ9wGAg+zvaJQEaZ+wuAG9zL1wJ/lHksFDBA48psi02OhUBomcenAdMq+JqOFePDZe7/FfjavfwoML3MY2Huc3B+OfsOBbKBHu77TwGfneS5WuJeHgX8WGY7wSbkG8rZ72Bg1bHeQ/f9OPe5DMB+GRQBEWUefwZ42708HviuzGMdgPzjnFsDnAb4u89ThzKP3QwscC+/A0wBYo96fj9gE9Ad8HP6819bb1qCr73SjDEFJXdEJFRE/uP+CZ4NLAKipPwWGntKFowxee7F8Epu2xQ4UGYdwI7yAq5gjHvKLOeVialp2X0bYw5ynBKlO6aPgFHuXxsjscnsZM5ViaNjMGXvi0gjEZkuIjvd+52GLelXRMm5zCmzbhvQrMz9o89NsJz4+kt9INC9r2Pt9z7sF9VP7mqfMe7XNg/7C2EysE9EpohI3Qq+FlVFNMHXXkcPI3oP0A442xhTF/vzGsrUEXvAbqCeiISWWdf8ONufSoy7y+7bfcyYEzxnKrZq4QIgAvj8FOM4OgbhyNf7NPZ96eze79VH7fN4Q7/uwp7LiDLrWgA7TxDTiewHXNjqqD/t1xizxxhzozGmKbZk/4q4m1caYyYZY7phfy20Be49xVhUJWmCVyUisHXJmSJSD3jM0wc0xmwDlgPjRaSOiJwDXOqhGD8GLhGRniJSB3iCE3/+FwOZ2CqI6caYw6cYxxdARxEZ6i4534mtqioRAeQCWSLSjD8nxL3YevA/McbsAJYCz4hIsIgkANdjfwWcNGObYH4IPCUiESLSEri7ZL8ickWZC8wZ2C+hYhE5U0TOFpFA4CBQABSfSiyq8jTBqxITgRBsie1H4OtqOu5I4BxsdcmTwAzgUDnbnnSMxph1wG3Yi6S7scko9QTPMdhqmZbuv6cUhzFmP3AF8Cz29bYBvi+zyeNAVyAL+2Xw6VG7eAZ4WEQyReTvxzjEVdh6+V3ATOAxY8x3FYntBO7AJuktwBLsOXzT/diZwDIRycVeuL3LGLMFqAu8jj3P27Cv94UqiEVVgrgviCjlFdzN7DYYYzz+C0IpX6cleOUo90/51iLiJyIDgMuAWU7HpZQv0B6MymmNsVURMdgqk1uNMaucDUkp36BVNEop5aO0ikYppXyUV1XR1K9f38TFxTkdhlJK1RgrVqzYb4xpcKzHvCrBx8XFsXz5cqfDUEqpGkNEtpX3mFbRKKWUj9IEr5RSPkoTvFJK+SivqoM/FpfLRWpqKgUFBSfeWDkmODiY2NhYAgMDnQ5FKeXm9Qk+NTWViIgI4uLiKH8+CeUkYwzp6emkpqYSH3/0LHdKKad4fRVNQUEBMTExmty9mIgQExOjv7KU8jJen+ABTe41gL5HSnmfGpHglVLKl3z/PUybBoWFsGwZvPKKZ46jCf440tPTSUxMJDExkcaNG9OsWbPS+4cPHz7uc5cvX86dd955wmP06NGjSmJdsGABl1xySZXsSylV9YyBlBR49lk491y45hpo1gy6d4cnn4T8/Ko/ptdfZHVSTEwMq1evBmD8+PGEh4fz97//b56FwsJCAgKOfQqTkpJISko64TGWLl1aNcEqpbzO6tWwZw8UFcEDD8Cvv9r1l18OV14Jb70FvXvD7bdDSEjVH18TfCVde+21BAcHs2rVKpKTkxkxYgR33XUXBQUFhISE8NZbb9GuXTsWLFjAhAkTmDNnDuPHj2f79u1s2bKF7du3M3bs2NLSfXh4OLm5uSxYsIDx48dTv3591q5dS7du3Zg2bRoiwpdffsndd99NWFgYycnJbNmyhTlz5pQb44EDBxgzZgxbtmwhNDSUKVOmkJCQwMKFC7nrrrsAW2e+aNEicnNzGT58ONnZ2RQWFvLqq6/Sq1evajmXStV0OTkwd65dPnzYJvOff7br9++3VTEl4uLg3/+Gbt3g7LNBxCZ5T6pRCX7s12NZvWd1le4zsXEiEwdMrNRzUlNTWbp0Kf7+/mRnZ7N48WICAgL47rvvePDBB/nkk0/+9JwNGzYwf/58cnJyaNeuHbfeeuuf2oyvWrWKdevW0bRpU5KTk/n+++9JSkri5ptvZtGiRcTHx3PVVVedML7HHnuMLl26MGvWLObNm8eoUaNYvXo1EyZMYPLkySQnJ5Obm0twcDBTpkzhwgsv5KGHHqKoqIi8vLxKnQulahOXy1anfPMNXHCBrUdPSTlym6ZNoUEDWyXzwgtw1lmQng4DBnimlH48NSrBe4srrrgCf39/ALKyshg9ejS///47IoLL5Trmcy6++GKCgoIICgqiYcOG7N27l9jY2CO2Oeuss0rXJSYmkpKSQnh4OK1atSptX37VVVcxZcqU48a3ZMmS0i+Zfv36kZ6eTnZ2NsnJydx9992MHDmSoUOHEhsby5lnnsmYMWNwuVwMHjyYxMTEUzo3StVkK1bAwYO2jrywEDIzISYGsrPh88/hn/+01S7t29tE37o1fPUVNGoEQUFQrx40bnzi41SXGpXgK1vS9pSwsLDS5UceeYS+ffsyc+ZMUlJS6NOnzzGfExQUVLrs7+9PYWHhSW1zKsaNG8fFF1/Ml19+SXJyMt988w3nnnsuixYt4osvvuDaa6/l7rvvZtSoUVV6XKW83Z49cP318OWX9v4119jqlS1bIDISsrLs+jZt4KOPYNgw2LXLJvTgYOfiPpEaleC9UVZWFs2aNQPg7bffrvL9t2vXji1btpCSkkJcXBwzZsw44XN69erFe++9xyOPPMKCBQuoX78+devWZfPmzXTu3JnOnTvz888/s2HDBkJCQoiNjeXGG2/k0KFDrFy5UhO88nkpKbBhA4SFQW6uvci5Zw888wzs3QsTJ0LnzrbFy7ZtEBsLycnQqxf4udseNm3q6EuoEE3wp+i+++5j9OjRPPnkk1x88cVVvv+QkBBeeeUVBgwYQFhYGGeeeeYJnzN+/HjGjBlDQkICoaGhTJ06FYCJEycyf/58/Pz86NixIxdddBHTp0/nhRdeIDAwkPDwcN55550qfw1KOWnrVlsXXlAAbdtCaCiMG3dks8SYGJg3z178BBg71iZ1d01sjeVVc7ImJSWZoyf8WL9+Pe3bt3coIu+Qm5tLeHg4xhhuu+022rRpw9/+9jenw/oTfa+UN0hJsXXn0dEQEQHnnAPbt9skvnOn3aZfP3jsMdvyJTAQOnSwF0ZrIhFZYYw5ZptsLcHXAK+//jpTp07l8OHDdOnShZtvvtnpkJTyCgcPwvr19u/SpTBzpm2mWKJOHft37lzo2dMm+I0bbdvzml46rwhN8DXA3/72N68ssSvlhLw8mDPHXuz84osjq1q6dYMJE6BVK1uXvno1XHaZTe5ge466L5nVCprglVJezxj47Td4/334z39su/JGjeC66+D88+3F0s6doUkTpyP1LprglVJeo+wlwaVLYfly2xxx9mzb6kXElshvvx369Kkd1SynQhO8UspRaWm2Z+jXX9u/Lhc0bAi//24f9/OzdeZ33AFDhmgpvTI0wSulqlV+PixZAv/9r725x/OjQQPbnT883DZtvPtuOyhXdDSUM6afOgEdLtgDwsPDAdi1axfDhg075jZ9+vTh6CahR5s4ceIRY8MMHDiQzMzMU45v/PjxTJgw4ZT3o1RFrVwJN9wAiYk2YffvbzsTRUbaLv8//2w7Gr37Lrz6qi3N33KLTfqa3E+enjoPatq0KR9//PFJP3/ixIlcffXVhIaGAvBlST9qpbxYXp7t5r9kiU3sq1bZ5onh4XaMlwsugL597bK7LKQ8REvwJzBu3DgmT55cer+k9Jubm8t5551H165d6dy5M5999tmfnpuSkkKnTp0AyM/PZ8SIEbRv354hQ4aQX6Zt16233kpSUhIdO3bkscceA2DSpEns2rWLvn370rdvXwDi4uLYv38/AC+++CKdOnWiU6dOTJw4sfR47du358Ybb6Rjx47079//iOMcy+rVq+nevTsJCQkMGTKEjIyM0uN36NCBhIQERowYAcDChQtLJzzp0qULOTk5J3VOle8wxpa8ly6Fp5+2HYhKSuhPPmnHcunTxw6Tm5pqmzW+8AIMHKjJvTrUqBL82LH/q6+rKomJ9qdieYYPH87YsWO57bbbAPjwww/55ptvCA4OZubMmdStW5f9+/fTvXt3Bg0aVO7cpK+++iqhoaGsX7+eNWvW0LVr19LHnnrqKerVq0dRURHnnXcea9as4c477+TFF19k/vz51K9f/4h9rVixgrfeeotly5ZhjOHss8+md+/eREdH8/vvv/PBBx/w+uuvc+WVV/LJJ59w9dVXl/v6Ro0axcsvv0zv3r159NFHefzxx5k4cSLPPvssW7duJSgoqLRa6FjDDavapaDAJvNt22DfPnjjjf9dDAX7/3TnnbbpYs+etvmick6NSvBO6NKlC/v27WPXrl2kpaURHR1N8+bNcblcPPjggyxatAg/Pz927tzJ3r17aVzOWKGLFi0qneQjISGBhISE0sc+/PBDpkyZQmFhIbt37+a333474vGjLVmyhCFDhpSOajl06FAWL17MoEGDiI+PLx3yt1u3bqQcPVh1GVlZWWRmZtK7d28ARo8ezRVXXFEa48iRIxk8eDCDBw8GOOZww6p2MMbOG3r//bbXaIlzzoHbbrMdi7p3r7nd/X1VjUrwxytpe9IVV1zBxx9/zJ49exg+fDgA7733HmlpaaxYsYLAwEDi4uIoKCio9L63bt3KhAkT+Pnnn4mOjubaa689qf2UOHrI4RNV0ZTniy++YNGiRXz++ec89dRT/Prrr8ccbvj0008/6ViV98rLsxc6P/oIFi60U87t2wcXXmjboHfqZCevaNTI6UjV8WgdfAUMHz6c6dOn8/HHH5eWcLOysmjYsCGBgYHMnz+fbdu2HXcf5557Lu+//z4Aa9euZc2aNQBkZ2cTFhZGZGQke/fu5auvvip9TkRExDHruXv16sWsWbPIy8vj4MGDzJw586Sm2YuMjCQ6OprFixcD8O6779K7d2+Ki4vZsWMHffv25bnnniMrK4vc3NzS4Ybvv/9+zjzzTDZs2FDpYyrvVVxsOxRdeaUtiV9+OXz3HZx3Hlx8MUyZYie3uOQSO/2cJnfvV6NK8E7p2LEjOTk5NGvWjCbuXhYjR47k0ksvpXPnziQlJZ2wJHvrrbdy3XXX0b59e9q3b0+3bt0AOOOMM+jSpQunn346zZs3Jzk5ufQ5N910EwMGDKBp06bMnz+/dH3Xrl259tprOeusswC44YYb6NKly3GrY8ozdepUbrnlFvLy8mjVqhVvvfUWRUVFXH311WRlZWGM4c477yQqKopHHnnkT8MNq5pt7147dktqKqxda28NG8KoUXZSi969tZliTabDBasqo++VdzPGJvI5c2DGDDtL0ebNtuNRfDxERdkLpCNGaFKvSXS4YKVqmYwMWLPG1p23aGHHdHnoIdtsEaBjR3thNDERHnjAToShfI8meKV8SFaWHW3x6af/N49oia5d4eWX7bRzCQl24C7l2zya4EXkb8ANgAF+Ba4zxlS6iYgxptz25co7eFNVX21SVGRburz5pm2+uHq1bQEzcKBt7RIcbMd1CQuzdeo6+mLt4rEELyLNgDuBDsaYfBH5EBgBvF2Z/QQHB5Oenk5MTIwmeS9ljCE9PV07PlWjrVvt7EWvvWY7Gp12GrRsCddcAzfeaCe+KOHuCK1qIU9X0QQAISLiAkKBXZXdQWxsLKmpqaSlpVV5cKrqBAcHa8cnDzMGvv3W1pmvWmXX9ehhhwQYNswOq6tUWR5L8MaYnSIyAdgO5APfGmO+PXo7EbkJuAmgRYsWf9pPYGAg8fHxngpTKa9UWGjboG/caMd62bULFiywk0fHx9tOfwMGQLt2TkeqvJknq2iigcuAeCAT+EhErjbGTCu7nTFmCjAFbDNJT8WjVE0xbZotpaem2vsBAbZtelISjB8Pf/kLlOmwrFS5PFlFcz6w1RiTBiAinwI9gGnHfZZStVBWFnz5pb1gOnMmnH02vPSS7WgUHa3VL+rkeDLBbwe6i0gotormPOD4M1woVQscPGgntli9GjIz7Zgun3wCOTlQty48/rhts64tXtSp8mQd/DIR+RhYCRQCq3BXxShVG2Vk2MT+3HO2Tj06GmJi4MABO9bLHXfYkrsmdlVVPNqKxhjzGPCYJ4+hlDfauBH++U87IuOwYRAYaDsZ5efbli8zZkBysnY2Up6lPVmVqiKFhTaxf/ABPP+8LYknJ9u6dGPsxdF77oEuXZyOVNUWmuCVOgWZmXacl6+/hnfegZLuGldfbUvwDRvaTknFxdC6tbOxqtpHE7xSlbRpE7z4om3xcuCAXRcQAIMGweDBcNZZR7ZP124cyima4JWqoHnz4OGH4YcfbDv0K66wg3YlJNjp6iIjnY5QqSNpgleqHH/8YcdL37vXNmmcONGWxp97DkaP1hmNlPfTBK/UUdauteO7zJhx5Pqrr4ZXX4XwcGfiUqqyNMGrWq+oCN5/H774wk6SsX49hIba6pgBA2xJvVEjiIhwOlKlKkcTvKqVCgrsWC/ffmtL5WvX2pmPOnaEv/4Vhg+3E08rVZNpgle1Rn6+HZHxjTdg1ixbcgd7kXTGDHvRVDseKV+iCV75tLVrYcIE+OknOx/poUNQr56dXDohwXY6OuMMp6NUyjM0wSufk5kJ+/bBU0/ZzkdhYdC/vx3v5bzzoE8fO5WdUr5OE7zyCYcO2Y5HkyfDjz/adYGBcP/9cO+9dlAvpWobTfCqRsvNhUmTbBv1tDRo2xb+8Q/b6qVfPx0eQNVumuBVjVFYCIsXw1df2d6kmzbZIXhdLhg4EMaOtVUwOjmGUpYmeOX1iopsG/X77rOjNdapY6evu+wye8F08GA7VIBS6kia4JVXOnAApkyBdevsGDC7dtkBvKZPtxdLtTepUiemCV55jd274e23bTJ//32b5Js3t6MzjhgBQ4faC6dKqYrRBK8cVVQE8+fbKpjXX7fzlUZE2CqXCRNsW3Wl1MnRBK+q3eHD8PPP9kLpf/5jR22sU8fWpT/1FJx2mtMRKuUbfCLBG2NwFbuo41/H6VDUcaxdC888A7Nn2+aNYC+Wzphh69XDwpyNTylfU+MTfFFxEfVfqM/tZ97OP/r9w+lw1FE2bLDjvsyebUvsERF2btIBA+Ccc6BxY6cjVMp31fgE7+/nT3RwNJszNjsdisL2KP3lF5g50942brTru3WzY6zfeqtt2qiU8rwan+ABWtdrrQneQRkZ8Mor8NprdghesHOU9ukDd9xh26vHxjoaolK1kk8k+FZRrfhk/SdOh1Gr/PCDbZ++YwdMm2ZbvwwYADffbIcHGDAAoqOdjlKp2s0nEnzreq1Jz08nqyCLyGCd+diT9u61PUrfecfeDw6GYcPsgF7apFEp7+IbCT7ajii1JWMLXZp0cTga35Kfb9uof/ONnQVp9my77sEHYdw4ncZOKW/mGwm+nk3wmzM2a4KvAi6XnRxj7lx44glbao+Ohrp1oXdv2wGpbVuno1RKnYhPJPgIV2swsPmAXmg9FevW2aF3P/zQTpoB0KsXvPuuHXrX39/Z+JRSlVPjE/yBA9CvZwRBjd7l98QlTodTYxQX2wmnJ02CRYvsmC8bN0JIiB3z5YILoEMH27xR5ylVqmaq8Qk+OhpGjYInn7yaWY+14dGu0KKF01F5r9xce4F00iSb0Bs3hquvtgN8DRtmx1TX2Y+U8g01PsGL2Bl8vtn3Jj+/OZK2be00bQ89ZMc3qe0KCuCTT+Drr+3E01u32jr2pCRb9XLllXqelPJVNT7BlxgwIoXlYe0YvHszTzzhz6ef2pYel19e+xLYnj12MK9vvrHjvOzfDw0aQM+etvpl0CA7WqNWvSjl23xmcrPusd0xkdu48tHP+Owz22X+L3+x9ciffgrGOB2h57hc8OuvdmTGxERo0sQm8TfftBdJ5861Sf/TT+1gX+eco8ldqdrAZxJ8/9b9aRbRjNdXvs6gQXaQq9mzbUecyy+3zfu++84mw5ru4EFYsACeftrORRodbTsZ3XKL/SL75z9h4UJ7AfrTT20LGJ2nVKnax2eqaAL8Ari+y/X8Y9E/2Ja5jZZRLbn0UrjoIluSfeQR2zKkXj24/XZ7MbEmdKUvLral7bQ0eOklW5f+yy92ogyA9u1h9GhITrZJvmNHLZ0rpSwxXlR3kZSUZJYvX37Sz9+WuY34l+J5+NyHeaLvE0c8lpdn66TfeccOXxsaaqeB69HDdto5/XRbT+0NCgrgv/+Fjz+2v0IOHrTri4rsL5HkZBv32WfryIxK1XYissIYk3TMxzyZ4EUkCvg/oBNggDHGmB/K2/5UEzzAwPcGsmbvGlLGphDgd+wfKGvWwMsv23k/8/L+t75fP7jnHlvqr65SsMsFixfbzkVpabBvHyxfbpN8VJQdibFJE5vcr7/eTjytlFIlnEzwU4HFxpj/E5E6QKgxJrO87asiwc9cP5OhHw5l9ojZXNru0uNuW1gI27fb9uDLl8OUKXa42x49bIuT5s3hkktsW/HiYtsJqKKJv6jIXgfIyLBd/DMzbU/Rn3+2ifvQIdvBaMMGG0dEhG2/HxVlJ5nu399+4dS2FkBKqcpxJMGLSCSwGmhlKniQqkjwriIXLSa24MymZzL7qtmVe67L1tc//7xN9IcPH/l4QIBNvn362C+GrCybnIuK7F+XyybyjAzbNLGg4M/HaNDAVrmI2KqWbt2ga1c7ZV1IyMm/bqVU7XS8BO/Ji6zxQBrwloicAawA7jLGHPTgMQn0D2RM4hie/f7Z0outFX5uoB3P/Oab7f0//rAjKebl2VYo6em2Hv/pp23pPibGJn1/f/s3MBBatbIXb+vXtxc9GzWC7GxbMm/dGuLi7L6N0ZYtSinP8mQJPgn4EUg2xiwTkZeAbGPMI0dtdxNwE0CLFi26bdu27ZSPvSNrB60nteaWpFuYdNGkU97f0Vwum8yVUsppxyvBe7IMmQqkGmOWue9/DHQ9eiNjzBRjTJIxJqlBFTVjaR7ZnGsSruH1la+z7+C+KtlnWZrclVI1gccSvDFmD7BDRErafZwH/Oap4x3t/p73c6jwEBN/nFhdh1RKKa/i6VrgO4D3RGQNkAg87eHjlWob05ZhHYYx+efJZBVkVddhlVLKa3g0wRtjVrurXxKMMYONMRmePN7RHuj5ANmHsnnl51eq87BKKeUVfLodR5cmXbjotIv414//Is+Vd+InKKWUD/HpBA+2FJ+Wl8abq950OhSllKpWPp/ge7XsRXLzZCYsnYCryAeGklRKqQry+QQPMK7nOLZlbWP62ulOh6KUUtWmViT4i9tcTKeGnXju++coNsVOh6OUUtWiViR4EWFc8jjWpa1jzqY5ToejlFLVolYkeIDhnYYTFxXHM0uewZvGwFdKKU+pNQk+wC+Ae3vcy4+pPzI/Zb7T4SillMfVmgQPMKbLGJpGNGX8gvFaildK+bxaleCDA4J5sOeDLN6+mLlb5zodjlJKeVStSvAAN3S9gdi6sTw07yFtUaOU8mkVSvAiEiYifu7ltiIySERq5KC5QQFB/KPvP/hp50988OsHToejlFIeU9ES/CIgWESaAd8C1wBveyooTxt1xii6NunK/d/dz8HDHp1gSimlHFPRBC/GmDxgKPCKMeYKoKPnwvIsP/Fj4oUT2ZmzkwlLJzgdjlJKeUSFE7yInAOMBL5wr/P3TEjVo1fLXlzR4Qqe+/45UrNTnQ5HKaWqXEUT/FjgAWCmMWadiLQCanxj8ucveJ5iU8wDcx9wOhSllKpyFUrwxpiFxphBxpjn3Bdb9xtj7vRwbB4XFxXHPefcw7Q101iWuuzET1BKqRqkoq1o3heRuiISBqwFfhORez0bWvUY13McjcMbM/absdr5SSnlUypaRdPBGJMNDAa+AuKxLYxk3ooAABi2SURBVGlqvIigCJ7u9zQ/pv7IO7+843Q4SilVZSqa4APd7d4HA7ONMS7AZ4q7oxNH06N5D+7+9m725u51OhyllKoSFU3w/wFSgDBgkYi0BLI9FVR18xM//u/S/yP3cC53fl3jLy0opRRQ8Yusk4wxzYwxA421Dejr4diqVfsG7Xm418N8uO5DFqQscDocpZQ6ZRW9yBopIi+KyHL37Z/Y0rxP+XuPv9MysiVjvx5LUXGR0+EopdQpqWgVzZtADnCl+5YNvOWpoJwSEhjCCxe8wC97f+HNVW86HY5SSp2Siib41saYx4wxW9y3x4FWngzMKcM6DKNXi148NO8hsgqynA5HKaVOWkUTfL6I9Cy5IyLJQL5nQnKWiDBxwET25+3nyUVPOh2OUkqdtIom+FuAySKSIiIpwL+Bmz0WlcO6NunKmC5jmLhsImv2rnE6HKWUOikVbUXzizHmDCABSDDGdAH6eTQyhz13/nPUC6nHmM/GUFhc6HQ4SilVaZWa0ckYk+3u0Qpwtwfi8RoxoTFMHjiZFbtX8OIPLzodjlJKVdqpTNknVRaFlxrWYRhD2w/l0fmPsnH/RqfDUUqpSjmVBO8zQxUcz+SBkwkNDOX62dfrHK5KqRrluAleRHJEJPsYtxygaTXF6KjG4Y3514X/4vsd3zP5p8lOh6OUUhV23ARvjIkwxtQ9xi3CGBNQXUE6bdQZoxhw2gAemPsAWzO2Oh2OUkpVyKlU0dQaIsJ/LvkPIsKNn9+o48YrpWoETfAV1CKyBS9c8AJzt87ljVVvOB2OUkqdkCb4Srip2030ievDPd/eoxN1K6W8nib4SigZN95V5OLmOTdrVY1Syqt5PMGLiL+IrBKROZ4+VnVoXa81T5/3NF/+/iXvrnnX6XCUUqpc1VGCvwtYXw3HqTZ3nHUHvVr04q9f/JXf0n5zOhyllDomjyZ4EYkFLgb+z5PHqW7+fv58cPkHhNUJ4/IPLyfnUI7TISml1J94ugQ/EbgPKLcLqIjcVDJTVFpamofDqTrN6jZj+uXT2ZS+SZtOKqW8kscSvIhcAuwzxqw43nbGmCnGmCRjTFKDBg08FY5H9I3vy9P9nmbGuhm8/NPLToejlFJH8GQJPhkY5B4/fjrQT0SmefB4jrgv+T4GtRvEPd/ew9IdS50ORymlSnkswRtjHjDGxBpj4oARwDxjzNWeOp5TRISpg6fSIrIFV350JfsO7nM6JKWUArQdfJWICo7ikys/IT0/nas+uYqi4iKnQ1JKqepJ8MaYBcaYS6rjWE5JbJzIqxe/yryt83h0/qNOh6OUUlqCr0rXJl7LjV1v5OklTzNnk0/061JK1WCa4KvYpIsm0bVJV66ZeQ1bMrY4HY5SqhbTBF/FggOC+fiKjwEY9uEwCgoLHI5IKVVbaYL3gPjoeKYNmcaqPau4Zc4t2glKKeUITfAecnHbixnfezxTf5nK4wsfdzocpVQtVGum3XPCo70fZVvWNh5f+DjxUfGMThztdEhKqVpES/AeVDLVX7/4ftw852aWpS5zOiSlVC2iCd7DAv0DmTFsBk0imnDZ9MvYfGCz0yEppWoJTfDVoH5ofb74yxe4il1c8O4F7MrZ5XRISqlaQBN8NenQoANfjfyKfQf3ceG0CzmQf8DpkJRSPk4TfDU6q9lZfDbiMzalb+KS9y/h4OGDToeklPJhmuCr2XmtzuODyz9g2c5lDP1wKIeLDjsdklLKR2mCd8DQ9kOZcskUvt38LdfMvEZHn1RKeYS2g3fI9V2v50D+Ae777j6igqJ49ZJX8RP9vlVKVR1N8A66N/leMgoyeGbJM2QeyuSdwe8QFBDkdFhKKR+hCd5hT/V7iujgaO777j72HdzHzOEziQqOcjospZQP0DoBh4kI9ybfy7Qh0/h++/ec+9a57M7Z7XRYSikfoAneS4xMGMmXI79kS8YWer3Vi5TMFKdDUkrVcJrgvcj5rc7nu1HfkZ6fTq+3erFh/wanQ1JK1WCa4L1M99juLLx2Ia4iF+e+dS6rdq9yOiSlVA2lCd4LJTRKYPF1iwkJDKHv1L4s3rbY6ZCUUjWQJngv1SamDYuvW0zj8Mac9855vLb8NZ0ZSilVKZrgvViLyBb8eMOPXND6Am794lZu/PxGneNVKVVhmuC9XFRwFJ9f9TmPnPsIb6x6g95v99bhhpVSFaIJvgbwEz+e6PsEn175Kev2rSNpShL/3fxfp8NSSnk5TfA1yJD2Q/jh+h+IDI6k/7T+/PWLv5J7ONfpsJRSXkoTfA3TuVFnVt60kru7381ry1/jjNfOYMWuFU6HpZTyQprga6CQwBD+eeE/S9vLJ7+ZzJur3nQ6LKWUl9EEX4P1atmLlTevpFfLXlw/+3pu/vxm8l35ToellPISmuBruPqh9fl65NeMSx7HlJVT6PBKBz7f+LnTYSmlvIAmeB/g7+fPM+c/w7xR8wgJCGHQ9EEM+mAQWzO2Oh2aUspBmuB9SN/4vqy+ZTXPn/8887bOo8MrHXhy0ZMcKjzkdGhKKQdogvcxdfzrcG/yvay/bT2XtL2ER+Y/QqdXO7F0x1KnQ1NKVTNN8D6qeWRzPrriI765+huKTTG93+7NhKUT9CKsUrWIJngf1791f1bctIKBbQZy73/vpcXEFjwy7xH25O5xOjSllIdpgq8FooKjmDV8FgtGLyC5eTJPLX6KVi+14omFT2iJXikf5rEELyLNRWS+iPwmIutE5C5PHUudmIjQO643s0bMYuPtG7m03aU8tuAxOr7SkZnrZ+pQxEr5IE+W4AuBe4wxHYDuwG0i0sGDx1MV1CamDTOGzWDuqLmEBoYy9MOhnPn6mXy24TNN9Er5EI8leGPMbmPMSvdyDrAeaOap46nK6xffj1U3r+LNQW+SWZDJ4BmDOeO1M3h9xescPHzQ6fCUUqeoWurgRSQO6AIsO8ZjN4nIchFZnpaWVh3hqDIC/QO5rst1bLh9A+8OeReAm+bcRKtJrXjpx5d0ghGlajDx9E9yEQkHFgJPGWM+Pd62SUlJZvny5R6NRx2fMYYl25cwfuF45m2dR2zdWB7s+SCjE0cTGhjqdHhKqaOIyApjTNKxHvNoCV5EAoFPgPdOlNyVdxARerXsxdxRc/numu+IrRvLX7/8Ky3+1YLH5j/GzuydToeolKogj5XgRUSAqcABY8zYijxHS/DexxjD4u2LmbB0Ap9vsoOYnV7/dG7qehM3druR8DrhDkeoVO12vBK8JxN8T2Ax8CtQ7F79oDHmy/Keowneu21K38TsjbOZvXE2i7cvpl5IPe446w7uOOsOYkJjnA5PqVrJkQR/MjTB1xw/pv7Is0ue5bONnxEaGMpVna6iZ4ueDDl9CJHBkU6Hp1StoQleecxvab/x3PfPMWvDLLIPZVM/tD73J9/PFR2uoGVUS6fDU8rnaYJXHldsivlp5088OPdB5qfMB6BH8x6MSRxDn7g+tIpuhb0so5SqSprgVbXalL6JWRtm8caqN9iUvgmAM5ueyQM9H+DithdTx7+OwxEq5Ts0wStHGGNYu28t81PmM/HHiWzN3ErdoLr0atGLpKZJ3ND1BmLrxjodplI1miZ45ThXkYtvN3/LzA0zWbZzGb+l/Ya/+HPhaRfSu2Vvzm15Ll2bdCXAL8DpUJWqUTTBK6+TkpnCSz++xJd/fFlajRMTEsPl7S9neKfh9G7ZG38/f4ejVMr7aYJXXm13zm4WbVvErI2zmL1xNnmuPBqFNeLStpdSaAoJCwxjaPuh9Inrg5/oFAZKlaUJXtUYea48vtj0BTPWzeCbzd8QGRRJRkEGea48OjTowN3d72bw6YO1Y5VSbprgVY2W58pj5vqZPPv9s6zdtxY/8aN1dGs6N+pMn5Z9uLzD5TSNaOp0mEo5QhO88gnGGFbuXsmcTXNYm7aW5buWk5KZQoBfAP1b96duUF0SGyUypP0Q2sa0dTpcpaqFJnjlszbu38iry19l7ta55Lny2JKxBYCODTrSPbY7raNbc2m7S+nYoKN2tFI+SRO8qjW2Z21n1oZZzNowi/X717Mndw8AjcIa0b5BezrU78AZjc/gnNhz6NCgg7bUUTWeJnhVa+3J3cPM9TNZvms56/ev57e038g6lAVARJ0Izmp2Ft2adCPncA4RdSIY3mk4iY0TtbWOqjE0wSvlZoxhc8ZmftjxAz+k2tuve38lMjiSnEM5uIpdRNSJoE1MGxqENmBgm4EMbT8UP/EjOjiakMAQp1+CUkfQBK/UcRSbYvzEj/S8dGZvnM3K3SvZnLGZ7VnbWZe27ohtm4Q3oUfzHvRs0ZOkpklEBUcRFxWnE58ox2iCV+okrdi1gmU7l+Ev/uzP28/6/ev5fsf3pGSmlG4jCB0bduSSNpdwUZuLSGqaRHBAMILohV3lcZrglapiO7N38uu+X8k+lM36tPUs2r6IhSkLKTJFpdvER8VzadtLSc1JZd/BfQT5BzH6jNH8pfNfEBGt51dVQhO8UtUgIz+D73d8zy97fqGwuJClqUuZt3UecVFxNK/bnF05u9iYvpEAvwAKiwuJCYmhfYP29I3rS8OwhkQHR9OjeQ9i68YS4BegpX9VIZrglXJISf1+yfKn6z9l+a7lBPkHsffgXlbuXsmK3SsoNsVHPC8kIITT6p1Gu/rtaBXViuiQaEr+V5NbJJPUNInQwNBqfz3K+2iCV8qLHTx8kDxXHrtzd7N0x1LS89I5kH+ATQc2sSl9E1sztuIqdv3peY3DG9MquhXxUfE0r9scg6FxeGP6t+6PMQY/8aNVdCuCAoIceFWquhwvwevg20o5LKxOGGF1wmgQ1oCERgl/etwYQ0FhASJCQWEBC1IWsHbfWrZmbGVL5haWbF/CjuwdBPgFcLjo8BHP9RM/4qPiiYuKIzokmuhg98293CSiCV2bdKVpRNPSXxquIhe5h3OJDomultevPEdL8Er5AGMMIsLWjK0s3LaQkIAQXMUuNqVvYmP6RnZk7SCjIIOM/AwyCjL+9EUAUMe/DiEBIeQczqHYFNMsohlnx57N6TGn80fGH/iJH4mNEklsnMjp9U+ncXhj/XXgBbSKRilVyhhDniuPjIIMtmdtZ+XulezP209BYQH5rnwigyMJrxPO6j2rWbZzGVsythAfFU+xKWZb1rbS/QjCafVOo2VUS4L8g6jjX4f6ofXp0rgLsXVjCfQPJD0vnUbhjYiPiifQPxB/8cdP/PD3s39DAkIIqxPm4Nmo+TTBK6VOWmFxYelUihn5Gazes5otGVtKO4LtzNmJq8jF4aLD7MrZRXp+eoX3LUhpy6GsQ1mEBISQdSiLXTm7iI+KJ6FRAgmNEujcsDONwhuR58qjcXhjggOCAftl5Sp21eqJ3DXBK6WqhTGG1OxU9h7cy+Giw9QLqcfunN1sy9pGUXERxaaYIuP+W1zEvoP7+Hrz12QVZBEZHEm+K5/wOuE0jWjK5ozNrE9b/6cLzCXXFeKj4/kt7Td25ewiLDCMhEYJnBN7Ds0jm3Pw8EH25+0nIiiCjPwM0vPT6dakG/HR8QT4Bfzp1iC0AW1j2tbIwec0wSulaqTDRYfZlL6JNXvXkJ6XTmhgKNuztrMxfSObMzZzWr3TaF+/PQfyD/DTzp9YuXslh4oOARAWGEaeK4+IoAgigyLZkb3juMcK8g+iYVhDwuqEYYyhaURTggKC2HxgM2F1wmga0ZTGYY3xEz8MhgahDWgU3oiIOhHsz9tPcEAwzSOb07xuc2JCYwgOCCYkIISQwBCC/IP+1K+h2BTjKnLhKnZRWFxIVHDUSZ0jbUWjlKqR6vjXoVPDTnRq2KlC2xtjOJB/gNDAUEICQyg2xaVDRuzO2c2+g/soLC484uYqdrErZxdr961l38F95LnyMBh2Zu8ksyCTxMaJ5BfmsytnF6v3rC49TlpeGoXFhRWKy0/8aBTWqPS6REFhwRG9nhuHN2b3Pbsrf4JOQBO8UspniMgR8/WWHQ6iSUQTmkQ0qbJjFZtiMgsyyTmUQ/3Q+uS58tiRvYMdWTvILMgkvzC/9ML1QddBduXsorC4kPqh9QkJCKGOfx0C/QMJ9AukblDdKourLE3wSil1EvzEj3oh9agXUg+gtC9D1yZdHY7sf3S0I6WU8lGa4JVSykdpgldKKR+lCV4ppXyUJnillPJRmuCVUspHaYJXSikfpQleKaV8lFeNRSMiacC2E254bPWB/VUYTlXRuCrPW2PTuCpH46q8k4mtpTGmwbEe8KoEfypEZHl5A+44SeOqPG+NTeOqHI2r8qo6Nq2iUUopH6UJXimlfJQvJfgpTgdQDo2r8rw1No2rcjSuyqvS2HymDl4ppdSRfKkEr5RSqgxN8Eop5aNqfIIXkQEislFE/hCRcQ7G0VxE5ovIbyKyTkTucq8fLyI7RWS1+zbQofhSRORXdwzL3evqich/ReR399/oao6pXZnzslpEskVkrBPnTETeFJF9IrK2zLpjnh+xJrk/c2tExKMzPJQT2wsissF9/JkiEuVeHyci+WXO3WvVHFe5752IPOA+ZxtF5MJqjmtGmZhSRGS1e311nq/ycoTnPmfGmBp7A/yBzUAroA7wC9DBoViaAF3dyxHAJqADMB74uxecqxSg/lHrngfGuZfHAc85/F7uAVo6cc6Ac4GuwNoTnR9gIPAVIEB3YJkDsfUHAtzLz5WJLa7sdg7Edcz3zv2/8AsQBMS7/2/9qyuuox7/J/CoA+ervBzhsc9ZTS/BnwX8YYzZYow5DEwHLnMiEGPMbmPMSvdyDrAeaOZELJVwGTDVvTwVGOxgLOcBm40xJ9uT+ZQYYxYBB45aXd75uQx4x1g/AlEiUnWTfVYgNmPMt8aYkhmffwRiPXX8ysR1HJcB040xh4wxW4E/sP+/1RqXiAhwJfCBJ459PMfJER77nNX0BN8M2FHmfipekFRFJA7oAixzr7rd/RPrzequBinDAN+KyAoRucm9rpExpmQq9z1AI2dCA2AER/7TecM5K+/8eNvnbgy2pFciXkRWichCEenlQDzHeu+85Zz1AvYaY34vs67az9dROcJjn7OanuC9joiEA58AY40x2cCrQGsgEdiN/XnohJ7GmK7ARcBtInJu2QeN/U3oSJtZEakDDAI+cq/ylnNWysnzczwi8hBQCLznXrUbaGGM6QLcDbwvInWrMSSve++OchVHFiSq/XwdI0eUqurPWU1P8DuB5mXux7rXOUJEArFv3HvGmE8BjDF7jTFFxphi4HU89LP0RIwxO91/9wEz3XHsLfnJ5/67z4nYsF86K40xe90xesU5o/zz4xWfOxG5FrgEGOlODLirQNLdyyuwdd1tqyum47x3jp8zEQkAhgIzStZV9/k6Vo7Ag5+zmp7gfwbaiEi8uxQ4ApjtRCDuur03gPXGmBfLrC9bZzYEWHv0c6shtjARiShZxl6gW4s9V6Pdm40GPqvu2NyOKFV5wzlzK+/8zAZGuVs5dAeyyvzErhYiMgC4DxhkjMkrs76BiPi7l1sBbYAt1RhXee/dbGCEiASJSLw7rp+qKy6384ENxpjUkhXVeb7KyxF48nNWHVePPXnDXmnehP3mfcjBOHpif1qtAVa7bwOBd4Ff3etnA00ciK0VtgXDL8C6kvMExABzgd+B74B6DsQWBqQDkWXWVfs5w37B7AZc2LrO68s7P9hWDZPdn7lfgSQHYvsDWz9b8ll7zb3t5e73eDWwEri0muMq970DHnKfs43ARdUZl3v928AtR21bneervBzhsc+ZDlWglFI+qqZX0SillCqHJnillPJRmuCVUspHaYJXSikfpQleKaV8lCZ45fNEpEiOHLWyykYddY9G6FQ7faWOK8DpAJSqBvnGmESng1CqumkJXtVa7nHBnxc7Tv5PInKae32ciMxzD5g1V0RauNc3Ejv2+i/uWw/3rvxF5HX3GN/fikiIe/s73WN/rxGR6Q69TFWLaYJXtUHIUVU0w8s8lmWM6Qz8G5joXvcyMNUYk4AdxGuSe/0kYKEx5gzseOPr3OvbAJONMR2BTGzvSLBje3dx7+cWT704pcqjPVmVzxORXGNM+DHWpwD9jDFb3INA7THGxIjIfmwXe5d7/W5jTH0RSQNijTGHyuwjDvivMaaN+/79QKAx5kkR+RrIBWYBs4wxuR5+qUodQUvwqrYz5SxXxqEyy0X879rWxdixRLoCP7tHM1Sq2miCV7Xd8DJ/f3AvL8WOTAowEljsXp4L3AogIv4iElneTkXED2hujJkP3A9EAn/6FaGUJ2mJQtUGIeKeZNnta2NMSVPJaBFZgy2FX+VedwfwlojcC6QB17nX3wVMEZHrsSX1W7GjFh6LPzDN/SUgwCRjTGaVvSKlKkDr4FWt5a6DTzLG7Hc6FqU8QatolFLKR2kJXimlfJSW4JVSykdpgldKKR+lCV4ppXyUJnillPJRmuCVUspH/T+wbRwzfVfx5AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "frpoqVGCZkak",
        "outputId": "33791d44-3f17-4ebd-c136-48141de8542c"
      },
      "source": [
        "acc_train = history.history['accuracy']\n",
        "acc_val = history.history['val_accuracy']\n",
        "epochs = range(200)\n",
        "plt.plot(epochs, acc_train, 'g', label='Training acc')\n",
        "plt.plot(epochs, acc_val, 'b', label='validation acc')\n",
        "plt.title('Training and Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBrQuS2jwU9F"
      },
      "source": [
        "new_model = tf.keras.models.load_model('/content/drive/MyDrive/lstm-basic-validation')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO78Ex9O5lF_"
      },
      "source": [
        "# Create a function to generate 'next_words' number of words on top of the seeded bar\n",
        "def generateraplyrics(next_words):\n",
        "  seed_text  = random.choice(bars)\n",
        "  token_list = sentence_to_integer(seed_text)\n",
        "  token_list = pad_sequences([token_list], maxlen = padding_length - 1, padding = 'pre')\n",
        "  predicted  = new_model.predict_classes(token_list, verbose = 0)\n",
        "  lyrics = int_to_word[predicted[0]]\n",
        "  for _ in range(next_words):\n",
        "      token_list = sentence_to_integer(lyrics)\n",
        "      token_list = pad_sequences([token_list], maxlen = padding_length - 1, padding = 'pre')\n",
        "      predicted  = new_model.predict_classes(token_list, verbose = 0)\n",
        "      lyrics += ' ' + int_to_word[predicted[0]]\n",
        "  return lyrics.capitalize()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsQYK-4RxjJB",
        "outputId": "14927243-b612-4cd1-aa0d-0ef1b079dda4"
      },
      "source": [
        "# Example of output with 4000 words generated \n",
        "for i in range(80):\n",
        "  print(generateraplyrics(49))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Killers cmon poop i dont care what nobody say is guns and that i kick her in the door waving the fourfour of rough riders kid dont love back the tree i love it the tree was short a daughter thats i wrote me a daughter i call me big\n",
            "People at the funeral up in the back i see the story the tree i love it when i love to lick me a tape to call me a daughter thats a daughter time to lick me the tree i call it like i wrote me a daughter i call\n",
            "No no no notorious this ninja robbed you want to do it i use a dozen i aint for the funk ill die for the funk along ive like me to the waste dipped thats a waste dipped thats a waste side lyrical side lyrical daughter thats a lot i\n",
            "The more problems we see whats goin on poop you want to frick with biggie smalls the weak is this stroke of mine play with ill wit a lot of your trunk dipped thats the spot i call the tree i love it when i call me big poppa like\n",
            "Taya ran up when i died would tears go to me and her you dont play fo in the average appetit black tricks as like lick my hoe time to lick my leer lip quiver like a waste dipped thats a daughter i call ms time time to lick me\n",
            "Motherfrickers better strip dont get the paper hits the inf or two dreamin of me i dance i love ma i love you to the rim with benjamins it with it in the pathfinder i better blow the cell to the tree i lip quiver the tree i wrote me\n",
            "Should i die on the train track please send that i want to biggie smalls is a ninja never come the world youll be back their new side lyrical side lyrical dipped a lot used to why the tree i love it when i call me big poppa wrote me\n",
            "My style is flashy like a fiver strobes woman rum of their team with the hoe dark to with the cl*ts a lot used to lick the cl*ts a lot used to lick the cl*ts a lot used to lick the cl*ts a lot used to lick the cl*ts a\n",
            "Cats named mad bad bad boy my pocket aint a commission b***** out my dear dark to move like poop with the aids drinker on my trunk dipped to lick your raps call me the spot to big call me the spot i call the tree i the tree i\n",
            "To all my uptown ninjas ninjas like a mystery frickin been poops still a star pushed me for the d*ck dreamin your gat call your clicks i call me the tree i love to lick a lot of was side call me the daughter was a daughter thats i wrote\n",
            "I got the cleanest meanest penis ya never seen this stroke of genius that that i love to play a z but you tryin to put me with the spot i love to the spot thats your gat call your raps call me the tree i was the tree i\n",
            "Others let em hold you down reach for the stars cuffed friend as in florida now im time for b***** i met the ej and ginger ale in the pathfinder i call me the spot i call me the spot i call the tree i the tree i was the\n",
            "Ninjas bleed just like us believe my pipe bust your hands that the limit and come and yo come and poop aint not to get with that aint somethin somethin man poop big poppa like poop poop poop look with the aids on about my side lyrical dipped a lot\n",
            "Up north found put d*cks like a toaster i got them thugs next missing and me and her motherfrickin heres pounds of chope whats a pint i dont get with this bricks than their hoes call me the flow for it i not to when your upper lip quiver why\n",
            "Smalls now check it i got more mack than craig and in the bed by james todd smith in my hand tryin to lick my half encaged your trunk dipped a lot used to lick the cl*ts a lot used to lick the cl*ts a lot used to lick the\n",
            "Pass the blunt to be on your moms kick late to not cause you go up like aint somethin poop poop look at the love to the space crackside a lot of was side lyrical side lyrical side lyrical side a lot used to why the tree i love it\n",
            "N thangs aint da same crew round college back so long no question to me no question to let me do a name aint ma ma palm you like when that that that you like that poop you poop call me like that i love to me the cleanest lip\n",
            "Stop im ready to get a asthma attack like a fresh pair of street skirt tuesday of ma man ill time time now i e somethin somethin man poop hoes i like that poop poop poop poop poop aint me to the love of your trunk dipped thats the spot\n",
            "Ninja ninja ninja to all my brooklyn ninjas ninjas like a faculty its been poops still a man from their half of my friends lyrical daughter time to lick me a lot of was a daughter thats a waste dipped to lick me a lot of lyrical side lyrical side\n",
            "Roll the same treasure so grams i had to measure the day is my half hour i doubleg ie millies millies thats the spot thats your raps time to like i wrote me big poppa call me big poppa me like call me big poppa dont call me big poppa\n",
            "I got the cleanest meanest penis ya never seen this stroke of genius that that i love to play a z but you tryin to put me with the spot i love to the spot thats your gat call your raps call me the tree i was the tree i\n",
            "This must mean she aint tryin to wait all my gun ninjas aint like wonderin by im mean beef out i got that way ma hoes to call me a sandwhiches is a hoe that cry and frank play askin not knockers on the wall your clicks i lip quiver\n",
            "I got the cleanest meanest penis ya never seen this stroke of genius that that i love to play a z but you tryin to put me with the spot i love to the spot thats your gat call your raps call me the tree i was the tree i\n",
            "Killin ya now gucci brooklyn i never know what they want from me ninja like a name you like me up like a waist please put me up up down like me and black question all day a wig pushed back the crews big a lot used to lick the\n",
            "Of fistskill where your motherfrickin ninja for me for my d*ck til ma i got to get the wind blows spit your clicks was short like a clicks i pay it like you like i wrote me a lot of was like time time time time to i wrote me\n",
            "The more problems we see whats goin on poop you want to frick with biggie smalls the weak is this stroke of mine play with ill wit a lot of your trunk dipped thats the spot i call the tree i love it when i call me big poppa like\n",
            "Like b i double gone i had to find me and all i want is hoes big booty hoes cmon all mcs have the man from me and these thugs never never dont in ma man man that aint like a headpiece poop yeah the car sirens thats the spot\n",
            "Check it my lyrical carjack bricks uhhuh uhh what the burner is slow time and get with time that b***** time play ill like a hoe to made my friends lyrical daughter thats a daughter time to lick me a lot of was like was side used to lick me\n",
            "Boy you thank you what you want ninja ninja ninja ninja ninja ninja ninja ninja ninja ninja is a ninja is deep throat on motherfrickers you know poop dont dont die no mistake lazy bail by me out no time for bond im fricking do i got to go to\n",
            "I got the cleanest meanest penis ya never seen this stroke of genius that that i love to play a z but you tryin to put me with the spot i love to the spot thats your gat call your raps call me the tree i was the tree i\n",
            "Off the rough bath and unplug the only whats a x frick with game i like the spot i love to the space crackside thats the spot i call the pathfinder crackside the tree i wrote me a lot used to lick the cl*ts a lot used to lick the\n",
            "To all my uptown ninjas ninjas like a mystery frickin been poops still a star pushed me for the d*ck dreamin your gat call your clicks i call me the tree i love to lick a lot of was side call me the daughter was a daughter thats i wrote\n",
            "Who rock the spot biggie you know that you know that you keep on i do it i frick around poop frick around poop frick around poop frick around poop frick around poop frick around and frick the th to a number one contender you got a story to the\n",
            "And i dont frick ya not too but i wrote me a heineken how to the back is the days you aint the love of the pathfinder i call me the spot thats the cell to the tree i call me the spot thats the cell to the tree i\n",
            "Not to be fricked with my d*ck size in a room off the problem and why the yacht acclaimed dipped like lick me ninjaz like the tree i love it when i call me big poppa call me big poppa call me big poppa i like the cleanest lip quiver\n",
            "A tbone steak cheese sometimes i hear death knockin at my baby is unbelievable its a ninja from queens bullets name yeah me on the gall my daughter was a lot used to lick the cl*ts was short a daughter i call me the spot i call me the tree\n",
            "They actors and plain him with the clips i know you be a ladies in the back of the pathfinder thats the cell thats the cell i call the tree i love it when the tree i love it like you like i wrote me big poppa a lot of\n",
            "I got the cleanest meanest penis ya never seen this stroke of genius that that i love to play a z but you tryin to put me with the spot i love to the spot thats your gat call your raps call me the tree i was the tree i\n",
            "The more problems we see whats goin on poop you want to frick with biggie smalls the weak is this stroke of mine play with ill wit a lot of your trunk dipped thats the spot i call the tree i love it when i call me big poppa like\n",
            "When i was shot dat ninja like i started to touch me and a lot of he you be on the wrong road to come on the wind blows alot call ms side lyrical dipped a lot of your trunk dipped thats the spot i call the tree i love\n",
            "Why am i trying to give you what you want ninja ninja right boo true momma is deep deeper than the average appetit in my man dark back back behind my pen and me a daughter was it thats me like the pathfinder i call me the spot thats a\n",
            "Out here nor speak no evil inside two n likes that she with the freak b***** why this frick the cl*ts alot thats it a spot thats like a lot of the pathfinder was a lot used to lick the cl*ts a lot used to lick the cl*ts a lot\n",
            "Cmon shorty get high get high get high armed and dangerous aint remain as possible make the head tight than you catch up down to this rap cream girls time and lick me my world poop me for the pathfinder alot was the tree i love it when i call\n",
            "With the five in front probably a connivin i need the shadow of rough ten dipped thats the gat was a lot i wrote me the tree to your daughter thats your gat call your clicks i call me the daughter was a daughter i lip to the tree i\n",
            "On the road lookin when the coupe ill tremblin in her to the x frick the tree i love it when i call me big poppa me i wrote me a flow call your clicks was a daughter thats a lot i wrote me the daughter was a daughter i\n",
            "When i was shot dat ninja like i started to touch me and a lot of he you be on the wrong road to come on the wind blows alot call ms side lyrical dipped a lot of your trunk dipped thats the spot i call the tree i love\n",
            "Out here nor speak no evil inside two n likes that she with the freak b***** why this frick the cl*ts alot thats it a spot thats like a lot of the pathfinder was a lot used to lick the cl*ts a lot used to lick the cl*ts a lot\n",
            "Blow the end of us biggie biggie i go the same fourfive poop for the car sirens thats my daughter i call me the spot i call me the spot to the tree i call it the spot to big call me a lot used to lick the cl*ts a\n",
            "Broke of frickin an rb b***** biggie gots ta creep with a booty broke of ya singin g biggie biggie donna still with me now poop i dont do now poop i dont want to frick with poop ya dont get with that i like the frick to when i\n",
            "With the five in front probably a connivin i need the shadow of rough ten dipped thats the gat was a lot i wrote me the tree to your daughter thats your gat call your clicks i call me the daughter was a daughter i lip to the tree i\n",
            "On the road lookin when the coupe ill tremblin in her to the x frick the tree i love it when i call me big poppa me i wrote me a flow call your clicks was a daughter thats a lot i wrote me the daughter was a daughter i\n",
            "Now i got the mac in the funk ill tremblin it we did it im cold it up no question all the time time for you to like ninjaz with the love the tree i love it when i call me big poppa call me big poppa i call me\n",
            "Out here nor speak no evil inside two n likes that she with the freak b***** why this frick the cl*ts alot thats it a spot thats like a lot of the pathfinder was a lot used to lick the cl*ts a lot used to lick the cl*ts a lot\n",
            "Level a group home in the west coast black hood uhhuh come the wind blows an rims used to lick my daughter a daughter thats a lot used to lick the cl*ts a lot used to lick the cl*ts a lot used to lick the cl*ts a lot used to\n",
            "Junior mafia hehe mm out ninjaz or lil mind i wanna see unbelievable poop poop poop poop poop tell me why why why you wanna get with me puff going back to cali if i love to me the dog three to why this frick high dont dance frick the\n",
            "From the mississippi down down with my faculty now baby i dont wanna live no question no stroke of mine play with computers a pimp part of you blow on the wall and me on the wall the tree i love it when i call me big poppa dont call\n",
            "Lets ride lets ride lets ride lets ride lets ride lets ride coast things i aint back im got up honey this bizarre to play the chocolate the ej and ginger ale in the pathfinder alot was a lot of was side call the pathfinder crackside thats a waste side\n",
            "On the road lookin when the coupe ill tremblin in her to the x frick the tree i love it when i call me big poppa me i wrote me a flow call your clicks was a daughter thats a lot i wrote me the daughter was a daughter i\n",
            "To all my uptown ninjas ninjas like a mystery frickin been poops still a star pushed me for the d*ck dreamin your gat call your clicks i call me the tree i love to lick a lot of was side call me the daughter was a daughter thats i wrote\n",
            "For the jackers digits push a mayor frank white tryin to lick my d*ck on me on my friends grand spot i call me the spot thats your lot time to lick me a lot of me i wrote me a lot of was a waste dipped thats a daughter\n",
            "I got the cleanest meanest penis ya never seen this stroke of genius that that i love to play a z but you tryin to put me with the spot i love to the spot thats your gat call your raps call me the tree i was the tree i\n",
            "Verbally man deep for the stallin gimme the wind blows alot thats it lip to the waste dipped thats a waste dipped thats a waste side lyrical side lyrical side lyrical side lyrical side lyrical side a daughter i lip quiver why why i wrote me a lot used to\n",
            "I got the cleanest meanest penis ya never seen this stroke of genius that that i love to play a z but you tryin to put me with the spot i love to the spot thats your gat call your raps call me the tree i was the tree i\n",
            "To all my uptown ninjas ninjas like a mystery frickin been poops still a star pushed me for the d*ck dreamin your gat call your clicks i call me the tree i love to lick a lot of was side call me the daughter was a daughter thats i wrote\n",
            "A tbone steak cheese sometimes i hear death knockin at my baby is unbelievable its a ninja from queens bullets name yeah me on the gall my daughter was a lot used to lick the cl*ts was short a daughter i call me the spot i call me the tree\n",
            "I got the cleanest meanest penis ya never seen this stroke of genius that that i love to play a z but you tryin to put me with the spot i love to the spot thats your gat call your raps call me the tree i was the tree i\n",
            "Amount mcs got the briefcases nothin we took it like total this bizarre in the goldie sound in the car sirens why the lip crackside the tree i wrote me a lot used to lick the cl*ts a lot used to lick the cl*ts a lot used to lick the\n",
            "It didnt take long or since i feel to go to go to all my hands in the air if youse a true player for my friends baby thats a cell was a daughter was your daughter big thats a daughter time to lick me big poppa a daughter i\n",
            "And i dont frick ya not too but i wrote me a heineken how to the back is the days you aint the love of the pathfinder i call me the spot thats the cell to the tree i call me the spot thats the cell to the tree i\n",
            "Time to explain your game talk your poop grab your gat call your clicks i your daughter i call it when i like i wrote me the tree i made to the tree i love to lick a clicks was like like i wrote me a daughter i call me\n",
            "That i killed yo bum in the mist kid somebody gotta see her brother with the chocolate i aint no telling where a hoes grab you to you spit on the cl*ts was short like a clicks was short like a clicks was a daughter thats i wrote me a\n",
            "To all my uptown ninjas ninjas like a mystery frickin been poops still a star pushed me for the d*ck dreamin your gat call your clicks i call me the tree i love to lick a lot of was side call me the daughter was a daughter thats i wrote\n",
            "Of fistskill where your motherfrickin ninja for me for my d*ck til ma i got to get the wind blows spit your clicks was short like a clicks i pay it like you like i wrote me a lot of was like time time time time to i wrote me\n",
            "Can i get witcha can i get witcha can i get witcha can i get witcha can i get witcha can i get witcha can i get witcha can i get witcha can i get witcha can i get witcha can i get witcha can i get witcha can i\n",
            "In the mornin kick the door in wave like the love of my side lyrical side lyrical side lyrical side lyrical side lyrical side a daughter i lip quiver why why i wrote me a lot used to lick the cl*ts a lot used to lick the cl*ts a lot\n",
            "Out here nor speak no evil inside two n likes that she with the freak b***** why this frick the cl*ts alot thats it a spot thats like a lot of the pathfinder was a lot used to lick the cl*ts a lot used to lick the cl*ts a lot\n",
            "To all my uptown ninjas ninjas like a mystery frickin been poops still a star pushed me for the d*ck dreamin your gat call your clicks i call me the tree i love to lick a lot of was side call me the daughter was a daughter thats i wrote\n",
            "The more problems we see whats goin on poop you want to frick with biggie smalls the weak is this stroke of mine play with ill wit a lot of your trunk dipped thats the spot i call the tree i love it when i call me big poppa like\n",
            "And i dont frick ya not too but i wrote me a heineken how to the back is the days you aint the love of the pathfinder i call me the spot thats the cell to the tree i call me the spot thats the cell to the tree i\n",
            "To all my uptown ninjas ninjas like a mystery frickin been poops still a star pushed me for the d*ck dreamin your gat call your clicks i call me the tree i love to lick a lot of was side call me the daughter was a daughter thats i wrote\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5458f922aLi"
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}