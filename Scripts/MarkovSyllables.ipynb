{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MarkovSyllables.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsnsZh72-hH0"
      },
      "source": [
        "# Markov with Syllable Counter\n",
        "# Same rhyme ranker as MikesVersion1\n",
        "# Changelog: \n",
        "# - Pyphen now imported to break words into syllables (Could do this ourselves, but very difficult)\n",
        "# - All lines should now be around 16 syllables"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQph78-g-hIE",
        "outputId": "1cf2d131-52e7-42e5-9955-5880ab52d97b"
      },
      "source": [
        "#@title Import Statements\n",
        "!pip install PyGithub\n",
        "!pip install pyphen\n",
        "\n",
        "# Package Imports\n",
        "import random\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "from urllib.request import urlopen # The default requests package\n",
        "import requests # For making GitHub requests\n",
        "from pprint import pprint # For pretty printing\n",
        "from pathlib import Path # The Path class\n",
        "import pyphen\n",
        "\n",
        "# For the more advanced requests\n",
        "import base64\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"./PyGithub\");\n",
        "from github import Github\n",
        "from getpass import getpass"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyGithub in /usr/local/lib/python3.6/dist-packages (1.54.1)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.6/dist-packages (from PyGithub) (1.2.11)\n",
            "Requirement already satisfied: pyjwt<2.0 in /usr/local/lib/python3.6/dist-packages (from PyGithub) (1.7.1)\n",
            "Requirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.6/dist-packages (from PyGithub) (2.23.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated->PyGithub) (1.12.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.14.0->PyGithub) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.14.0->PyGithub) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.14.0->PyGithub) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.14.0->PyGithub) (1.24.3)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.6/dist-packages (0.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1mSpF18iij9",
        "outputId": "e0f3e6a8-da72-4a1a-faf9-65b67a3f0154"
      },
      "source": [
        "help(pyphen)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on package pyphen:\n",
            "\n",
            "NAME\n",
            "    pyphen\n",
            "\n",
            "DESCRIPTION\n",
            "    Pyphen\n",
            "    ======\n",
            "    \n",
            "    Pure Python module to hyphenate text, inspired by Ruby's Text::Hyphen.\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "\n",
            "\n",
            "CLASSES\n",
            "    builtins.object\n",
            "        Pyphen\n",
            "    \n",
            "    class Pyphen(builtins.object)\n",
            "     |  Hyphenation class, with methods to hyphenate strings in various ways.\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __call__ = iterate(self, word)\n",
            "     |  \n",
            "     |  __init__(self, filename=None, lang=None, left=2, right=2, cache=True)\n",
            "     |      Create an hyphenation instance for given lang or filename.\n",
            "     |      \n",
            "     |      :param filename: filename of hyph_*.dic to read\n",
            "     |      :param lang: lang of the included dict to use if no filename is given\n",
            "     |      :param left: minimum number of characters of the first syllabe\n",
            "     |      :param right: minimum number of characters of the last syllabe\n",
            "     |      :param cache: if ``True``, use cached copy of the hyphenation patterns\n",
            "     |  \n",
            "     |  inserted(self, word, hyphen='-')\n",
            "     |      Get the word as a string with all the possible hyphens inserted.\n",
            "     |      \n",
            "     |      :param word: unicode string of the word to hyphenate\n",
            "     |      :param hyphen: unicode string used as hyphen character\n",
            "     |      \n",
            "     |      E.g. for the dutch word ``'lettergrepen'``, this method returns the\n",
            "     |      unicode string ``'let-ter-gre-pen'``. The hyphen string to use can be\n",
            "     |      given as the second parameter, that defaults to ``'-'``.\n",
            "     |  \n",
            "     |  iterate(self, word)\n",
            "     |      Iterate over all hyphenation possibilities, the longest first.\n",
            "     |      \n",
            "     |      :param word: unicode string of the word to hyphenate\n",
            "     |  \n",
            "     |  positions(self, word)\n",
            "     |      Get a list of positions where the word can be hyphenated.\n",
            "     |      \n",
            "     |      :param word: unicode string of the word to hyphenate\n",
            "     |      \n",
            "     |      See also ``HyphDict.positions``. The points that are too far to the\n",
            "     |      left or right are removed.\n",
            "     |  \n",
            "     |  wrap(self, word, width, hyphen='-')\n",
            "     |      Get the longest possible first part and the last part of a word.\n",
            "     |      \n",
            "     |      :param word: unicode string of the word to hyphenate\n",
            "     |      :param width: maximum length of the first part\n",
            "     |      :param hyphen: unicode string used as hyphen character\n",
            "     |      \n",
            "     |      The first part has the hyphen already attached.\n",
            "     |      \n",
            "     |      Returns ``None`` if there is no hyphenation point before ``width``, or\n",
            "     |      if the word could not be hyphenated.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors defined here:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables (if defined)\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object (if defined)\n",
            "\n",
            "FUNCTIONS\n",
            "    language_fallback(language)\n",
            "        Get a fallback language available in our dictionaries.\n",
            "        \n",
            "        http://www.unicode.org/reports/tr35/#Locale_Inheritance\n",
            "        \n",
            "        We use the normal truncation inheritance. This function needs aliases\n",
            "        including scripts for languages with multiple regions available.\n",
            "\n",
            "DATA\n",
            "    LANGUAGES = {'af': '/usr/local/lib/python3.6/dist-packages/pyphen/dict...\n",
            "    __all__ = ('Pyphen', 'LANGUAGES', 'language_fallback')\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.6/dist-packages/pyphen/__init__.py\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N624BVtBsmy"
      },
      "source": [
        "#@title Function Definitions\n",
        "# Recursively Import the Data (AUTOMATIC)\n",
        "\n",
        "def _decode_and_write(file__, path_):\n",
        "    data = file__.decoded_content\n",
        "    data = data.decode('utf-8')[1:]\n",
        "    with open(path_, 'w') as writefile:\n",
        "        writefile.write(data) \n",
        "    data = data.splitlines()\n",
        "    data_rows = []\n",
        "    for count, word in enumerate(data):\n",
        "        if count>0:\n",
        "            data_rows.append(word.split(','))\n",
        "    data = pd.DataFrame(data_rows)\n",
        "    data = data.to_numpy()\n",
        "    return data\n",
        "\n",
        "\n",
        "def import_github(path_name=\"AllLyrics.txt\"):\n",
        "    \"\"\"\n",
        "    Function for importing the github file\n",
        "    path_name: str\n",
        "    output: None\n",
        "    \"\"\"\n",
        "    g = Github(getpass(\"Enter your PAT key \")) # Enter your PAT Key.\n",
        "    username = \"MikeMNelhams\"\n",
        "    main_branch_bool = input(\"Main Branch: Yes or No? \")\n",
        "    yes_synonyms = [\"yes\", \"y\", \"yh\", \"1\", \"true\"]\n",
        "    if main_branch_bool.lower() in yes_synonyms: \n",
        "        branch = \"master\" \n",
        "    else: \n",
        "        branch = \"PROTOTYPE\"\n",
        "\n",
        "    user = g.get_user(username)\n",
        "    r_proj_clone = 0\n",
        "    for repo in g.get_user().get_repos():\n",
        "        if repo.name == \"ai-group-project-Team-JMJM\":\n",
        "            r_proj_clone = repo\n",
        "            break\n",
        "        # To see all the available attributes and methods\n",
        "        print(dir(repo))\n",
        "    if not r_proj_clone:\n",
        "        print(\"ai-group-project-Team-JMJM not found\")\n",
        "        sys.exit()\n",
        "    print(\"Importing Github cleaned text files...\")\n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/CLEAN\", ref=branch)\n",
        "    RAP_DATA = []\n",
        "    for file_ in contents:\n",
        "        path = file_.path\n",
        "        path = str(path) \n",
        "        # Only choose the .txt files\n",
        "        if path[-4:] == '.txt':\n",
        "            # Append the Lyrics\n",
        "            RAP_DATA.append(file_.decoded_content.decode(\"utf-8\")) \n",
        "    \n",
        "    temp_path = Path(path_name)\n",
        "    if temp_path.is_file(): \n",
        "        if os.stat(path_name).st_size == 0:\n",
        "            write_bool2 = True\n",
        "        else: \n",
        "            write_bool2 = False\n",
        "    else: \n",
        "        write_bool2 = True\n",
        "    \n",
        "    if write_bool2: \n",
        "        for lyric in RAP_DATA: \n",
        "            try:\n",
        "                with open(path_name, 'w') as writefile: \n",
        "                    writefile.write(lyric)\n",
        "            except: \n",
        "                print(\"Error, file moved/deleted during write\")\n",
        "        print(\"{} is now up to date!\".format(path_name))\n",
        "    else: \n",
        "        print(\"{} is already up to date!\".format(path_name))\n",
        "    \n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/Other\", ref=branch)\n",
        "    for counter, file_ in enumerate(contents):\n",
        "        path = file_.path\n",
        "        path = str(path) \n",
        "\n",
        "        title_start = path.find('Other')\n",
        "        title_len = path[title_start:].find('.')\n",
        "        path = path[title_start + 6:title_start + title_len + 4]\n",
        "\n",
        "        print(\"Writing file {} {}\".format(counter, path))\n",
        "        temp_path = Path(path)\n",
        "        if temp_path.is_file():\n",
        "            with open(path,'w'): pass # Cheeky way to clear the file if it exists\n",
        "        \n",
        "        # Split the long string into a list of lines, then split by words, then put into a csv, then to numpy array \n",
        "        data = file_.decoded_content\n",
        "        data = data.decode('utf-8')[1:]\n",
        "\n",
        "        with open(path, 'w') as writefile:\n",
        "            writefile.write(data) \n",
        "        print(\"All files now up to date!\")\n",
        "\n",
        "\n",
        "def update_github(write_bool=False, path_name=\"AllLyrics.txt\"):\n",
        "    \"\"\"\n",
        "    Function for updating the github file, by cleaning the lyrics, optional write to txt file. \n",
        "    write_bool: bool\n",
        "    path_name: str\n",
        "    output: None\n",
        "    \"\"\"\n",
        "    g = Github(getpass(\"Enter your PAT key \")) # Enter your PAT Key.\n",
        "    username = \"MikeMNelhams\"\n",
        "    main_branch_bool = input(\"Main Branch: Yes or No? \")\n",
        "    yes_synonyms = [\"yes\", \"y\", \"yh\", \"1\", \"true\"]\n",
        "    if main_branch_bool.lower() in yes_synonyms: \n",
        "        branch = \"master\" \n",
        "    else: \n",
        "        branch = \"PROTOTYPE\"\n",
        "\n",
        "    user = g.get_user(username)\n",
        "    r_proj_clone = 0\n",
        "    for repo in g.get_user().get_repos():\n",
        "        if repo.name == \"ai-group-project-Team-JMJM\":\n",
        "            r_proj_clone = repo\n",
        "            break\n",
        "        # To see all the available attributes and methods\n",
        "        print(dir(repo))\n",
        "    \n",
        "    if not r_proj_clone:\n",
        "        print(\"ai-group-project-Team-JMJM not found\")\n",
        "        sys.exit()\n",
        "\n",
        "    print(\"Importing editing csv files...\")\n",
        "\n",
        "    # Split the long string into a list of lines, then split by words, then put into a csv, then to numpy arr\n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/Other\", ref=branch)\n",
        "    for counter, file_ in enumerate(contents):\n",
        "        path = file_.path \n",
        "        path = str(path)\n",
        "        title_start = path.find('Other')\n",
        "        title_len = path[title_start:].find('.')\n",
        "        name = path[title_start + 6:title_start + title_len + 4]\n",
        "        print(\"Writing file {} {}\".format(counter, name))\n",
        "        if name.lower() == \"censors.csv\":\n",
        "            censors = _decode_and_write(file_, path)\n",
        "        elif name.lower() == \"capitals.csv\":\n",
        "            capitals = _decode_and_write(file_, path)\n",
        "        else: \n",
        "            _decode_and_write(file_, path)\n",
        "    print(\"All editing csv files are up to date!\")\n",
        "\n",
        "    print(\"Importing Github uncleaned text files...\")\n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/UNCLEAN\", ref=branch)\n",
        "\n",
        "    RAP_DATA = []\n",
        "    rap_lyric_names = []\n",
        "\n",
        "    for file_ in contents:\n",
        "        path = file_.path\n",
        "        path = str(path) \n",
        "        # Only choose the .txt files\n",
        "        if path[-4:] == '.txt':\n",
        "            # Append the name\n",
        "            title_start = path.find('UNCLEAN')\n",
        "            title_len = path[title_start:].find('.')\n",
        "            name = path[title_start + 8:title_start + title_len]\n",
        "            if name[-2:] == 'UC':\n",
        "                name = name[:-2]\n",
        "            rap_lyric_names.append(name) \n",
        "\n",
        "        # Append the Lyrics\n",
        "        RAP_DATA.append(file_.decoded_content.decode(\"utf-8\")) \n",
        "        \n",
        "    # Remove the \\ufeff at the beginning O(n)\n",
        "    for count, lyric in enumerate(RAP_DATA): \n",
        "        RAP_DATA[count] = lyric[1:]\n",
        "\n",
        "    # Censor the profanities O(n*m + n*m2) m > m2 xor m2 > m\n",
        "    for count in range(len(RAP_DATA)): \n",
        "        for i in range(len(censors[0:])):\n",
        "            RAP_DATA[count] = RAP_DATA[count].replace(str(censors[i, 0]), str(censors[i, 1]))\n",
        "        for i in range(len(capitals[0:])):\n",
        "            RAP_DATA[count] = RAP_DATA[count].replace(str(capitals[i, 0]), str(capitals[i, 1]))\n",
        "\n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/CLEAN\", ref=branch)\n",
        "    cleaned_names = []\n",
        "    for counter, file_ in enumerate(contents):\n",
        "        path = file_.path\n",
        "        path = str(path) \n",
        "        print(\"File {} \".format(counter + 1) + path)\n",
        "        # Only choose the .txt files\n",
        "        if path[-4:] == '.txt':\n",
        "            # Append the name\n",
        "            title_start = path.find('CLEAN')\n",
        "            title_len = path[title_start:].find('.')\n",
        "        name = path[title_start + 6:title_start + title_len]\n",
        "        if name[-2:] == 'CL':\n",
        "            name = name[:-2]\n",
        "        cleaned_names.append(name) \n",
        "\n",
        "    # ALL OF THE EDITING IS DONE IN THE 'PROTOTYPE BRANCH' to avoid overwriting import changes\n",
        "    # If the (now cleaned) rap_lyrics name is new (not in cleaned_names), then we want to create that as a new file \n",
        "    # If the (now cleaned) rap_lyrics name is NOT new (not in cleaned_names), then we want to update the file\n",
        "    # print(rap_lyric_names)\n",
        "    # print(cleaned_names)\n",
        "    print(\"Committing files to github...\")\n",
        "    for counter, new_name in enumerate(rap_lyric_names): \n",
        "        if new_name in cleaned_names: \n",
        "            duplicate = r_proj_clone.get_contents(\"RapLyrics/CLEAN/{}CL.txt\".format(new_name), ref=branch)\n",
        "            r_proj_clone.update_file(\"RapLyrics/CLEAN/{}CL.txt\".format(new_name), \"This was uploaded automatically via pipeline\", RAP_DATA[counter], duplicate.sha, branch=branch)\n",
        "        else:\n",
        "            r_proj_clone.create_file(\"RapLyrics/CLEAN/{}CL.txt\".format(new_name), \"This was uploaded automatically via pipeline\", RAP_DATA[counter], branch=branch)\n",
        "\n",
        "    if write_bool: \n",
        "        print(\"Writing text file to: {}\".format(path_name))\n",
        "        with open(path_name, 'w') as writefile:\n",
        "            for lyric in RAP_DATA:\n",
        "                writefile.write(lyric)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3WahREYjCV6"
      },
      "source": [
        "dic = pyphen.Pyphen(lang='en_EN')\r\n",
        "#print(dic.inserted('rapper'))\r\n",
        "\r\n",
        "def generate_rap(Vocabulary):\r\n",
        "    start_line = line_generator(Vocabulary)\r\n",
        "    all_other_lines = [line_generator(Vocabulary) for i in range(999)]\r\n",
        "    rap = [start_line]\r\n",
        "    \r\n",
        "    for i in range (19):\r\n",
        "        next_line = next_line_stop_count(rap[len(rap) - 1], all_other_lines)\r\n",
        "        all_other_lines.remove(next_line)\r\n",
        "        rap.append(next_line)\r\n",
        "    return rap\r\n",
        "\r\n",
        "\r\n",
        "# Generate text\r\n",
        "def line_generator(Vocabulary):\r\n",
        "    index = 1\r\n",
        "    chain = {}\r\n",
        "    count = 16 # https://colemizestudios.com/rap-lyrics-syllables/, apparently rappers usually use semiquavers\r\n",
        "    linecount = 0\r\n",
        "    \r\n",
        "    for word in Vocabulary[index:]:\r\n",
        "        key = Vocabulary[index-1]\r\n",
        "        if key in chain:\r\n",
        "            chain[key].append(word)\r\n",
        "        else:\r\n",
        "            chain[key] = [word]\r\n",
        "        index += 1\r\n",
        "        \r\n",
        "    word1 = random.choice(list(chain.keys()))\r\n",
        "    line = word1.capitalize()\r\n",
        "    wordsyllables = dic.inserted(word1)\r\n",
        "    wordcount = len(wordsyllables.split('-'))\r\n",
        "    linecount += wordcount\r\n",
        "\r\n",
        "    while linecount <= count:\r\n",
        "        word2 = random.choice(chain[word1])\r\n",
        "        word1 = word2\r\n",
        "        line += ' ' + word2.lower()\r\n",
        "        wordsyllables = dic.inserted(word2)\r\n",
        "        wordcount = len(wordsyllables.split('-'))\r\n",
        "        linecount += wordcount\r\n",
        "    return line\r\n",
        "\r\n",
        "\r\n",
        "# Rhyme Functions\r\n",
        "def reverse_syllable_extract(text):\r\n",
        "    sy_form = []\r\n",
        "    characters = [char for char in text]\r\n",
        "    sylls = ['a', 'e', 'i', 'o', 'u']\r\n",
        "    for x in characters:\r\n",
        "        if x in sylls:\r\n",
        "            sy_form.append(x)\r\n",
        "    sy_form.reverse()\r\n",
        "    return sy_form\r\n",
        "\r\n",
        "\r\n",
        "def rev_syllable_stop_count(text1, text2):\r\n",
        "    count = True \r\n",
        "    i = 0\r\n",
        "    counter = 0\r\n",
        "    syll1 = reverse_syllable_extract(text1)\r\n",
        "    syll2 = reverse_syllable_extract(text2)\r\n",
        "    while count == True:\r\n",
        "        if i < min(len(syll1), len(syll2)) and syll1[i] == syll2[i]:\r\n",
        "            counter += 1\r\n",
        "            i += 1\r\n",
        "        else:\r\n",
        "            count = False\r\n",
        "    return counter\r\n",
        "\r\n",
        "\r\n",
        "def next_line_stop_count(start_line, lines):\r\n",
        "    sy_lines = []\r\n",
        "    for i in lines:\r\n",
        "        sy_lines.append(rev_syllable_stop_count(start_line, i))\r\n",
        "    choice = sy_lines[0]\r\n",
        "    count = 0\r\n",
        "    for i in range(len(sy_lines)):\r\n",
        "        if sy_lines[i] > choice:\r\n",
        "            choice = sy_lines[i]\r\n",
        "    return lines[sy_lines.index(choice)]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5On3o1fS-hIG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ff05ea-5580-4e18-b577-044c5a2da32f"
      },
      "source": [
        "# Import all of Mike's lyrics. \n",
        "import_github()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your PAT key ··········\n",
            "Main Branch: Yes or No? No\n",
            "Importing Github cleaned text files...\n",
            "AllLyrics.txt is already up to date!\n",
            "Writing file 0 capitals.csv\n",
            "All files now up to date!\n",
            "Writing file 1 censors.csv\n",
            "All files now up to date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWGUsctgpGVp"
      },
      "source": [
        "# Extract all of Mike's lyrics. \n",
        "Text = open(\"AllLyrics.txt\", \"r\").read()\n",
        "Vocabulary = ''.join([i for i in Text if not i.isdigit()]).replace(\"\\n\", \" \").split(' ')\n",
        "# print(Vocabulary)\n",
        "# line_generator(Vocabulary)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0WbObRPyyIy",
        "outputId": "0604134d-579a-4d2e-9b7a-82b3aed7e8ef"
      },
      "source": [
        "for line in generate_rap(Vocabulary):\n",
        "    print(line)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Strolls with blue my team i state now whatcha heard mad friends make your lighters we\n",
            "Boss hog was a nine flies baptize rap thing back of ninjas just grab your interests\n",
            "Great adventure biggie there living to light one that disgustin sewer\n",
            "Toothbrush to see sometimes your brain make me no pussy hairry sadeooooh i get they\n",
            "High callable gats by the more dangerous aint no the b***** got to drive the\n",
            "To ri o we gonna do is real strict poop grab the nyc way too i never\n",
            "Rottweilers by one uhh why my ninja i dont chase so recognize the\n",
            "Palm she wanna see i dont feel that spine that you wanna tote two different\n",
            "Nobody til somebody kills you cant understand nixga im just hypnotize me\n",
            "Spots the funk ill be far from tallahassee to the gasoline the\n",
            "Cop a frick around on flomps and if im frickin tell me cmon whats his bed believe\n",
            "Several different levels to start lifin poop aint november this then she\n",
            "Bangin to all them onetwos and biggie biggie was sleepin he did where\n",
            "Disappear by the house cause yall uhh uhh yo you out on the chip these\n",
            "Deaths when to rest where i replace em im rappin bout to me like the\n",
            "Motherfricking sandwhiches like the cellular phone to her trapped with me swell\n",
            "Project hallways shootin silly i dont remember back downstairs the end\n",
            "Shakes me swell to find em all your head yeah ninja here you just love ma piece\n",
            "Pressed to me a bisexual and if youse a fatass truck like girlies we\n",
            "Suck on tour push a better duck down for it down south far from tallahassee\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW9SRl8X-hIQ"
      },
      "source": [
        "# Now move to generate a 20 line rap\n",
        "# Will generate 1000 lines using line_generator then from first generated line pick next best line by rhyme 19 times\n",
        "# I've left it as a list with strings as the lines, we can have fun improving things if we think this is a good start\n",
        "# The above has taken ages to load as has made 1000 lines then compared each one to try and find the best next!\n",
        "# Also the vocab is much longer now"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
