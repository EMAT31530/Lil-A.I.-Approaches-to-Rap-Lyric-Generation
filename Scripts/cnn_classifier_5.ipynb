{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn classifier 5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bJXISN-YhE5"
      },
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "from __future__ import print_function\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from keras import utils as np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx4DD9jdYhrn",
        "outputId": "26dbe84f-3d61-4be3-949f-0999f326497c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkgyEH2dYiA0"
      },
      "source": [
        "# upload txt files for our data\n",
        "# All Rock\n",
        "rock1 = open('/content/drive/My Drive/Colab Notebooks/AllRock.txt', 'r').read()\n",
        "rock = ''.join([i for i in rock1 if not i.isdigit()]).replace(\"\\n\", \" \").lower().replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\").replace(\",\", \"\").replace(\"\", \"\").replace(\"'\", \"\").replace(\")\", \"\").replace(\"(\", \"\").split(' ')\n",
        "# All Pop\n",
        "pop1 = open('/content/drive/My Drive/Colab Notebooks/AllPop.txt', 'r').read()\n",
        "pop = ''.join([i for i in pop1 if not i.isdigit()]).replace(\"\\n\", \" \").lower().replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\").replace(\",\", \"\").replace(\"\", \"\").replace(\"'\", \"\").replace(\")\", \"\").replace(\"(\", \"\").split(' ')\n",
        "# All Country\n",
        "country1 = open('/content/drive/My Drive/Colab Notebooks/AllCountry.txt', 'r').read()\n",
        "country = ''.join([i for i in country1 if not i.isdigit()]).replace(\"\\n\", \" \").lower().replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\").replace(\",\", \"\").replace(\"\", \"\").replace(\"'\", \"\").replace(\")\", \"\").replace(\"(\", \"\").split(' ')\n",
        "# All Rap\n",
        "rap1 = open('/content/drive/My Drive/Colab Notebooks/AllLyrics.txt', 'r').read()\n",
        "rap = ''.join([i for i in rap1 if not i.isdigit()]).replace(\"\\n\", \" \").lower().replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\").replace(\",\", \"\").replace(\"\", \"\").replace(\"'\", \"\").replace(\")\", \"\").replace(\"(\", \"\").split(' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdKMSVXZYpvn"
      },
      "source": [
        "# create samples of 200 words each for each genre - this is our estimate length of song\n",
        "SONG_LENGTH = 200\n",
        "# Rock\n",
        "Rock = [rock[i*SONG_LENGTH:(i+1)*SONG_LENGTH] for i in range(0,int(len(rock)/200))]\n",
        "# Country\n",
        "Country = [country[i*SONG_LENGTH:(i+1)*SONG_LENGTH] for i in range(0,int(len(country)/200))]\n",
        "# Pop\n",
        "Pop = [pop[i*SONG_LENGTH:(i+1)*SONG_LENGTH] for i in range(0,int(len(pop)/200))]\n",
        "# Rap\n",
        "Rap = [rap[i*SONG_LENGTH:(i+1)*SONG_LENGTH] for i in range(0,int(len(rap)/200))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKsBNcRMYqZW"
      },
      "source": [
        "# joining the strings in the samples\n",
        "ds_rock = [' '.join(Rock[i]) for i in range(len(Rock))]\n",
        "ds_country = [' '.join(Country[i]) for i in range(len(Country))]\n",
        "ds_pop = [' '.join(Pop[i]) for i in range(len(Pop))]\n",
        "ds_rap = [' '.join(Rap[i]) for i in range(len(Rap))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv9ruqcxYsj6",
        "outputId": "45f109d0-6eea-4c9e-c92e-80a70c5bfa70"
      },
      "source": [
        "# make a list here where each sample has it's genre number\n",
        "# rock 0, country 1, pop 2, rap 3\n",
        "ds_ro = []\n",
        "genre = 0\n",
        "for sample in ds_rock:\n",
        "  ds_ro.append([genre, sample])\n",
        "\n",
        "ds_co = []\n",
        "genre = 1\n",
        "for sample in ds_country:\n",
        "  ds_co.append([genre, sample])\n",
        "\n",
        "ds_po = []\n",
        "genre = 2\n",
        "for sample in ds_pop:\n",
        "  ds_po.append([genre, sample])\n",
        "\n",
        "ds_ra = []\n",
        "genre = 3\n",
        "for sample in ds_rap:\n",
        "  ds_ra.append([genre, sample])\n",
        "\n",
        "ds = ds_ro+ds_co+ds_po+ds_ra\n",
        "\n",
        "ds = np.array(ds)\n",
        "print('Genres: ', ds[:, 0])\n",
        "print('Lyrics: ', ds[:, 1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Genres:  ['0' '0' '0' ... '3' '3' '3']\n",
            "Lyrics:  ['yesterday all my troubles seemed so far away now it looks as though theyre here to stay oh i believe in yesterday suddenly im not half the man i used to be theres a shadow hanging over me oh yesterday came suddenly why she had to go i dont know she wouldnt say i said something wrong now i long for yesterday yesterday love was such an easy game to play now i need a place to hide away oh i believe in yesterday why she had to go i dont know she wouldnt say i said something wrong now i long for yesterday yesterday love was such an easy game to play now i need a place to hide away oh i believe in yesterday mm mm mm mm mm mm mm when i find myself in times of trouble mother mary comes to me speaking words of wisdom let it be and in my hour of darkness she is standing right in front of me speaking words of wisdom let it be let it be let it be let it be let it be whisper words of wisdom let it be and when the broken hearted people living'\n",
            " 'in the world agree there will be an answer let it be for though they may be parted there is still a chance that they will see there will be an answer let it be let it be let it be let it be let it be there will be an answer let it be let it be let it be let it be let it be whisper words of wisdom let it be let it be let it be let it be let it be whisper words of wisdom let it be and when the night is cloudy there is still a light that shines on me shine until tomorrow let it be i wake up to the sound of music mother mary comes to me speaking words of wisdom let it be let it be let it be let it be yeah let it be there will be an answer let it be let it be let it be let it be yeah let it be whisper words of wisdom let it be words are flowing out like endless rain into a paper cup they slither wildly as they slip away across the universe pools of sorrow waves'\n",
            " 'of joy are drifting through my opened mind possessing and caressing me jai guru deva om nothings gonna change my world nothings gonna change my world nothings gonna change my world nothings gonna change my world images of broken light which dance before me like a million eyes they call me on and on across the universe thoughts meander like a restless wind inside a letter box they tumble blindly as they make their way across the universe jai guru deva om nothings gonna change my world nothings gonna change my world nothings gonna change my world nothings gonna change my world sounds of laughter shades of life are ringing through my opened ears inciting and inviting me limitless undying love which shines around me like a million suns it calls me on and on across the universe jai guru deva om nothings gonna change my world nothings gonna change my world nothings gonna change my world nothings gonna change my world jai guru deva jai guru deva jai guru deva jai guru deva jai guru deva hey jude dont make it bad take a sad song and make it better remember to let her into your heart then you'\n",
            " ...\n",
            " 'that im sick of ninjaz lyin im sick of b*****es hawkin ayo yoyo big ayo chill matter of fact im sick of talkin ayo big ayo big damn we was supposed to rule the world baby we was unstoppable the poop cant be over no the poop cant be over man i know you hear me ninja i know you hear me you got too much livin to do too much unfinished business it aint over live your life well its the funk docta spock methtical biggie biggie mmmhmmmmmm uhh uhh uhh yo cmon big uhh fuck that i preach it my nine reaches the prestigious cats that speak this willie poop flooded pieces my hand releases snatches smack ya cabbage halfass rappers shouldnt have it so i grab it never run the outcome is usually a beatdown brutally frick who you be or where youre from west or east coast squeeze toast leave most in the blood they layin in what what the rings and things you sing about bring em out its hard to yell when the barrels in your mouth its more than i expected i thought your peopleels was rented but they wasnt so run it'\n",
            " 'cousin i could chill the heat doesnt ran up in your shell about a dozen you never see bank like frank white your hand clutchin your chestplate contemplate you bout to die ninja wait keep yo hands high yo yo yo i dont brownnose out of town hoes im up around fo with the crowbar to the five point oh i get bagged im john doe suspect you bum like prime roastin calvin klein clothes explode the pyros when doc guest appear im out there i bought it with george jetson here your time is near so get your body dropped off i stopped trustin ninjaz since gotti got caught its bricks keep your wrist covered or piss colored by the waist got a gun as dark as kris brother icu my sheisty crew like ice me too i break your legs leave your eyes slightly blue the doc was born with a grenade palm im concurrent in your hood like a teenage mom yo biggie what what she havin my baybayy if i pull out the ak keep your hands high this rule is so underrated actin as if it cant happen youre frontin aint no other kings in'\n",
            " 'this rap thing biggie a motherfrickin rap phenomenon this rule is so underrated actin as if it cant happen youre frontin aint no other kings in this rap thing biggie a motherfrickin rap phenomenon uhh uhh i got a new mouth to feed im due south with keys yall pick seeds out yall sandwhiches i watch cowards bleed motherfricker please its my block with my rocks fuck that hiphop them onetwos and you dont stops me and my ninja lance took kim and cees advance bought ten bricks four pounds of sandwhiches plants from branson now we lampin twelve room mansion bitches get naked off get money players anthem dont forget one more chance and my other hits other poop ninjaz spit be counterfeit robbery come actually in and out like frickin rapidly pass the gat to me make his chest rest where his back should be talkin blasphemy blastin me your family rest in coffins often frank wizzard frick you soft or fragilla play hard like reggie miller rapper slash dope dealer slash gorilla slash illest turned killer now now dont approach me with that rah rah poop you out of pocket i take these adolescents back to spofford']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwefSRjmZII8"
      },
      "source": [
        "x = ds[:, 1]\n",
        "y = ds[:, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2Z-G7-tYzLm"
      },
      "source": [
        " # tokenize here\n",
        "tk = Tokenizer(num_words= 200, filters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True, split=\" \")\n",
        "tk.fit_on_texts(x)\n",
        "x = tk.texts_to_sequences(x)\n",
        "x = sequence.pad_sequences(x, maxlen=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KIKqjP5ZQXF"
      },
      "source": [
        "# classification category\n",
        "labelencoder_Y = LabelEncoder()\n",
        "y = labelencoder_Y.fit_transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-fY_sS0ZUVs"
      },
      "source": [
        "# one hot encoding \n",
        "y = np_utils.to_categorical(y, num_classes= 11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf9s-8CeZWlY"
      },
      "source": [
        "np.random.seed(200)\n",
        "indices = np.arange(len(x))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3b1wAVcZYrt"
      },
      "source": [
        "index_from=3\n",
        "start_char = 1\n",
        "if start_char is not None:\n",
        "  x = [[start_char] + [w + index_from for w in x1] for x1 in x]\n",
        "  elif index_from:\n",
        "x = [[w + index_from for w in x1] for x1 in x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_BkAm5hZaLy"
      },
      "source": [
        "num_words = None\n",
        "if not num_words:\n",
        "  num_words = max([max(x1) for x1 in x])\n",
        "\n",
        "  oov_char = 2\n",
        "  skip_top = 0\n",
        "\n",
        "  if oov_char is not None:\n",
        "  x = [[w if (skip_top <= w < num_words) else oov_char for w in x1] for x1 in x]\n",
        "  else:\n",
        "x = [[w for w in x1 if (skip_top <= w < num_words)] for x1 in x]\n",
        "        \n",
        "# split data here\n",
        "test_split = 0.2\n",
        "idx = int(len(x) * (1 - test_split))\n",
        "x_train, y_train = np.array(x[:idx]), np.array(y[:idx])\n",
        "x_test, y_test = np.array(x[idx:]), np.array(y[idx:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbCQnfsSZcWt",
        "outputId": "ffef1a13-fcd5-4e84-fbbd-e99c9855693f"
      },
      "source": [
        "x_train = sequence.pad_sequences(x_train, maxlen=201)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=201)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (2100, 201)\n",
            "x_test shape: (525, 201)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k99cO2KhZfH4",
        "outputId": "4eb21e90-f9c5-482c-a964-f60f823b6e79"
      },
      "source": [
        "max_features = 1000\n",
        "maxlen = 201\n",
        "embedding_dims = 50\n",
        "filters = 250\n",
        "kernel_size = 3\n",
        "hidden_dims = 250\n",
        "\n",
        "\n",
        "# CNN here\n",
        "print('Building model...')\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(max_features,embedding_dims,input_length=maxlen))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# add Convolution1D\n",
        "model.add(Conv1D(filters,kernel_size,padding='valid',activation='relu',strides=1))\n",
        "# max pooling:\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "model.add(Dense(hidden_dims))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(11))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,batch_size=32,epochs=50,validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building model...\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 5s 64ms/step - loss: 1.3926 - accuracy: 0.5762 - val_loss: 0.8574 - val_accuracy: 0.6343\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 4s 57ms/step - loss: 0.8689 - accuracy: 0.6166 - val_loss: 0.6066 - val_accuracy: 0.7581\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 4s 57ms/step - loss: 0.6669 - accuracy: 0.7021 - val_loss: 0.5702 - val_accuracy: 0.7695\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 4s 57ms/step - loss: 0.5929 - accuracy: 0.7595 - val_loss: 0.5294 - val_accuracy: 0.7790\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.5444 - accuracy: 0.7755 - val_loss: 0.5037 - val_accuracy: 0.7714\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 4s 57ms/step - loss: 0.5303 - accuracy: 0.7839 - val_loss: 0.4712 - val_accuracy: 0.7943\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 4s 57ms/step - loss: 0.4324 - accuracy: 0.8303 - val_loss: 0.4963 - val_accuracy: 0.7905\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 4s 57ms/step - loss: 0.3774 - accuracy: 0.8493 - val_loss: 0.4197 - val_accuracy: 0.8267\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 4s 57ms/step - loss: 0.3373 - accuracy: 0.8720 - val_loss: 0.4053 - val_accuracy: 0.8438\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.2671 - accuracy: 0.9026 - val_loss: 0.4034 - val_accuracy: 0.8286\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.2428 - accuracy: 0.9082 - val_loss: 0.4197 - val_accuracy: 0.8343\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.1823 - accuracy: 0.9346 - val_loss: 0.3910 - val_accuracy: 0.8514\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.1567 - accuracy: 0.9501 - val_loss: 0.3795 - val_accuracy: 0.8629\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 4s 57ms/step - loss: 0.1251 - accuracy: 0.9632 - val_loss: 0.3805 - val_accuracy: 0.8705\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0960 - accuracy: 0.9762 - val_loss: 0.4860 - val_accuracy: 0.8343\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 4s 57ms/step - loss: 0.1018 - accuracy: 0.9732 - val_loss: 0.5101 - val_accuracy: 0.8438\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 4s 56ms/step - loss: 0.0687 - accuracy: 0.9811 - val_loss: 0.4316 - val_accuracy: 0.8629\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0493 - accuracy: 0.9893 - val_loss: 0.4827 - val_accuracy: 0.8571\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0408 - accuracy: 0.9916 - val_loss: 0.4499 - val_accuracy: 0.8610\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 4s 57ms/step - loss: 0.0330 - accuracy: 0.9920 - val_loss: 0.4698 - val_accuracy: 0.8457\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0291 - accuracy: 0.9925 - val_loss: 0.4971 - val_accuracy: 0.8571\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0187 - accuracy: 0.9954 - val_loss: 0.5199 - val_accuracy: 0.8571\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.7289 - val_accuracy: 0.8438\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0179 - accuracy: 0.9972 - val_loss: 0.5766 - val_accuracy: 0.8590\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.5357 - val_accuracy: 0.8686\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0101 - accuracy: 0.9987 - val_loss: 0.6141 - val_accuracy: 0.8495\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.5863 - val_accuracy: 0.8533\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.6151 - val_accuracy: 0.8552\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.6091 - val_accuracy: 0.8629\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0122 - accuracy: 0.9970 - val_loss: 0.6250 - val_accuracy: 0.8610\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0162 - accuracy: 0.9957 - val_loss: 0.6362 - val_accuracy: 0.8629\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.6492 - val_accuracy: 0.8686\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0142 - accuracy: 0.9972 - val_loss: 0.7337 - val_accuracy: 0.8590\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0110 - accuracy: 0.9959 - val_loss: 0.6525 - val_accuracy: 0.8610\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.7373 - val_accuracy: 0.8743\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8765 - val_accuracy: 0.8419\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 4s 59ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 0.7555 - val_accuracy: 0.8629\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 4s 57ms/step - loss: 0.0092 - accuracy: 0.9953 - val_loss: 0.8067 - val_accuracy: 0.8552\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.7485 - val_accuracy: 0.8667\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 4s 59ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.8120 - val_accuracy: 0.8590\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.7921 - val_accuracy: 0.8552\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.7443 - val_accuracy: 0.8762\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.7657 - val_accuracy: 0.8724\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 4s 59ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.7795 - val_accuracy: 0.8705\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.9852 - val_accuracy: 0.8438\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 4s 59ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.7913 - val_accuracy: 0.8610\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 3.0973e-04 - accuracy: 1.0000 - val_loss: 0.8619 - val_accuracy: 0.8552\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.8338 - val_accuracy: 0.8590\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.8882 - val_accuracy: 0.8571\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 4s 58ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.8622 - val_accuracy: 0.8629\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6daa5cfc10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vni_9AwmaOq2",
        "outputId": "354fea45-3d67-4322-d1e9-a8dbeb819fd6"
      },
      "source": [
        "accr = model.evaluate(x_test,y_test)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17/17 [==============================] - 0s 15ms/step - loss: 0.8622 - accuracy: 0.8629\n",
            "Test set\n",
            "  Loss: 0.862\n",
            "  Accuracy: 0.863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTpOlmGqa6Kp"
      },
      "source": [
        "def classify_string(input):\n",
        "  lyric = [str(input)]\n",
        "  seq = tk.texts_to_sequences(lyric)\n",
        "  pred = model.predict(seq)\n",
        "  labels = ['rock', 'country', 'pop', 'rap']\n",
        "  print(labels[np.argmax(pred)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGxIQstjbBjj"
      },
      "source": [
        "def classify_list(input):\n",
        "  for lyric in input:\n",
        "    classify_string(lyric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGPXLCrKbD_5",
        "outputId": "924ee207-9813-4473-f083-30189d18717e"
      },
      "source": [
        "# markov generated lyrics\n",
        "lyrics = ['Bumpin i meant for you call my ninja like',\n",
        " 'Biz dont take their baby mommas ninja frick you nasty boy you',\n",
        " 'Shifty sticks and pray and flee the frick all of you',\n",
        " 'Glocks but all ill die slow',\n",
        " 'Wondering if im askin blunt sip champagne range rover been outside for',\n",
        " 'And youre so take that crown two pounds you know',\n",
        " 'Publishing i thought i get witcha can i could cop',\n",
        " 'Miss the more cause you in the right one',\n",
        " 'Onyx and them hoes i love',\n",
        " 'Gat call me puff daddy biggie gots ta like',\n",
        " 'Everything around me shit b***** in ya imma stay yappin when',\n",
        " 'Hum all about fingers in the loot im',\n",
        " 'Rollem up heard whos this yeah keep on top sky is',\n",
        " 'Drunk of ninjaz from now drop to',\n",
        " 'Declinin windin like flypaper neighbor slow down',\n",
        " 'Expensive cars i tote my crew i only got enough heart',\n",
        " 'Lame dudes whos next move but the drugs to spit phrases thatll',\n",
        " 'Guy well its cool and your poop so hard to',\n",
        " 'Clap wit my life in ma little nasty boy',\n",
        " 'Dial you should too much better man played',\n",
        " 'Lali like that you frick doin all mcs have']\n",
        "\n",
        "classify_list(lyrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 201) for input KerasTensor(type_spec=TensorSpec(shape=(None, 201), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
            "country\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 201) for input KerasTensor(type_spec=TensorSpec(shape=(None, 201), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
            "country\n",
            "rock\n",
            "rock\n",
            "rock\n",
            "rock\n",
            "pop\n",
            "country\n",
            "rock\n",
            "rock\n",
            "rock\n",
            "rock\n",
            "pop\n",
            "country\n",
            "rock\n",
            "rock\n",
            "rock\n",
            "rap\n",
            "rock\n",
            "pop\n",
            "rock\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CR5PqhObFrp",
        "outputId": "2a7c8137-5f39-499b-d081-4646bbd982c8"
      },
      "source": [
        "# lstm generated lyrics\n",
        "lyrics2 = ['in the veins hard to explain how i maintain', \n",
        "  'to put my back in the house so i can i wanna flaunt you thats right', \n",
        "  'with the grime of my ninja frick',\n",
        "  'with the ds crept in blastin him you dont want to slit the clits alot',\n",
        "  'used to lick the clits a lot of problems never be the beamer with the goldie sound',\n",
        "  'like a steelo not my steelo oh no thats not my my steelo oh i steelo not my steelo oh no',\n",
        "  'thats not my no steelo bust my no dough day but this sittin bodies not my']\n",
        "\n",
        "classify_list(lyrics2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "country\n",
            "rock\n",
            "country\n",
            "rock\n",
            "pop\n",
            "country\n",
            "rap\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBPXIRtFbV7s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}