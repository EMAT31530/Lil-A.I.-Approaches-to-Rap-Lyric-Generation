{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Classifier_mike_01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bJXISN-YhE5"
      },
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "from __future__ import print_function\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from keras import utils as np_utils\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrt6uXE1fPu-"
      },
      "source": [
        "# SUMMARY\n",
        "# Epochs - 1080\n",
        "# Total training run time - 4353\n",
        "# Training final epoch accuracy - 0.9385\n",
        "# Test accuracy - 0.7333\n",
        "# Macro F1 Score - 0.6499\n",
        "# Markov generated accuracy - 0.8025\n",
        "# RNN generated accuracy - 0.8857"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx4DD9jdYhrn",
        "outputId": "0d03510e-1b56-4105-e60d-83d9b3c5d57c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkgyEH2dYiA0"
      },
      "source": [
        "# All Rock\n",
        "rock1 = open('/content/drive/My Drive/Colab Notebooks/NewAllRock.txt', 'r').read()\n",
        "rock = ''.join([i for i in rock1 if not i.isdigit()]).replace(\"\\n\", \" \").lower().replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\").replace(\",\", \"\").replace(\"\", \"\").replace(\"'\", \"\").replace(\")\", \"\").replace(\"(\", \"\").split(' ')\n",
        "# All Pop\n",
        "pop1 = open('/content/drive/My Drive/Colab Notebooks/NewAllPop.txt', 'r').read()\n",
        "pop = ''.join([i for i in pop1 if not i.isdigit()]).replace(\"\\n\", \" \").lower().replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\").replace(\",\", \"\").replace(\"\", \"\").replace(\"'\", \"\").replace(\")\", \"\").replace(\"(\", \"\").split(' ')\n",
        "# All Country\n",
        "country1 = open('/content/drive/My Drive/Colab Notebooks/NewAllCountry.txt', 'r').read()\n",
        "country = ''.join([i for i in country1 if not i.isdigit()]).replace(\"\\n\", \" \").lower().replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\").replace(\",\", \"\").replace(\"\", \"\").replace(\"'\", \"\").replace(\")\", \"\").replace(\"(\", \"\").split(' ')\n",
        "# All Rap\n",
        "rap1 = open('/content/drive/My Drive/Colab Notebooks/AllLyrics.txt', 'r').read()\n",
        "rap = ''.join([i for i in rap1 if not i.isdigit()]).replace(\"\\n\", \" \").lower().replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\").replace(\",\", \"\").replace(\"\", \"\").replace(\"'\", \"\").replace(\")\", \"\").replace(\"(\", \"\").split(' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdKMSVXZYpvn"
      },
      "source": [
        "# create samples of 10 words each for each genre - this is our estimate length of line\n",
        "SONG_LENGTH = 10\n",
        "# Rock\n",
        "Rock = [rock[i*SONG_LENGTH:(i+1)*SONG_LENGTH] for i in range(0,int(len(rock)/int(SONG_LENGTH)))]\n",
        "# Country\n",
        "Country = [country[i*SONG_LENGTH:(i+1)*SONG_LENGTH] for i in range(0,int(len(country)/int(SONG_LENGTH)))]\n",
        "# Pop\n",
        "Pop = [pop[i*SONG_LENGTH:(i+1)*SONG_LENGTH] for i in range(0,int(len(pop)/int(SONG_LENGTH)))]\n",
        "# Rap\n",
        "Rap = [rap[i*SONG_LENGTH:(i+1)*SONG_LENGTH] for i in range(0,int(len(rap)/int(SONG_LENGTH)))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKsBNcRMYqZW"
      },
      "source": [
        "# joining the strings in the samples\n",
        "ds_rock = [' '.join(Rock[i]) for i in range(len(Rock))]\n",
        "ds_country = [' '.join(Country[i]) for i in range(len(Country))]\n",
        "ds_pop = [' '.join(Pop[i]) for i in range(len(Pop))]\n",
        "ds_rap = [' '.join(Rap[i]) for i in range(len(Rap))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv9ruqcxYsj6",
        "outputId": "573eaaaa-f186-410e-8a13-299a457ff7c9"
      },
      "source": [
        "# make a list here where each sample has it's genre number\n",
        "# rock 0, country 1, pop 2, rap 3\n",
        "ds_ro = []\n",
        "genre = 0\n",
        "for sample in ds_rock:\n",
        "  ds_ro.append([genre, sample])\n",
        "\n",
        "ds_co = []\n",
        "genre = 1\n",
        "for sample in ds_country:\n",
        "  ds_co.append([genre, sample])\n",
        "\n",
        "ds_po = []\n",
        "genre = 2\n",
        "for sample in ds_pop:\n",
        "  ds_po.append([genre, sample])\n",
        "\n",
        "ds_ra = []\n",
        "genre = 3\n",
        "for sample in ds_rap:\n",
        "  ds_ra.append([genre, sample])\n",
        "\n",
        "ds = ds_ro+ds_co+ds_po+ds_ra\n",
        "\n",
        "ds = np.array(ds)\n",
        "print('Genres: ', ds[:, 0])\n",
        "print('Lyrics: ', ds[:, 1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Genres:  ['0' '0' '0' ... '3' '3' '3']\n",
            "Lyrics:  ['theres a lady whos sure all that glitters is gold'\n",
            " 'and shes buying a stairway to heaven when she gets'\n",
            " 'there she knows if the stores are all closed with' ...\n",
            " 'kick me when im down but im up again scorchin'\n",
            " 'hot forcin my way up in the door to kill'\n",
            " 'the bullpoop like a matador keep your hands high what']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwefSRjmZII8"
      },
      "source": [
        "x = ds[:, 1]\n",
        "y = ds[:, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2Z-G7-tYzLm"
      },
      "source": [
        " # Tokenize\n",
        "tk = Tokenizer(num_words= 1000, filters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True, split=\" \")\n",
        "tk.fit_on_texts(x)\n",
        "x = tk.texts_to_sequences(x)\n",
        "x = sequence.pad_sequences(x, maxlen=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KIKqjP5ZQXF"
      },
      "source": [
        "# Classification category\n",
        "labelencoder_Y = LabelEncoder()\n",
        "y = labelencoder_Y.fit_transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-fY_sS0ZUVs"
      },
      "source": [
        "# One hot encoding \n",
        "y = np_utils.to_categorical(y, num_classes= 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf9s-8CeZWlY"
      },
      "source": [
        "np.random.seed(200)\n",
        "indices = np.arange(len(x))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_BkAm5hZaLy"
      },
      "source": [
        "num_words = None\n",
        "if not num_words:\n",
        "  num_words = max([max(x1) for x1 in x])\n",
        "\n",
        "  oov_char = 2\n",
        "  skip_top = 0\n",
        "\n",
        "  if oov_char is not None:\n",
        "    x = [[w if (skip_top <= w < num_words) else oov_char for w in x1] for x1 in x]\n",
        "  else:\n",
        "    x = [[w for w in x1 if (skip_top <= w < num_words)] for x1 in x]\n",
        "        \n",
        "# Splitting data here\n",
        "test_split = 0.2\n",
        "idx = int(len(x) * (1 - test_split))\n",
        "x_train, y_train = np.array(x[:idx]), np.array(y[:idx])\n",
        "x_test, y_test = np.array(x[idx:]), np.array(y[idx:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbCQnfsSZcWt",
        "outputId": "07e44807-bf28-4075-b42c-da53c89db4fc"
      },
      "source": [
        "x_train = sequence.pad_sequences(x_train, maxlen=201)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=201)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (46758, 201)\n",
            "x_test shape: (11690, 201)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k99cO2KhZfH4",
        "outputId": "b83fcfdb-df0a-43f1-832a-555cb5b4828b"
      },
      "source": [
        "max_features = 1000\n",
        "maxlen = 201\n",
        "embedding_dims = 50\n",
        "filters = 250\n",
        "kernel_size = 3\n",
        "hidden_dims = 250\n",
        "load_model = False\n",
        "\n",
        "# CNN here\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(max_features,embedding_dims,input_length=maxlen))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Add Convolution1D\n",
        "model.add(Conv1D(filters,kernel_size,padding='valid',activation='relu',strides=1))\n",
        "# Max pooling:\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "model.add(Dense(hidden_dims))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(4))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "\n",
        "save_path = 'model_save_CNN/cp.ckpt'\n",
        "\n",
        "if not load_model: \n",
        "    model_callback_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "    model_callback_saving = tf.keras.callbacks.ModelCheckpoint(filepath=save_path, save_weights_only=True, verbose=1)\n",
        "\n",
        "    model.fit(x_train, y_train,batch_size=256, epochs=1080, validation_data=(x_test, y_test), callbacks=[model_callback_stopping, model_callback_saving])\n",
        "else:\n",
        "    model.load_weights(save_path)\n",
        "    print('Restored Model')\n",
        "    \n",
        "# On previous run Epoch 1 was 5s, 1.5hrs has 5400s so will run for [5400/5]=1080 epochs on GPU\n",
        "# Does seem to plateau around Epoch 277"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1080\n",
            "183/183 [==============================] - 37s 23ms/step - loss: 1.1301 - accuracy: 0.5413 - val_loss: 0.9802 - val_accuracy: 0.5898\n",
            "Epoch 2/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.9227 - accuracy: 0.6173 - val_loss: 0.9264 - val_accuracy: 0.6166\n",
            "Epoch 3/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.8759 - accuracy: 0.6399 - val_loss: 0.8952 - val_accuracy: 0.6334\n",
            "Epoch 4/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.8235 - accuracy: 0.6680 - val_loss: 0.8757 - val_accuracy: 0.6431\n",
            "Epoch 5/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.7917 - accuracy: 0.6845 - val_loss: 0.8549 - val_accuracy: 0.6604\n",
            "Epoch 6/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.7650 - accuracy: 0.6961 - val_loss: 0.8508 - val_accuracy: 0.6655\n",
            "Epoch 7/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.7148 - accuracy: 0.7224 - val_loss: 0.8219 - val_accuracy: 0.6766\n",
            "Epoch 8/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.6863 - accuracy: 0.7340 - val_loss: 0.8181 - val_accuracy: 0.6814\n",
            "Epoch 9/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.6532 - accuracy: 0.7493 - val_loss: 0.8200 - val_accuracy: 0.6879\n",
            "Epoch 10/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.6326 - accuracy: 0.7572 - val_loss: 0.7973 - val_accuracy: 0.6928\n",
            "Epoch 11/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.5967 - accuracy: 0.7757 - val_loss: 0.8039 - val_accuracy: 0.6862\n",
            "Epoch 12/1080\n",
            "183/183 [==============================] - 4s 19ms/step - loss: 0.5717 - accuracy: 0.7851 - val_loss: 0.7935 - val_accuracy: 0.6938\n",
            "Epoch 13/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.5587 - accuracy: 0.7905 - val_loss: 0.8028 - val_accuracy: 0.7001\n",
            "Epoch 14/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.5392 - accuracy: 0.7949 - val_loss: 0.7887 - val_accuracy: 0.7097\n",
            "Epoch 15/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.5187 - accuracy: 0.8064 - val_loss: 0.8185 - val_accuracy: 0.7080\n",
            "Epoch 16/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.5089 - accuracy: 0.8079 - val_loss: 0.8146 - val_accuracy: 0.7098\n",
            "Epoch 17/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.4859 - accuracy: 0.8180 - val_loss: 0.8081 - val_accuracy: 0.7088\n",
            "Epoch 18/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.4770 - accuracy: 0.8207 - val_loss: 0.8406 - val_accuracy: 0.6941\n",
            "Epoch 19/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.4713 - accuracy: 0.8234 - val_loss: 0.8256 - val_accuracy: 0.7158\n",
            "Epoch 20/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.4597 - accuracy: 0.8290 - val_loss: 0.8380 - val_accuracy: 0.7146\n",
            "Epoch 21/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.4488 - accuracy: 0.8319 - val_loss: 0.8913 - val_accuracy: 0.7089\n",
            "Epoch 22/1080\n",
            "183/183 [==============================] - 4s 19ms/step - loss: 0.4395 - accuracy: 0.8340 - val_loss: 0.8095 - val_accuracy: 0.7161\n",
            "Epoch 23/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.4247 - accuracy: 0.8431 - val_loss: 0.8613 - val_accuracy: 0.7034\n",
            "Epoch 24/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.4233 - accuracy: 0.8411 - val_loss: 0.8184 - val_accuracy: 0.7180\n",
            "Epoch 25/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.4136 - accuracy: 0.8441 - val_loss: 0.8465 - val_accuracy: 0.7108\n",
            "Epoch 26/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.4046 - accuracy: 0.8503 - val_loss: 0.8475 - val_accuracy: 0.7116\n",
            "Epoch 27/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3998 - accuracy: 0.8498 - val_loss: 0.8313 - val_accuracy: 0.7247\n",
            "Epoch 28/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3869 - accuracy: 0.8557 - val_loss: 0.8293 - val_accuracy: 0.7188\n",
            "Epoch 29/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3827 - accuracy: 0.8552 - val_loss: 0.8666 - val_accuracy: 0.7115\n",
            "Epoch 30/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3795 - accuracy: 0.8607 - val_loss: 0.8425 - val_accuracy: 0.7174\n",
            "Epoch 31/1080\n",
            "183/183 [==============================] - 4s 19ms/step - loss: 0.3710 - accuracy: 0.8633 - val_loss: 0.8656 - val_accuracy: 0.7129\n",
            "Epoch 32/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3597 - accuracy: 0.8630 - val_loss: 0.8942 - val_accuracy: 0.7140\n",
            "Epoch 33/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3669 - accuracy: 0.8634 - val_loss: 0.8526 - val_accuracy: 0.7186\n",
            "Epoch 34/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3574 - accuracy: 0.8657 - val_loss: 0.8640 - val_accuracy: 0.7248\n",
            "Epoch 35/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3533 - accuracy: 0.8658 - val_loss: 0.8982 - val_accuracy: 0.7190\n",
            "Epoch 36/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3476 - accuracy: 0.8707 - val_loss: 0.8746 - val_accuracy: 0.7189\n",
            "Epoch 37/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3489 - accuracy: 0.8688 - val_loss: 0.8662 - val_accuracy: 0.7286\n",
            "Epoch 38/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3399 - accuracy: 0.8733 - val_loss: 0.8790 - val_accuracy: 0.7197\n",
            "Epoch 39/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3312 - accuracy: 0.8759 - val_loss: 0.9053 - val_accuracy: 0.7157\n",
            "Epoch 40/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3318 - accuracy: 0.8762 - val_loss: 0.8829 - val_accuracy: 0.7241\n",
            "Epoch 41/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3314 - accuracy: 0.8760 - val_loss: 0.9395 - val_accuracy: 0.7305\n",
            "Epoch 42/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3260 - accuracy: 0.8778 - val_loss: 0.9147 - val_accuracy: 0.7222\n",
            "Epoch 43/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3232 - accuracy: 0.8788 - val_loss: 0.8729 - val_accuracy: 0.7253\n",
            "Epoch 44/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3237 - accuracy: 0.8779 - val_loss: 0.9172 - val_accuracy: 0.7206\n",
            "Epoch 45/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3131 - accuracy: 0.8841 - val_loss: 0.9625 - val_accuracy: 0.7210\n",
            "Epoch 46/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3150 - accuracy: 0.8816 - val_loss: 0.9340 - val_accuracy: 0.7293\n",
            "Epoch 47/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3130 - accuracy: 0.8821 - val_loss: 0.9499 - val_accuracy: 0.7265\n",
            "Epoch 48/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3104 - accuracy: 0.8836 - val_loss: 0.9812 - val_accuracy: 0.7283\n",
            "Epoch 49/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.3057 - accuracy: 0.8851 - val_loss: 0.9204 - val_accuracy: 0.7257\n",
            "Epoch 50/1080\n",
            "183/183 [==============================] - 4s 19ms/step - loss: 0.3047 - accuracy: 0.8860 - val_loss: 0.9581 - val_accuracy: 0.7269\n",
            "Epoch 51/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2952 - accuracy: 0.8884 - val_loss: 0.9230 - val_accuracy: 0.7281\n",
            "Epoch 52/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2919 - accuracy: 0.8890 - val_loss: 0.9410 - val_accuracy: 0.7227\n",
            "Epoch 53/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2949 - accuracy: 0.8896 - val_loss: 0.9166 - val_accuracy: 0.7274\n",
            "Epoch 54/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2862 - accuracy: 0.8943 - val_loss: 0.9304 - val_accuracy: 0.7220\n",
            "Epoch 55/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2937 - accuracy: 0.8903 - val_loss: 0.9830 - val_accuracy: 0.7328\n",
            "Epoch 56/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2876 - accuracy: 0.8923 - val_loss: 0.9735 - val_accuracy: 0.7336\n",
            "Epoch 57/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2883 - accuracy: 0.8893 - val_loss: 0.9410 - val_accuracy: 0.7346\n",
            "Epoch 58/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2827 - accuracy: 0.8941 - val_loss: 0.9533 - val_accuracy: 0.7341\n",
            "Epoch 59/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2838 - accuracy: 0.8946 - val_loss: 0.9829 - val_accuracy: 0.7167\n",
            "Epoch 60/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2808 - accuracy: 0.8939 - val_loss: 0.9898 - val_accuracy: 0.7308\n",
            "Epoch 61/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2758 - accuracy: 0.8965 - val_loss: 0.9535 - val_accuracy: 0.7299\n",
            "Epoch 62/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2694 - accuracy: 0.8986 - val_loss: 1.0332 - val_accuracy: 0.7274\n",
            "Epoch 63/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2737 - accuracy: 0.8987 - val_loss: 1.0275 - val_accuracy: 0.7313\n",
            "Epoch 64/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2634 - accuracy: 0.9003 - val_loss: 1.0075 - val_accuracy: 0.7340\n",
            "Epoch 65/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2747 - accuracy: 0.8966 - val_loss: 0.9746 - val_accuracy: 0.7327\n",
            "Epoch 66/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2708 - accuracy: 0.8997 - val_loss: 0.9683 - val_accuracy: 0.7337\n",
            "Epoch 67/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2670 - accuracy: 0.8982 - val_loss: 0.9823 - val_accuracy: 0.7329\n",
            "Epoch 68/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2640 - accuracy: 0.9014 - val_loss: 0.9935 - val_accuracy: 0.7318\n",
            "Epoch 69/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2611 - accuracy: 0.9031 - val_loss: 1.0502 - val_accuracy: 0.7319\n",
            "Epoch 70/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2532 - accuracy: 0.9046 - val_loss: 0.9930 - val_accuracy: 0.7327\n",
            "Epoch 71/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2603 - accuracy: 0.9034 - val_loss: 1.0107 - val_accuracy: 0.7327\n",
            "Epoch 72/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2596 - accuracy: 0.9047 - val_loss: 1.0171 - val_accuracy: 0.7354\n",
            "Epoch 73/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2524 - accuracy: 0.9045 - val_loss: 1.0164 - val_accuracy: 0.7314\n",
            "Epoch 74/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2549 - accuracy: 0.9041 - val_loss: 1.0093 - val_accuracy: 0.7260\n",
            "Epoch 75/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2520 - accuracy: 0.9046 - val_loss: 1.0324 - val_accuracy: 0.7322\n",
            "Epoch 76/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2512 - accuracy: 0.9047 - val_loss: 0.9861 - val_accuracy: 0.7320\n",
            "Epoch 77/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2506 - accuracy: 0.9060 - val_loss: 1.0558 - val_accuracy: 0.7317\n",
            "Epoch 78/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2477 - accuracy: 0.9080 - val_loss: 1.0411 - val_accuracy: 0.7335\n",
            "Epoch 79/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2476 - accuracy: 0.9068 - val_loss: 1.0623 - val_accuracy: 0.7305\n",
            "Epoch 80/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2461 - accuracy: 0.9088 - val_loss: 1.0625 - val_accuracy: 0.7346\n",
            "Epoch 81/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2537 - accuracy: 0.9056 - val_loss: 1.0371 - val_accuracy: 0.7334\n",
            "Epoch 82/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2489 - accuracy: 0.9060 - val_loss: 1.0474 - val_accuracy: 0.7269\n",
            "Epoch 83/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2406 - accuracy: 0.9117 - val_loss: 1.0655 - val_accuracy: 0.7341\n",
            "Epoch 84/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2408 - accuracy: 0.9110 - val_loss: 1.0650 - val_accuracy: 0.7338\n",
            "Epoch 85/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2387 - accuracy: 0.9120 - val_loss: 1.0993 - val_accuracy: 0.7371\n",
            "Epoch 86/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2404 - accuracy: 0.9105 - val_loss: 1.0820 - val_accuracy: 0.7334\n",
            "Epoch 87/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2376 - accuracy: 0.9112 - val_loss: 1.0404 - val_accuracy: 0.7333\n",
            "Epoch 88/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2372 - accuracy: 0.9141 - val_loss: 1.1230 - val_accuracy: 0.7365\n",
            "Epoch 89/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2340 - accuracy: 0.9113 - val_loss: 1.1094 - val_accuracy: 0.7213\n",
            "Epoch 90/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2377 - accuracy: 0.9106 - val_loss: 1.0994 - val_accuracy: 0.7380\n",
            "Epoch 91/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2341 - accuracy: 0.9130 - val_loss: 1.0755 - val_accuracy: 0.7310\n",
            "Epoch 92/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2367 - accuracy: 0.9126 - val_loss: 1.0777 - val_accuracy: 0.7345\n",
            "Epoch 93/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2312 - accuracy: 0.9127 - val_loss: 1.1063 - val_accuracy: 0.7358\n",
            "Epoch 94/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2294 - accuracy: 0.9156 - val_loss: 1.0775 - val_accuracy: 0.7370\n",
            "Epoch 95/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2277 - accuracy: 0.9164 - val_loss: 1.1134 - val_accuracy: 0.7396\n",
            "Epoch 96/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2289 - accuracy: 0.9139 - val_loss: 1.0714 - val_accuracy: 0.7348\n",
            "Epoch 97/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2310 - accuracy: 0.9132 - val_loss: 1.1626 - val_accuracy: 0.7399\n",
            "Epoch 98/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2283 - accuracy: 0.9163 - val_loss: 1.1347 - val_accuracy: 0.7374\n",
            "Epoch 99/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2242 - accuracy: 0.9158 - val_loss: 1.1055 - val_accuracy: 0.7291\n",
            "Epoch 100/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2277 - accuracy: 0.9151 - val_loss: 1.0665 - val_accuracy: 0.7247\n",
            "Epoch 101/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2214 - accuracy: 0.9183 - val_loss: 1.1302 - val_accuracy: 0.7374\n",
            "Epoch 102/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2224 - accuracy: 0.9171 - val_loss: 1.1193 - val_accuracy: 0.7334\n",
            "Epoch 103/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2189 - accuracy: 0.9186 - val_loss: 1.1270 - val_accuracy: 0.7348\n",
            "Epoch 104/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2195 - accuracy: 0.9195 - val_loss: 1.1343 - val_accuracy: 0.7332\n",
            "Epoch 105/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2186 - accuracy: 0.9199 - val_loss: 1.1533 - val_accuracy: 0.7361\n",
            "Epoch 106/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2240 - accuracy: 0.9180 - val_loss: 1.1311 - val_accuracy: 0.7339\n",
            "Epoch 107/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2151 - accuracy: 0.9200 - val_loss: 1.1287 - val_accuracy: 0.7281\n",
            "Epoch 108/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2246 - accuracy: 0.9171 - val_loss: 1.1661 - val_accuracy: 0.7333\n",
            "Epoch 109/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2188 - accuracy: 0.9203 - val_loss: 1.1502 - val_accuracy: 0.7276\n",
            "Epoch 110/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2162 - accuracy: 0.9206 - val_loss: 1.1472 - val_accuracy: 0.7335\n",
            "Epoch 111/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2154 - accuracy: 0.9208 - val_loss: 1.2129 - val_accuracy: 0.7367\n",
            "Epoch 112/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2215 - accuracy: 0.9180 - val_loss: 1.2124 - val_accuracy: 0.7336\n",
            "Epoch 113/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2119 - accuracy: 0.9216 - val_loss: 1.2037 - val_accuracy: 0.7335\n",
            "Epoch 114/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2139 - accuracy: 0.9216 - val_loss: 1.1742 - val_accuracy: 0.7307\n",
            "Epoch 115/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2127 - accuracy: 0.9217 - val_loss: 1.1431 - val_accuracy: 0.7334\n",
            "Epoch 116/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2201 - accuracy: 0.9200 - val_loss: 1.1829 - val_accuracy: 0.7343\n",
            "Epoch 117/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2023 - accuracy: 0.9247 - val_loss: 1.1839 - val_accuracy: 0.7382\n",
            "Epoch 118/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2110 - accuracy: 0.9223 - val_loss: 1.2710 - val_accuracy: 0.7363\n",
            "Epoch 119/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2205 - accuracy: 0.9198 - val_loss: 1.1745 - val_accuracy: 0.7285\n",
            "Epoch 120/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2180 - accuracy: 0.9210 - val_loss: 1.1820 - val_accuracy: 0.7331\n",
            "Epoch 121/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2022 - accuracy: 0.9256 - val_loss: 1.1566 - val_accuracy: 0.7305\n",
            "Epoch 122/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2132 - accuracy: 0.9188 - val_loss: 1.1592 - val_accuracy: 0.7257\n",
            "Epoch 123/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2096 - accuracy: 0.9224 - val_loss: 1.2117 - val_accuracy: 0.7305\n",
            "Epoch 124/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2009 - accuracy: 0.9267 - val_loss: 1.2047 - val_accuracy: 0.7360\n",
            "Epoch 125/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2012 - accuracy: 0.9232 - val_loss: 1.1827 - val_accuracy: 0.7262\n",
            "Epoch 126/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2049 - accuracy: 0.9252 - val_loss: 1.2730 - val_accuracy: 0.7392\n",
            "Epoch 127/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2095 - accuracy: 0.9216 - val_loss: 1.2383 - val_accuracy: 0.7356\n",
            "Epoch 128/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2077 - accuracy: 0.9248 - val_loss: 1.2131 - val_accuracy: 0.7397\n",
            "Epoch 129/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2050 - accuracy: 0.9241 - val_loss: 1.1743 - val_accuracy: 0.7345\n",
            "Epoch 130/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1982 - accuracy: 0.9285 - val_loss: 1.2086 - val_accuracy: 0.7262\n",
            "Epoch 131/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2122 - accuracy: 0.9223 - val_loss: 1.2077 - val_accuracy: 0.7379\n",
            "Epoch 132/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2037 - accuracy: 0.9256 - val_loss: 1.2348 - val_accuracy: 0.7367\n",
            "Epoch 133/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2080 - accuracy: 0.9234 - val_loss: 1.3045 - val_accuracy: 0.7349\n",
            "Epoch 134/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2011 - accuracy: 0.9262 - val_loss: 1.2050 - val_accuracy: 0.7342\n",
            "Epoch 135/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1988 - accuracy: 0.9273 - val_loss: 1.2184 - val_accuracy: 0.7336\n",
            "Epoch 136/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2016 - accuracy: 0.9266 - val_loss: 1.1952 - val_accuracy: 0.7326\n",
            "Epoch 137/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2030 - accuracy: 0.9271 - val_loss: 1.1994 - val_accuracy: 0.7304\n",
            "Epoch 138/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2013 - accuracy: 0.9252 - val_loss: 1.2706 - val_accuracy: 0.7337\n",
            "Epoch 139/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2030 - accuracy: 0.9254 - val_loss: 1.2507 - val_accuracy: 0.7310\n",
            "Epoch 140/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1998 - accuracy: 0.9266 - val_loss: 1.1744 - val_accuracy: 0.7328\n",
            "Epoch 141/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1951 - accuracy: 0.9282 - val_loss: 1.2790 - val_accuracy: 0.7220\n",
            "Epoch 142/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2023 - accuracy: 0.9253 - val_loss: 1.2403 - val_accuracy: 0.7305\n",
            "Epoch 143/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1959 - accuracy: 0.9291 - val_loss: 1.2020 - val_accuracy: 0.7249\n",
            "Epoch 144/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1976 - accuracy: 0.9296 - val_loss: 1.2133 - val_accuracy: 0.7311\n",
            "Epoch 145/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1921 - accuracy: 0.9286 - val_loss: 1.2531 - val_accuracy: 0.7376\n",
            "Epoch 146/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2014 - accuracy: 0.9275 - val_loss: 1.2075 - val_accuracy: 0.7313\n",
            "Epoch 147/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2016 - accuracy: 0.9280 - val_loss: 1.2268 - val_accuracy: 0.7341\n",
            "Epoch 148/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1996 - accuracy: 0.9281 - val_loss: 1.1808 - val_accuracy: 0.7356\n",
            "Epoch 149/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1926 - accuracy: 0.9301 - val_loss: 1.2392 - val_accuracy: 0.7352\n",
            "Epoch 150/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1882 - accuracy: 0.9323 - val_loss: 1.2502 - val_accuracy: 0.7347\n",
            "Epoch 151/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1918 - accuracy: 0.9301 - val_loss: 1.2794 - val_accuracy: 0.7340\n",
            "Epoch 152/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1940 - accuracy: 0.9287 - val_loss: 1.2221 - val_accuracy: 0.7252\n",
            "Epoch 153/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1932 - accuracy: 0.9273 - val_loss: 1.3307 - val_accuracy: 0.7346\n",
            "Epoch 154/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1891 - accuracy: 0.9328 - val_loss: 1.2246 - val_accuracy: 0.7339\n",
            "Epoch 155/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1888 - accuracy: 0.9298 - val_loss: 1.3079 - val_accuracy: 0.7361\n",
            "Epoch 156/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1962 - accuracy: 0.9287 - val_loss: 1.2898 - val_accuracy: 0.7359\n",
            "Epoch 157/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1987 - accuracy: 0.9280 - val_loss: 1.2720 - val_accuracy: 0.7234\n",
            "Epoch 158/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1932 - accuracy: 0.9296 - val_loss: 1.2435 - val_accuracy: 0.7269\n",
            "Epoch 159/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1921 - accuracy: 0.9293 - val_loss: 1.2416 - val_accuracy: 0.7292\n",
            "Epoch 160/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1929 - accuracy: 0.9280 - val_loss: 1.3420 - val_accuracy: 0.7347\n",
            "Epoch 161/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.2018 - accuracy: 0.9282 - val_loss: 1.2877 - val_accuracy: 0.7334\n",
            "Epoch 162/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1876 - accuracy: 0.9303 - val_loss: 1.3008 - val_accuracy: 0.7330\n",
            "Epoch 163/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1970 - accuracy: 0.9295 - val_loss: 1.3396 - val_accuracy: 0.7322\n",
            "Epoch 164/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1947 - accuracy: 0.9293 - val_loss: 1.2615 - val_accuracy: 0.7311\n",
            "Epoch 165/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1895 - accuracy: 0.9332 - val_loss: 1.3241 - val_accuracy: 0.7350\n",
            "Epoch 166/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1859 - accuracy: 0.9301 - val_loss: 1.3037 - val_accuracy: 0.7249\n",
            "Epoch 167/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1963 - accuracy: 0.9275 - val_loss: 1.2817 - val_accuracy: 0.7303\n",
            "Epoch 168/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1890 - accuracy: 0.9311 - val_loss: 1.3010 - val_accuracy: 0.7321\n",
            "Epoch 169/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1967 - accuracy: 0.9303 - val_loss: 1.3610 - val_accuracy: 0.7347\n",
            "Epoch 170/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1909 - accuracy: 0.9305 - val_loss: 1.3021 - val_accuracy: 0.7325\n",
            "Epoch 171/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1842 - accuracy: 0.9328 - val_loss: 1.3266 - val_accuracy: 0.7332\n",
            "Epoch 172/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1909 - accuracy: 0.9317 - val_loss: 1.3229 - val_accuracy: 0.7363\n",
            "Epoch 173/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1943 - accuracy: 0.9314 - val_loss: 1.3124 - val_accuracy: 0.7336\n",
            "Epoch 174/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1927 - accuracy: 0.9301 - val_loss: 1.3200 - val_accuracy: 0.7330\n",
            "Epoch 175/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1819 - accuracy: 0.9339 - val_loss: 1.3625 - val_accuracy: 0.7359\n",
            "Epoch 176/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1845 - accuracy: 0.9337 - val_loss: 1.3359 - val_accuracy: 0.7358\n",
            "Epoch 177/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1824 - accuracy: 0.9332 - val_loss: 1.3457 - val_accuracy: 0.7307\n",
            "Epoch 178/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1841 - accuracy: 0.9339 - val_loss: 1.3511 - val_accuracy: 0.7360\n",
            "Epoch 179/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1890 - accuracy: 0.9333 - val_loss: 1.3354 - val_accuracy: 0.7277\n",
            "Epoch 180/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1894 - accuracy: 0.9328 - val_loss: 1.2829 - val_accuracy: 0.7368\n",
            "Epoch 181/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1866 - accuracy: 0.9318 - val_loss: 1.2991 - val_accuracy: 0.7323\n",
            "Epoch 182/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1856 - accuracy: 0.9337 - val_loss: 1.3524 - val_accuracy: 0.7333\n",
            "Epoch 183/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1874 - accuracy: 0.9336 - val_loss: 1.3340 - val_accuracy: 0.7327\n",
            "Epoch 184/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1834 - accuracy: 0.9339 - val_loss: 1.3613 - val_accuracy: 0.7355\n",
            "Epoch 185/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1863 - accuracy: 0.9337 - val_loss: 1.3060 - val_accuracy: 0.7364\n",
            "Epoch 186/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1809 - accuracy: 0.9347 - val_loss: 1.3247 - val_accuracy: 0.7307\n",
            "Epoch 187/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1816 - accuracy: 0.9358 - val_loss: 1.3182 - val_accuracy: 0.7327\n",
            "Epoch 188/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1861 - accuracy: 0.9341 - val_loss: 1.3647 - val_accuracy: 0.7329\n",
            "Epoch 189/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1839 - accuracy: 0.9337 - val_loss: 1.3112 - val_accuracy: 0.7364\n",
            "Epoch 190/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1779 - accuracy: 0.9367 - val_loss: 1.3867 - val_accuracy: 0.7287\n",
            "Epoch 191/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1784 - accuracy: 0.9351 - val_loss: 1.3273 - val_accuracy: 0.7304\n",
            "Epoch 192/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1818 - accuracy: 0.9338 - val_loss: 1.4080 - val_accuracy: 0.7367\n",
            "Epoch 193/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1801 - accuracy: 0.9354 - val_loss: 1.2951 - val_accuracy: 0.7279\n",
            "Epoch 194/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1884 - accuracy: 0.9318 - val_loss: 1.3763 - val_accuracy: 0.7360\n",
            "Epoch 195/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1809 - accuracy: 0.9337 - val_loss: 1.4114 - val_accuracy: 0.7338\n",
            "Epoch 196/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1825 - accuracy: 0.9361 - val_loss: 1.3597 - val_accuracy: 0.7305\n",
            "Epoch 197/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1837 - accuracy: 0.9331 - val_loss: 1.4528 - val_accuracy: 0.7342\n",
            "Epoch 198/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1841 - accuracy: 0.9340 - val_loss: 1.3456 - val_accuracy: 0.7328\n",
            "Epoch 199/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1869 - accuracy: 0.9333 - val_loss: 1.3805 - val_accuracy: 0.7302\n",
            "Epoch 200/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1852 - accuracy: 0.9341 - val_loss: 1.3801 - val_accuracy: 0.7299\n",
            "Epoch 201/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1802 - accuracy: 0.9337 - val_loss: 1.3971 - val_accuracy: 0.7348\n",
            "Epoch 202/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1782 - accuracy: 0.9364 - val_loss: 1.3579 - val_accuracy: 0.7297\n",
            "Epoch 203/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1817 - accuracy: 0.9340 - val_loss: 1.3281 - val_accuracy: 0.7303\n",
            "Epoch 204/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1865 - accuracy: 0.9333 - val_loss: 1.4221 - val_accuracy: 0.7358\n",
            "Epoch 205/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1822 - accuracy: 0.9354 - val_loss: 1.2946 - val_accuracy: 0.7287\n",
            "Epoch 206/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1847 - accuracy: 0.9346 - val_loss: 1.3653 - val_accuracy: 0.7322\n",
            "Epoch 207/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1825 - accuracy: 0.9360 - val_loss: 1.3446 - val_accuracy: 0.7341\n",
            "Epoch 208/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1770 - accuracy: 0.9374 - val_loss: 1.4030 - val_accuracy: 0.7388\n",
            "Epoch 209/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1852 - accuracy: 0.9335 - val_loss: 1.2918 - val_accuracy: 0.7315\n",
            "Epoch 210/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1782 - accuracy: 0.9363 - val_loss: 1.3487 - val_accuracy: 0.7323\n",
            "Epoch 211/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1854 - accuracy: 0.9348 - val_loss: 1.3074 - val_accuracy: 0.7299\n",
            "Epoch 212/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1810 - accuracy: 0.9329 - val_loss: 1.3590 - val_accuracy: 0.7329\n",
            "Epoch 213/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1797 - accuracy: 0.9332 - val_loss: 1.3574 - val_accuracy: 0.7287\n",
            "Epoch 214/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1837 - accuracy: 0.9349 - val_loss: 1.4154 - val_accuracy: 0.7305\n",
            "Epoch 215/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1817 - accuracy: 0.9347 - val_loss: 1.2982 - val_accuracy: 0.7316\n",
            "Epoch 216/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1811 - accuracy: 0.9352 - val_loss: 1.3722 - val_accuracy: 0.7328\n",
            "Epoch 217/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1764 - accuracy: 0.9371 - val_loss: 1.4420 - val_accuracy: 0.7281\n",
            "Epoch 218/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1817 - accuracy: 0.9332 - val_loss: 1.3784 - val_accuracy: 0.7340\n",
            "Epoch 219/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1778 - accuracy: 0.9377 - val_loss: 1.3887 - val_accuracy: 0.7314\n",
            "Epoch 220/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1755 - accuracy: 0.9370 - val_loss: 1.3269 - val_accuracy: 0.7328\n",
            "Epoch 221/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1854 - accuracy: 0.9341 - val_loss: 1.3270 - val_accuracy: 0.7251\n",
            "Epoch 222/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1840 - accuracy: 0.9342 - val_loss: 1.3919 - val_accuracy: 0.7267\n",
            "Epoch 223/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1783 - accuracy: 0.9364 - val_loss: 1.3788 - val_accuracy: 0.7276\n",
            "Epoch 224/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1836 - accuracy: 0.9354 - val_loss: 1.3860 - val_accuracy: 0.7319\n",
            "Epoch 225/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1780 - accuracy: 0.9378 - val_loss: 1.3693 - val_accuracy: 0.7285\n",
            "Epoch 226/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1862 - accuracy: 0.9359 - val_loss: 1.4149 - val_accuracy: 0.7226\n",
            "Epoch 227/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1765 - accuracy: 0.9381 - val_loss: 1.4067 - val_accuracy: 0.7296\n",
            "Epoch 228/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1848 - accuracy: 0.9341 - val_loss: 1.3821 - val_accuracy: 0.7314\n",
            "Epoch 229/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1769 - accuracy: 0.9378 - val_loss: 1.4384 - val_accuracy: 0.7334\n",
            "Epoch 230/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1822 - accuracy: 0.9367 - val_loss: 1.3750 - val_accuracy: 0.7321\n",
            "Epoch 231/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1775 - accuracy: 0.9383 - val_loss: 1.4056 - val_accuracy: 0.7387\n",
            "Epoch 232/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1780 - accuracy: 0.9374 - val_loss: 1.3669 - val_accuracy: 0.7311\n",
            "Epoch 233/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1771 - accuracy: 0.9377 - val_loss: 1.4367 - val_accuracy: 0.7309\n",
            "Epoch 234/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1769 - accuracy: 0.9385 - val_loss: 1.3702 - val_accuracy: 0.7360\n",
            "Epoch 235/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1772 - accuracy: 0.9373 - val_loss: 1.4207 - val_accuracy: 0.7345\n",
            "Epoch 236/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1738 - accuracy: 0.9364 - val_loss: 1.4527 - val_accuracy: 0.7337\n",
            "Epoch 237/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1820 - accuracy: 0.9376 - val_loss: 1.3633 - val_accuracy: 0.7270\n",
            "Epoch 238/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1797 - accuracy: 0.9362 - val_loss: 1.3615 - val_accuracy: 0.7316\n",
            "Epoch 239/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1723 - accuracy: 0.9369 - val_loss: 1.4013 - val_accuracy: 0.7346\n",
            "Epoch 240/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1782 - accuracy: 0.9370 - val_loss: 1.4141 - val_accuracy: 0.7235\n",
            "Epoch 241/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1780 - accuracy: 0.9352 - val_loss: 1.4423 - val_accuracy: 0.7340\n",
            "Epoch 242/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1756 - accuracy: 0.9376 - val_loss: 1.3745 - val_accuracy: 0.7264\n",
            "Epoch 243/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1831 - accuracy: 0.9341 - val_loss: 1.4329 - val_accuracy: 0.7350\n",
            "Epoch 244/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1811 - accuracy: 0.9365 - val_loss: 1.3884 - val_accuracy: 0.7303\n",
            "Epoch 245/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1771 - accuracy: 0.9365 - val_loss: 1.4266 - val_accuracy: 0.7340\n",
            "Epoch 246/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1669 - accuracy: 0.9401 - val_loss: 1.5118 - val_accuracy: 0.7348\n",
            "Epoch 247/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1758 - accuracy: 0.9369 - val_loss: 1.4003 - val_accuracy: 0.7302\n",
            "Epoch 248/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1695 - accuracy: 0.9400 - val_loss: 1.4190 - val_accuracy: 0.7362\n",
            "Epoch 249/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1800 - accuracy: 0.9370 - val_loss: 1.3873 - val_accuracy: 0.7358\n",
            "Epoch 250/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1750 - accuracy: 0.9357 - val_loss: 1.3887 - val_accuracy: 0.7338\n",
            "Epoch 251/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1795 - accuracy: 0.9352 - val_loss: 1.3398 - val_accuracy: 0.7306\n",
            "Epoch 252/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1799 - accuracy: 0.9379 - val_loss: 1.3736 - val_accuracy: 0.7376\n",
            "Epoch 253/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1750 - accuracy: 0.9378 - val_loss: 1.4101 - val_accuracy: 0.7301\n",
            "Epoch 254/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1761 - accuracy: 0.9386 - val_loss: 1.4657 - val_accuracy: 0.7350\n",
            "Epoch 255/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1782 - accuracy: 0.9370 - val_loss: 1.4151 - val_accuracy: 0.7308\n",
            "Epoch 256/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1817 - accuracy: 0.9353 - val_loss: 1.3487 - val_accuracy: 0.7344\n",
            "Epoch 257/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1748 - accuracy: 0.9398 - val_loss: 1.4927 - val_accuracy: 0.7380\n",
            "Epoch 258/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1779 - accuracy: 0.9378 - val_loss: 1.3849 - val_accuracy: 0.7382\n",
            "Epoch 259/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1733 - accuracy: 0.9398 - val_loss: 1.3686 - val_accuracy: 0.7268\n",
            "Epoch 260/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1736 - accuracy: 0.9374 - val_loss: 1.4215 - val_accuracy: 0.7360\n",
            "Epoch 261/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1753 - accuracy: 0.9376 - val_loss: 1.4324 - val_accuracy: 0.7353\n",
            "Epoch 262/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1778 - accuracy: 0.9383 - val_loss: 1.4279 - val_accuracy: 0.7349\n",
            "Epoch 263/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1862 - accuracy: 0.9344 - val_loss: 1.4714 - val_accuracy: 0.7409\n",
            "Epoch 264/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1744 - accuracy: 0.9392 - val_loss: 1.4035 - val_accuracy: 0.7321\n",
            "Epoch 265/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1774 - accuracy: 0.9383 - val_loss: 1.4595 - val_accuracy: 0.7289\n",
            "Epoch 266/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1770 - accuracy: 0.9375 - val_loss: 1.3783 - val_accuracy: 0.7304\n",
            "Epoch 267/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1766 - accuracy: 0.9366 - val_loss: 1.3049 - val_accuracy: 0.7332\n",
            "Epoch 268/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1731 - accuracy: 0.9391 - val_loss: 1.4052 - val_accuracy: 0.7342\n",
            "Epoch 269/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1841 - accuracy: 0.9344 - val_loss: 1.4663 - val_accuracy: 0.7374\n",
            "Epoch 270/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1767 - accuracy: 0.9390 - val_loss: 1.3869 - val_accuracy: 0.7295\n",
            "Epoch 271/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1825 - accuracy: 0.9357 - val_loss: 1.3499 - val_accuracy: 0.7261\n",
            "Epoch 272/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1773 - accuracy: 0.9382 - val_loss: 1.4795 - val_accuracy: 0.7357\n",
            "Epoch 273/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1814 - accuracy: 0.9361 - val_loss: 1.4168 - val_accuracy: 0.7241\n",
            "Epoch 274/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1798 - accuracy: 0.9362 - val_loss: 1.4767 - val_accuracy: 0.7373\n",
            "Epoch 275/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1768 - accuracy: 0.9392 - val_loss: 1.4267 - val_accuracy: 0.7293\n",
            "Epoch 276/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1794 - accuracy: 0.9365 - val_loss: 1.4404 - val_accuracy: 0.7267\n",
            "Epoch 277/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1734 - accuracy: 0.9402 - val_loss: 1.4387 - val_accuracy: 0.7239\n",
            "Epoch 278/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1770 - accuracy: 0.9372 - val_loss: 1.4735 - val_accuracy: 0.7303\n",
            "Epoch 279/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1754 - accuracy: 0.9369 - val_loss: 1.3863 - val_accuracy: 0.7292\n",
            "Epoch 280/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1802 - accuracy: 0.9377 - val_loss: 1.5298 - val_accuracy: 0.7350\n",
            "Epoch 281/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1768 - accuracy: 0.9382 - val_loss: 1.4381 - val_accuracy: 0.7293\n",
            "Epoch 282/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1755 - accuracy: 0.9379 - val_loss: 1.4343 - val_accuracy: 0.7332\n",
            "Epoch 283/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1813 - accuracy: 0.9382 - val_loss: 1.4278 - val_accuracy: 0.7302\n",
            "Epoch 284/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1754 - accuracy: 0.9393 - val_loss: 1.4508 - val_accuracy: 0.7391\n",
            "Epoch 285/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1724 - accuracy: 0.9390 - val_loss: 1.4541 - val_accuracy: 0.7328\n",
            "Epoch 286/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1814 - accuracy: 0.9340 - val_loss: 1.3977 - val_accuracy: 0.7330\n",
            "Epoch 287/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1804 - accuracy: 0.9363 - val_loss: 1.3791 - val_accuracy: 0.7315\n",
            "Epoch 288/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1753 - accuracy: 0.9382 - val_loss: 1.4857 - val_accuracy: 0.7321\n",
            "Epoch 289/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1807 - accuracy: 0.9346 - val_loss: 1.4523 - val_accuracy: 0.7282\n",
            "Epoch 290/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1858 - accuracy: 0.9339 - val_loss: 1.3599 - val_accuracy: 0.7282\n",
            "Epoch 291/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1794 - accuracy: 0.9376 - val_loss: 1.3778 - val_accuracy: 0.7286\n",
            "Epoch 292/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1810 - accuracy: 0.9390 - val_loss: 1.4448 - val_accuracy: 0.7317\n",
            "Epoch 293/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1770 - accuracy: 0.9383 - val_loss: 1.3886 - val_accuracy: 0.7315\n",
            "Epoch 294/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1773 - accuracy: 0.9371 - val_loss: 1.3977 - val_accuracy: 0.7347\n",
            "Epoch 295/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1791 - accuracy: 0.9367 - val_loss: 1.4514 - val_accuracy: 0.7342\n",
            "Epoch 296/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1849 - accuracy: 0.9352 - val_loss: 1.4088 - val_accuracy: 0.7311\n",
            "Epoch 297/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1720 - accuracy: 0.9402 - val_loss: 1.4169 - val_accuracy: 0.7286\n",
            "Epoch 298/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1789 - accuracy: 0.9367 - val_loss: 1.5050 - val_accuracy: 0.7350\n",
            "Epoch 299/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1794 - accuracy: 0.9392 - val_loss: 1.3778 - val_accuracy: 0.7291\n",
            "Epoch 300/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1760 - accuracy: 0.9396 - val_loss: 1.4302 - val_accuracy: 0.7352\n",
            "Epoch 301/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1738 - accuracy: 0.9407 - val_loss: 1.4554 - val_accuracy: 0.7263\n",
            "Epoch 302/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1779 - accuracy: 0.9368 - val_loss: 1.4545 - val_accuracy: 0.7307\n",
            "Epoch 303/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1817 - accuracy: 0.9363 - val_loss: 1.6041 - val_accuracy: 0.7366\n",
            "Epoch 304/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1778 - accuracy: 0.9370 - val_loss: 1.4484 - val_accuracy: 0.7362\n",
            "Epoch 305/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1799 - accuracy: 0.9385 - val_loss: 1.4097 - val_accuracy: 0.7333\n",
            "Epoch 306/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1793 - accuracy: 0.9361 - val_loss: 1.3935 - val_accuracy: 0.7328\n",
            "Epoch 307/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1832 - accuracy: 0.9368 - val_loss: 1.4411 - val_accuracy: 0.7058\n",
            "Epoch 308/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1773 - accuracy: 0.9386 - val_loss: 1.4384 - val_accuracy: 0.7268\n",
            "Epoch 309/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1809 - accuracy: 0.9354 - val_loss: 1.5060 - val_accuracy: 0.7352\n",
            "Epoch 310/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1790 - accuracy: 0.9384 - val_loss: 1.3953 - val_accuracy: 0.7352\n",
            "Epoch 311/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1782 - accuracy: 0.9355 - val_loss: 1.3891 - val_accuracy: 0.7298\n",
            "Epoch 312/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1752 - accuracy: 0.9371 - val_loss: 1.4283 - val_accuracy: 0.7276\n",
            "Epoch 313/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1747 - accuracy: 0.9380 - val_loss: 1.4797 - val_accuracy: 0.7291\n",
            "Epoch 314/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1810 - accuracy: 0.9348 - val_loss: 1.3869 - val_accuracy: 0.7319\n",
            "Epoch 315/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1741 - accuracy: 0.9386 - val_loss: 1.5087 - val_accuracy: 0.7259\n",
            "Epoch 316/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1788 - accuracy: 0.9362 - val_loss: 1.4747 - val_accuracy: 0.7319\n",
            "Epoch 317/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1773 - accuracy: 0.9371 - val_loss: 1.4157 - val_accuracy: 0.7331\n",
            "Epoch 318/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1759 - accuracy: 0.9396 - val_loss: 1.4058 - val_accuracy: 0.7329\n",
            "Epoch 319/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1793 - accuracy: 0.9379 - val_loss: 1.4302 - val_accuracy: 0.7337\n",
            "Epoch 320/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1789 - accuracy: 0.9372 - val_loss: 1.4673 - val_accuracy: 0.7341\n",
            "Epoch 321/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1691 - accuracy: 0.9405 - val_loss: 1.3859 - val_accuracy: 0.7148\n",
            "Epoch 322/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1736 - accuracy: 0.9393 - val_loss: 1.4211 - val_accuracy: 0.7287\n",
            "Epoch 323/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1768 - accuracy: 0.9401 - val_loss: 1.4285 - val_accuracy: 0.7341\n",
            "Epoch 324/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1798 - accuracy: 0.9375 - val_loss: 1.4619 - val_accuracy: 0.7299\n",
            "Epoch 325/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1792 - accuracy: 0.9375 - val_loss: 1.4512 - val_accuracy: 0.7358\n",
            "Epoch 326/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1793 - accuracy: 0.9367 - val_loss: 1.3839 - val_accuracy: 0.7307\n",
            "Epoch 327/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1754 - accuracy: 0.9386 - val_loss: 1.4289 - val_accuracy: 0.7328\n",
            "Epoch 328/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1734 - accuracy: 0.9388 - val_loss: 1.4995 - val_accuracy: 0.7352\n",
            "Epoch 329/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1740 - accuracy: 0.9391 - val_loss: 1.3920 - val_accuracy: 0.7321\n",
            "Epoch 330/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1819 - accuracy: 0.9361 - val_loss: 1.4267 - val_accuracy: 0.7347\n",
            "Epoch 331/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1752 - accuracy: 0.9385 - val_loss: 1.4487 - val_accuracy: 0.7233\n",
            "Epoch 332/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1755 - accuracy: 0.9385 - val_loss: 1.4373 - val_accuracy: 0.7257\n",
            "Epoch 333/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1778 - accuracy: 0.9372 - val_loss: 1.4317 - val_accuracy: 0.7281\n",
            "Epoch 334/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1766 - accuracy: 0.9387 - val_loss: 1.3950 - val_accuracy: 0.7269\n",
            "Epoch 335/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1775 - accuracy: 0.9382 - val_loss: 1.4875 - val_accuracy: 0.7369\n",
            "Epoch 336/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1770 - accuracy: 0.9373 - val_loss: 1.3979 - val_accuracy: 0.7228\n",
            "Epoch 337/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1807 - accuracy: 0.9372 - val_loss: 1.3685 - val_accuracy: 0.7265\n",
            "Epoch 338/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1725 - accuracy: 0.9402 - val_loss: 1.4892 - val_accuracy: 0.7327\n",
            "Epoch 339/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1727 - accuracy: 0.9397 - val_loss: 1.4429 - val_accuracy: 0.7318\n",
            "Epoch 340/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1737 - accuracy: 0.9394 - val_loss: 1.5163 - val_accuracy: 0.7298\n",
            "Epoch 341/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1786 - accuracy: 0.9400 - val_loss: 1.4061 - val_accuracy: 0.7342\n",
            "Epoch 342/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1741 - accuracy: 0.9393 - val_loss: 1.4191 - val_accuracy: 0.7340\n",
            "Epoch 343/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1720 - accuracy: 0.9384 - val_loss: 1.4525 - val_accuracy: 0.7352\n",
            "Epoch 344/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1821 - accuracy: 0.9371 - val_loss: 1.4758 - val_accuracy: 0.7293\n",
            "Epoch 345/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1759 - accuracy: 0.9382 - val_loss: 1.5001 - val_accuracy: 0.7321\n",
            "Epoch 346/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1753 - accuracy: 0.9408 - val_loss: 1.4730 - val_accuracy: 0.7281\n",
            "Epoch 347/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1734 - accuracy: 0.9390 - val_loss: 1.5325 - val_accuracy: 0.7323\n",
            "Epoch 348/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1750 - accuracy: 0.9395 - val_loss: 1.5276 - val_accuracy: 0.7329\n",
            "Epoch 349/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1746 - accuracy: 0.9386 - val_loss: 1.4866 - val_accuracy: 0.7358\n",
            "Epoch 350/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1817 - accuracy: 0.9382 - val_loss: 1.3915 - val_accuracy: 0.7323\n",
            "Epoch 351/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1796 - accuracy: 0.9363 - val_loss: 1.4027 - val_accuracy: 0.7311\n",
            "Epoch 352/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1715 - accuracy: 0.9393 - val_loss: 1.4070 - val_accuracy: 0.7311\n",
            "Epoch 353/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1813 - accuracy: 0.9353 - val_loss: 1.4585 - val_accuracy: 0.7348\n",
            "Epoch 354/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1814 - accuracy: 0.9382 - val_loss: 1.4735 - val_accuracy: 0.7356\n",
            "Epoch 355/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1776 - accuracy: 0.9359 - val_loss: 1.4338 - val_accuracy: 0.7280\n",
            "Epoch 356/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1773 - accuracy: 0.9383 - val_loss: 1.4391 - val_accuracy: 0.7334\n",
            "Epoch 357/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1771 - accuracy: 0.9387 - val_loss: 1.4209 - val_accuracy: 0.7374\n",
            "Epoch 358/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1762 - accuracy: 0.9391 - val_loss: 1.4835 - val_accuracy: 0.7331\n",
            "Epoch 359/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1772 - accuracy: 0.9368 - val_loss: 1.4385 - val_accuracy: 0.7357\n",
            "Epoch 360/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1779 - accuracy: 0.9368 - val_loss: 1.3772 - val_accuracy: 0.7323\n",
            "Epoch 361/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1770 - accuracy: 0.9387 - val_loss: 1.3903 - val_accuracy: 0.7299\n",
            "Epoch 362/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1754 - accuracy: 0.9418 - val_loss: 1.4391 - val_accuracy: 0.7309\n",
            "Epoch 363/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1739 - accuracy: 0.9409 - val_loss: 1.3852 - val_accuracy: 0.7341\n",
            "Epoch 364/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1828 - accuracy: 0.9380 - val_loss: 1.4477 - val_accuracy: 0.7348\n",
            "Epoch 365/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1802 - accuracy: 0.9364 - val_loss: 1.4708 - val_accuracy: 0.7310\n",
            "Epoch 366/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1848 - accuracy: 0.9373 - val_loss: 1.5157 - val_accuracy: 0.7326\n",
            "Epoch 367/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1728 - accuracy: 0.9418 - val_loss: 1.3914 - val_accuracy: 0.7267\n",
            "Epoch 368/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1865 - accuracy: 0.9335 - val_loss: 1.4628 - val_accuracy: 0.7281\n",
            "Epoch 369/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1778 - accuracy: 0.9388 - val_loss: 1.4097 - val_accuracy: 0.7334\n",
            "Epoch 370/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1808 - accuracy: 0.9380 - val_loss: 1.3845 - val_accuracy: 0.7310\n",
            "Epoch 371/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1800 - accuracy: 0.9371 - val_loss: 1.4137 - val_accuracy: 0.7350\n",
            "Epoch 372/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1766 - accuracy: 0.9394 - val_loss: 1.5481 - val_accuracy: 0.7375\n",
            "Epoch 373/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1833 - accuracy: 0.9370 - val_loss: 1.4566 - val_accuracy: 0.7265\n",
            "Epoch 374/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1752 - accuracy: 0.9399 - val_loss: 1.3590 - val_accuracy: 0.7364\n",
            "Epoch 375/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1847 - accuracy: 0.9370 - val_loss: 1.4013 - val_accuracy: 0.7338\n",
            "Epoch 376/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1746 - accuracy: 0.9397 - val_loss: 1.4488 - val_accuracy: 0.7364\n",
            "Epoch 377/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1798 - accuracy: 0.9387 - val_loss: 1.4295 - val_accuracy: 0.7347\n",
            "Epoch 378/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1760 - accuracy: 0.9392 - val_loss: 1.4312 - val_accuracy: 0.7320\n",
            "Epoch 379/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1873 - accuracy: 0.9357 - val_loss: 1.4554 - val_accuracy: 0.7395\n",
            "Epoch 380/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1691 - accuracy: 0.9409 - val_loss: 1.4126 - val_accuracy: 0.7324\n",
            "Epoch 381/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1707 - accuracy: 0.9406 - val_loss: 1.4344 - val_accuracy: 0.7350\n",
            "Epoch 382/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1778 - accuracy: 0.9393 - val_loss: 1.4433 - val_accuracy: 0.7272\n",
            "Epoch 383/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1804 - accuracy: 0.9373 - val_loss: 1.4198 - val_accuracy: 0.7333\n",
            "Epoch 384/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1805 - accuracy: 0.9378 - val_loss: 1.4040 - val_accuracy: 0.7321\n",
            "Epoch 385/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1852 - accuracy: 0.9359 - val_loss: 1.4568 - val_accuracy: 0.7348\n",
            "Epoch 386/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1850 - accuracy: 0.9375 - val_loss: 1.4513 - val_accuracy: 0.7370\n",
            "Epoch 387/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1796 - accuracy: 0.9368 - val_loss: 1.4724 - val_accuracy: 0.7358\n",
            "Epoch 388/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1745 - accuracy: 0.9398 - val_loss: 1.5012 - val_accuracy: 0.7242\n",
            "Epoch 389/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1766 - accuracy: 0.9381 - val_loss: 1.4628 - val_accuracy: 0.7327\n",
            "Epoch 390/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1835 - accuracy: 0.9355 - val_loss: 1.4482 - val_accuracy: 0.7295\n",
            "Epoch 391/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1843 - accuracy: 0.9371 - val_loss: 1.4387 - val_accuracy: 0.7333\n",
            "Epoch 392/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1832 - accuracy: 0.9368 - val_loss: 1.4734 - val_accuracy: 0.7326\n",
            "Epoch 393/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1785 - accuracy: 0.9405 - val_loss: 1.4509 - val_accuracy: 0.7295\n",
            "Epoch 394/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1780 - accuracy: 0.9404 - val_loss: 1.4069 - val_accuracy: 0.7345\n",
            "Epoch 395/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1786 - accuracy: 0.9378 - val_loss: 1.3772 - val_accuracy: 0.7335\n",
            "Epoch 396/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1694 - accuracy: 0.9414 - val_loss: 1.4444 - val_accuracy: 0.7322\n",
            "Epoch 397/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1845 - accuracy: 0.9375 - val_loss: 1.3860 - val_accuracy: 0.7331\n",
            "Epoch 398/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1823 - accuracy: 0.9366 - val_loss: 1.4348 - val_accuracy: 0.7352\n",
            "Epoch 399/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1763 - accuracy: 0.9386 - val_loss: 1.4028 - val_accuracy: 0.7309\n",
            "Epoch 400/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1818 - accuracy: 0.9385 - val_loss: 1.4587 - val_accuracy: 0.7365\n",
            "Epoch 401/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1815 - accuracy: 0.9365 - val_loss: 1.4622 - val_accuracy: 0.7240\n",
            "Epoch 402/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1800 - accuracy: 0.9360 - val_loss: 1.5325 - val_accuracy: 0.7332\n",
            "Epoch 403/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1792 - accuracy: 0.9403 - val_loss: 1.5120 - val_accuracy: 0.7349\n",
            "Epoch 404/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1833 - accuracy: 0.9360 - val_loss: 1.4250 - val_accuracy: 0.7334\n",
            "Epoch 405/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1750 - accuracy: 0.9396 - val_loss: 1.3968 - val_accuracy: 0.7297\n",
            "Epoch 406/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1839 - accuracy: 0.9357 - val_loss: 1.5220 - val_accuracy: 0.7328\n",
            "Epoch 407/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1861 - accuracy: 0.9350 - val_loss: 1.3909 - val_accuracy: 0.7334\n",
            "Epoch 408/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1797 - accuracy: 0.9376 - val_loss: 1.4658 - val_accuracy: 0.7277\n",
            "Epoch 409/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1791 - accuracy: 0.9368 - val_loss: 1.4652 - val_accuracy: 0.7372\n",
            "Epoch 410/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1766 - accuracy: 0.9389 - val_loss: 1.4297 - val_accuracy: 0.7379\n",
            "Epoch 411/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1787 - accuracy: 0.9377 - val_loss: 1.4269 - val_accuracy: 0.7298\n",
            "Epoch 412/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1895 - accuracy: 0.9346 - val_loss: 1.4812 - val_accuracy: 0.7257\n",
            "Epoch 413/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1835 - accuracy: 0.9369 - val_loss: 1.5081 - val_accuracy: 0.7331\n",
            "Epoch 414/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1712 - accuracy: 0.9400 - val_loss: 1.3864 - val_accuracy: 0.7349\n",
            "Epoch 415/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1798 - accuracy: 0.9366 - val_loss: 1.4958 - val_accuracy: 0.7318\n",
            "Epoch 416/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1793 - accuracy: 0.9386 - val_loss: 1.5425 - val_accuracy: 0.7324\n",
            "Epoch 417/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1817 - accuracy: 0.9390 - val_loss: 1.4342 - val_accuracy: 0.7364\n",
            "Epoch 418/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1858 - accuracy: 0.9355 - val_loss: 1.5212 - val_accuracy: 0.7266\n",
            "Epoch 419/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1753 - accuracy: 0.9401 - val_loss: 1.4648 - val_accuracy: 0.7393\n",
            "Epoch 420/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1792 - accuracy: 0.9384 - val_loss: 1.4375 - val_accuracy: 0.7358\n",
            "Epoch 421/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1771 - accuracy: 0.9399 - val_loss: 1.4823 - val_accuracy: 0.7320\n",
            "Epoch 422/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1796 - accuracy: 0.9388 - val_loss: 1.4406 - val_accuracy: 0.7367\n",
            "Epoch 423/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1771 - accuracy: 0.9396 - val_loss: 1.4742 - val_accuracy: 0.7358\n",
            "Epoch 424/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1774 - accuracy: 0.9386 - val_loss: 1.5174 - val_accuracy: 0.7365\n",
            "Epoch 425/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1811 - accuracy: 0.9374 - val_loss: 1.4571 - val_accuracy: 0.7273\n",
            "Epoch 426/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1837 - accuracy: 0.9365 - val_loss: 1.4553 - val_accuracy: 0.7370\n",
            "Epoch 427/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1796 - accuracy: 0.9379 - val_loss: 1.4481 - val_accuracy: 0.7352\n",
            "Epoch 428/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1857 - accuracy: 0.9363 - val_loss: 1.4442 - val_accuracy: 0.7361\n",
            "Epoch 429/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1829 - accuracy: 0.9382 - val_loss: 1.4390 - val_accuracy: 0.7352\n",
            "Epoch 430/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1784 - accuracy: 0.9403 - val_loss: 1.3962 - val_accuracy: 0.7325\n",
            "Epoch 431/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1763 - accuracy: 0.9395 - val_loss: 1.4205 - val_accuracy: 0.7320\n",
            "Epoch 432/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1745 - accuracy: 0.9389 - val_loss: 1.4132 - val_accuracy: 0.7318\n",
            "Epoch 433/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1798 - accuracy: 0.9376 - val_loss: 1.4830 - val_accuracy: 0.7328\n",
            "Epoch 434/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1859 - accuracy: 0.9387 - val_loss: 1.4647 - val_accuracy: 0.7385\n",
            "Epoch 435/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1765 - accuracy: 0.9404 - val_loss: 1.5018 - val_accuracy: 0.7383\n",
            "Epoch 436/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1821 - accuracy: 0.9384 - val_loss: 1.4745 - val_accuracy: 0.7317\n",
            "Epoch 437/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1823 - accuracy: 0.9366 - val_loss: 1.5119 - val_accuracy: 0.7313\n",
            "Epoch 438/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1822 - accuracy: 0.9389 - val_loss: 1.4340 - val_accuracy: 0.7268\n",
            "Epoch 439/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1772 - accuracy: 0.9379 - val_loss: 1.5257 - val_accuracy: 0.7384\n",
            "Epoch 440/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1781 - accuracy: 0.9380 - val_loss: 1.4953 - val_accuracy: 0.7318\n",
            "Epoch 441/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1761 - accuracy: 0.9395 - val_loss: 1.4778 - val_accuracy: 0.7367\n",
            "Epoch 442/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1868 - accuracy: 0.9371 - val_loss: 1.4572 - val_accuracy: 0.7296\n",
            "Epoch 443/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1780 - accuracy: 0.9382 - val_loss: 1.4704 - val_accuracy: 0.7296\n",
            "Epoch 444/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1824 - accuracy: 0.9383 - val_loss: 1.4697 - val_accuracy: 0.7246\n",
            "Epoch 445/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1806 - accuracy: 0.9371 - val_loss: 1.4845 - val_accuracy: 0.7368\n",
            "Epoch 446/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1778 - accuracy: 0.9383 - val_loss: 1.4979 - val_accuracy: 0.7377\n",
            "Epoch 447/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1815 - accuracy: 0.9369 - val_loss: 1.5281 - val_accuracy: 0.7386\n",
            "Epoch 448/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1741 - accuracy: 0.9404 - val_loss: 1.4688 - val_accuracy: 0.7371\n",
            "Epoch 449/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1812 - accuracy: 0.9383 - val_loss: 1.4789 - val_accuracy: 0.7344\n",
            "Epoch 450/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1813 - accuracy: 0.9368 - val_loss: 1.4627 - val_accuracy: 0.7354\n",
            "Epoch 451/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1770 - accuracy: 0.9395 - val_loss: 1.3950 - val_accuracy: 0.7373\n",
            "Epoch 452/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1835 - accuracy: 0.9368 - val_loss: 1.4501 - val_accuracy: 0.7376\n",
            "Epoch 453/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1778 - accuracy: 0.9395 - val_loss: 1.4737 - val_accuracy: 0.7378\n",
            "Epoch 454/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1803 - accuracy: 0.9366 - val_loss: 1.5084 - val_accuracy: 0.7385\n",
            "Epoch 455/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1815 - accuracy: 0.9361 - val_loss: 1.4416 - val_accuracy: 0.7315\n",
            "Epoch 456/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1798 - accuracy: 0.9383 - val_loss: 1.4882 - val_accuracy: 0.7376\n",
            "Epoch 457/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1828 - accuracy: 0.9373 - val_loss: 1.4954 - val_accuracy: 0.7357\n",
            "Epoch 458/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1806 - accuracy: 0.9381 - val_loss: 1.4410 - val_accuracy: 0.7314\n",
            "Epoch 459/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1786 - accuracy: 0.9390 - val_loss: 1.5294 - val_accuracy: 0.7307\n",
            "Epoch 460/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1796 - accuracy: 0.9382 - val_loss: 1.4803 - val_accuracy: 0.7351\n",
            "Epoch 461/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1750 - accuracy: 0.9415 - val_loss: 1.4253 - val_accuracy: 0.7328\n",
            "Epoch 462/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1798 - accuracy: 0.9376 - val_loss: 1.4961 - val_accuracy: 0.7370\n",
            "Epoch 463/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1818 - accuracy: 0.9384 - val_loss: 1.5083 - val_accuracy: 0.7337\n",
            "Epoch 464/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1849 - accuracy: 0.9365 - val_loss: 1.5599 - val_accuracy: 0.7294\n",
            "Epoch 465/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1798 - accuracy: 0.9375 - val_loss: 1.4606 - val_accuracy: 0.7322\n",
            "Epoch 466/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1799 - accuracy: 0.9394 - val_loss: 1.4264 - val_accuracy: 0.7359\n",
            "Epoch 467/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1769 - accuracy: 0.9394 - val_loss: 1.4792 - val_accuracy: 0.7364\n",
            "Epoch 468/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1778 - accuracy: 0.9392 - val_loss: 1.4983 - val_accuracy: 0.7393\n",
            "Epoch 469/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1842 - accuracy: 0.9381 - val_loss: 1.4248 - val_accuracy: 0.7377\n",
            "Epoch 470/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1786 - accuracy: 0.9378 - val_loss: 1.5084 - val_accuracy: 0.7311\n",
            "Epoch 471/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1827 - accuracy: 0.9369 - val_loss: 1.4475 - val_accuracy: 0.7375\n",
            "Epoch 472/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1816 - accuracy: 0.9377 - val_loss: 1.4697 - val_accuracy: 0.7377\n",
            "Epoch 473/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1736 - accuracy: 0.9397 - val_loss: 1.4937 - val_accuracy: 0.7270\n",
            "Epoch 474/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1803 - accuracy: 0.9407 - val_loss: 1.5438 - val_accuracy: 0.7340\n",
            "Epoch 475/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1781 - accuracy: 0.9399 - val_loss: 1.4624 - val_accuracy: 0.7314\n",
            "Epoch 476/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1724 - accuracy: 0.9405 - val_loss: 1.4167 - val_accuracy: 0.7360\n",
            "Epoch 477/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1834 - accuracy: 0.9373 - val_loss: 1.4800 - val_accuracy: 0.7353\n",
            "Epoch 478/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1801 - accuracy: 0.9386 - val_loss: 1.4894 - val_accuracy: 0.7390\n",
            "Epoch 479/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1864 - accuracy: 0.9363 - val_loss: 1.4974 - val_accuracy: 0.7334\n",
            "Epoch 480/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1755 - accuracy: 0.9389 - val_loss: 1.4652 - val_accuracy: 0.7343\n",
            "Epoch 481/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1804 - accuracy: 0.9389 - val_loss: 1.4293 - val_accuracy: 0.7358\n",
            "Epoch 482/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1848 - accuracy: 0.9388 - val_loss: 1.4403 - val_accuracy: 0.7356\n",
            "Epoch 483/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1770 - accuracy: 0.9393 - val_loss: 1.5088 - val_accuracy: 0.7358\n",
            "Epoch 484/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1851 - accuracy: 0.9381 - val_loss: 1.4092 - val_accuracy: 0.7360\n",
            "Epoch 485/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1756 - accuracy: 0.9384 - val_loss: 1.5128 - val_accuracy: 0.7342\n",
            "Epoch 486/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1900 - accuracy: 0.9348 - val_loss: 1.4639 - val_accuracy: 0.7281\n",
            "Epoch 487/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1857 - accuracy: 0.9350 - val_loss: 1.5207 - val_accuracy: 0.7305\n",
            "Epoch 488/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1776 - accuracy: 0.9380 - val_loss: 1.5569 - val_accuracy: 0.7336\n",
            "Epoch 489/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1863 - accuracy: 0.9370 - val_loss: 1.4621 - val_accuracy: 0.7366\n",
            "Epoch 490/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1790 - accuracy: 0.9396 - val_loss: 1.4418 - val_accuracy: 0.7285\n",
            "Epoch 491/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1881 - accuracy: 0.9355 - val_loss: 1.4560 - val_accuracy: 0.7345\n",
            "Epoch 492/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1788 - accuracy: 0.9381 - val_loss: 1.4834 - val_accuracy: 0.7259\n",
            "Epoch 493/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1903 - accuracy: 0.9353 - val_loss: 1.4500 - val_accuracy: 0.7316\n",
            "Epoch 494/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1774 - accuracy: 0.9405 - val_loss: 1.5199 - val_accuracy: 0.7325\n",
            "Epoch 495/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1881 - accuracy: 0.9353 - val_loss: 1.4705 - val_accuracy: 0.7352\n",
            "Epoch 496/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1750 - accuracy: 0.9388 - val_loss: 1.5097 - val_accuracy: 0.7368\n",
            "Epoch 497/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1860 - accuracy: 0.9376 - val_loss: 1.4943 - val_accuracy: 0.7350\n",
            "Epoch 498/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1759 - accuracy: 0.9382 - val_loss: 1.4626 - val_accuracy: 0.7351\n",
            "Epoch 499/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1917 - accuracy: 0.9345 - val_loss: 1.4477 - val_accuracy: 0.7388\n",
            "Epoch 500/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1732 - accuracy: 0.9401 - val_loss: 1.4543 - val_accuracy: 0.7332\n",
            "Epoch 501/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1789 - accuracy: 0.9379 - val_loss: 1.5359 - val_accuracy: 0.7372\n",
            "Epoch 502/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1808 - accuracy: 0.9386 - val_loss: 1.4593 - val_accuracy: 0.7246\n",
            "Epoch 503/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1848 - accuracy: 0.9348 - val_loss: 1.3900 - val_accuracy: 0.7339\n",
            "Epoch 504/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1773 - accuracy: 0.9381 - val_loss: 1.5085 - val_accuracy: 0.7358\n",
            "Epoch 505/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1750 - accuracy: 0.9400 - val_loss: 1.5393 - val_accuracy: 0.7358\n",
            "Epoch 506/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1770 - accuracy: 0.9379 - val_loss: 1.4596 - val_accuracy: 0.7350\n",
            "Epoch 507/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1773 - accuracy: 0.9391 - val_loss: 1.5005 - val_accuracy: 0.7328\n",
            "Epoch 508/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1818 - accuracy: 0.9377 - val_loss: 1.4492 - val_accuracy: 0.7297\n",
            "Epoch 509/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1790 - accuracy: 0.9389 - val_loss: 1.4886 - val_accuracy: 0.7315\n",
            "Epoch 510/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1850 - accuracy: 0.9373 - val_loss: 1.4739 - val_accuracy: 0.7393\n",
            "Epoch 511/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1816 - accuracy: 0.9372 - val_loss: 1.4125 - val_accuracy: 0.7381\n",
            "Epoch 512/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1815 - accuracy: 0.9387 - val_loss: 1.5122 - val_accuracy: 0.7341\n",
            "Epoch 513/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1864 - accuracy: 0.9357 - val_loss: 1.4748 - val_accuracy: 0.7346\n",
            "Epoch 514/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1849 - accuracy: 0.9358 - val_loss: 1.5913 - val_accuracy: 0.7386\n",
            "Epoch 515/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1791 - accuracy: 0.9397 - val_loss: 1.4344 - val_accuracy: 0.7383\n",
            "Epoch 516/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1774 - accuracy: 0.9394 - val_loss: 1.5824 - val_accuracy: 0.7387\n",
            "Epoch 517/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1723 - accuracy: 0.9382 - val_loss: 1.4998 - val_accuracy: 0.7344\n",
            "Epoch 518/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1795 - accuracy: 0.9396 - val_loss: 1.5123 - val_accuracy: 0.7382\n",
            "Epoch 519/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1731 - accuracy: 0.9427 - val_loss: 1.4438 - val_accuracy: 0.7325\n",
            "Epoch 520/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1818 - accuracy: 0.9394 - val_loss: 1.4451 - val_accuracy: 0.7381\n",
            "Epoch 521/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1792 - accuracy: 0.9383 - val_loss: 1.4326 - val_accuracy: 0.7335\n",
            "Epoch 522/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1816 - accuracy: 0.9361 - val_loss: 1.5026 - val_accuracy: 0.7338\n",
            "Epoch 523/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1838 - accuracy: 0.9391 - val_loss: 1.5700 - val_accuracy: 0.7362\n",
            "Epoch 524/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1775 - accuracy: 0.9389 - val_loss: 1.4832 - val_accuracy: 0.7370\n",
            "Epoch 525/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1794 - accuracy: 0.9389 - val_loss: 1.4790 - val_accuracy: 0.7377\n",
            "Epoch 526/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1843 - accuracy: 0.9378 - val_loss: 1.4177 - val_accuracy: 0.7340\n",
            "Epoch 527/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1796 - accuracy: 0.9398 - val_loss: 1.4881 - val_accuracy: 0.7338\n",
            "Epoch 528/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1781 - accuracy: 0.9386 - val_loss: 1.4579 - val_accuracy: 0.7394\n",
            "Epoch 529/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1758 - accuracy: 0.9415 - val_loss: 1.4309 - val_accuracy: 0.7401\n",
            "Epoch 530/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1880 - accuracy: 0.9355 - val_loss: 1.5138 - val_accuracy: 0.7401\n",
            "Epoch 531/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1795 - accuracy: 0.9378 - val_loss: 1.4121 - val_accuracy: 0.7346\n",
            "Epoch 532/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1763 - accuracy: 0.9380 - val_loss: 1.5231 - val_accuracy: 0.7323\n",
            "Epoch 533/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1801 - accuracy: 0.9372 - val_loss: 1.4575 - val_accuracy: 0.7353\n",
            "Epoch 534/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1828 - accuracy: 0.9348 - val_loss: 1.4251 - val_accuracy: 0.7365\n",
            "Epoch 535/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1777 - accuracy: 0.9391 - val_loss: 1.5005 - val_accuracy: 0.7360\n",
            "Epoch 536/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1835 - accuracy: 0.9365 - val_loss: 1.4107 - val_accuracy: 0.7388\n",
            "Epoch 537/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1798 - accuracy: 0.9387 - val_loss: 1.5211 - val_accuracy: 0.7350\n",
            "Epoch 538/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1800 - accuracy: 0.9380 - val_loss: 1.3841 - val_accuracy: 0.7356\n",
            "Epoch 539/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1804 - accuracy: 0.9374 - val_loss: 1.5105 - val_accuracy: 0.7262\n",
            "Epoch 540/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1873 - accuracy: 0.9383 - val_loss: 1.4987 - val_accuracy: 0.7403\n",
            "Epoch 541/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1819 - accuracy: 0.9387 - val_loss: 1.4951 - val_accuracy: 0.7339\n",
            "Epoch 542/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1759 - accuracy: 0.9397 - val_loss: 1.4687 - val_accuracy: 0.7309\n",
            "Epoch 543/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1785 - accuracy: 0.9400 - val_loss: 1.5914 - val_accuracy: 0.7384\n",
            "Epoch 544/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1755 - accuracy: 0.9402 - val_loss: 1.4653 - val_accuracy: 0.7343\n",
            "Epoch 545/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1857 - accuracy: 0.9386 - val_loss: 1.4040 - val_accuracy: 0.7330\n",
            "Epoch 546/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1868 - accuracy: 0.9380 - val_loss: 1.5129 - val_accuracy: 0.7307\n",
            "Epoch 547/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1779 - accuracy: 0.9377 - val_loss: 1.4607 - val_accuracy: 0.7399\n",
            "Epoch 548/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1797 - accuracy: 0.9381 - val_loss: 1.4485 - val_accuracy: 0.7322\n",
            "Epoch 549/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1830 - accuracy: 0.9373 - val_loss: 1.4818 - val_accuracy: 0.7301\n",
            "Epoch 550/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1772 - accuracy: 0.9383 - val_loss: 1.5015 - val_accuracy: 0.7377\n",
            "Epoch 551/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1837 - accuracy: 0.9365 - val_loss: 1.4906 - val_accuracy: 0.7368\n",
            "Epoch 552/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1821 - accuracy: 0.9376 - val_loss: 1.4905 - val_accuracy: 0.7364\n",
            "Epoch 553/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1823 - accuracy: 0.9376 - val_loss: 1.4687 - val_accuracy: 0.7290\n",
            "Epoch 554/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1834 - accuracy: 0.9363 - val_loss: 1.5035 - val_accuracy: 0.7380\n",
            "Epoch 555/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1784 - accuracy: 0.9394 - val_loss: 1.5026 - val_accuracy: 0.7341\n",
            "Epoch 556/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1825 - accuracy: 0.9372 - val_loss: 1.5109 - val_accuracy: 0.7382\n",
            "Epoch 557/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1813 - accuracy: 0.9367 - val_loss: 1.5044 - val_accuracy: 0.7367\n",
            "Epoch 558/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1777 - accuracy: 0.9394 - val_loss: 1.5313 - val_accuracy: 0.7280\n",
            "Epoch 559/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1869 - accuracy: 0.9360 - val_loss: 1.5041 - val_accuracy: 0.7371\n",
            "Epoch 560/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1801 - accuracy: 0.9363 - val_loss: 1.4711 - val_accuracy: 0.7349\n",
            "Epoch 561/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1763 - accuracy: 0.9384 - val_loss: 1.4670 - val_accuracy: 0.7365\n",
            "Epoch 562/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1881 - accuracy: 0.9338 - val_loss: 1.4866 - val_accuracy: 0.7335\n",
            "Epoch 563/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1854 - accuracy: 0.9379 - val_loss: 1.4708 - val_accuracy: 0.7353\n",
            "Epoch 564/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1875 - accuracy: 0.9367 - val_loss: 1.5105 - val_accuracy: 0.7374\n",
            "Epoch 565/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1731 - accuracy: 0.9403 - val_loss: 1.5185 - val_accuracy: 0.7375\n",
            "Epoch 566/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1754 - accuracy: 0.9394 - val_loss: 1.5714 - val_accuracy: 0.7340\n",
            "Epoch 567/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1891 - accuracy: 0.9352 - val_loss: 1.5162 - val_accuracy: 0.7350\n",
            "Epoch 568/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1817 - accuracy: 0.9392 - val_loss: 1.4733 - val_accuracy: 0.7337\n",
            "Epoch 569/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1869 - accuracy: 0.9375 - val_loss: 1.4384 - val_accuracy: 0.7304\n",
            "Epoch 570/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1758 - accuracy: 0.9411 - val_loss: 1.5529 - val_accuracy: 0.7356\n",
            "Epoch 571/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1823 - accuracy: 0.9369 - val_loss: 1.5574 - val_accuracy: 0.7356\n",
            "Epoch 572/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1859 - accuracy: 0.9369 - val_loss: 1.4477 - val_accuracy: 0.7307\n",
            "Epoch 573/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1841 - accuracy: 0.9376 - val_loss: 1.5362 - val_accuracy: 0.7313\n",
            "Epoch 574/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1818 - accuracy: 0.9380 - val_loss: 1.4530 - val_accuracy: 0.7325\n",
            "Epoch 575/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1786 - accuracy: 0.9409 - val_loss: 1.4691 - val_accuracy: 0.7374\n",
            "Epoch 576/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1856 - accuracy: 0.9375 - val_loss: 1.4768 - val_accuracy: 0.7389\n",
            "Epoch 577/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1795 - accuracy: 0.9388 - val_loss: 1.4516 - val_accuracy: 0.7287\n",
            "Epoch 578/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1865 - accuracy: 0.9377 - val_loss: 1.4653 - val_accuracy: 0.7382\n",
            "Epoch 579/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1820 - accuracy: 0.9383 - val_loss: 1.5217 - val_accuracy: 0.7377\n",
            "Epoch 580/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1793 - accuracy: 0.9374 - val_loss: 1.4568 - val_accuracy: 0.7350\n",
            "Epoch 581/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1926 - accuracy: 0.9338 - val_loss: 1.4976 - val_accuracy: 0.7300\n",
            "Epoch 582/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1863 - accuracy: 0.9374 - val_loss: 1.5737 - val_accuracy: 0.7389\n",
            "Epoch 583/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1884 - accuracy: 0.9348 - val_loss: 1.4391 - val_accuracy: 0.7332\n",
            "Epoch 584/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1901 - accuracy: 0.9363 - val_loss: 1.5102 - val_accuracy: 0.7316\n",
            "Epoch 585/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1803 - accuracy: 0.9383 - val_loss: 1.5154 - val_accuracy: 0.7361\n",
            "Epoch 586/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1848 - accuracy: 0.9361 - val_loss: 1.4571 - val_accuracy: 0.7389\n",
            "Epoch 587/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1798 - accuracy: 0.9367 - val_loss: 1.4661 - val_accuracy: 0.7334\n",
            "Epoch 588/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1826 - accuracy: 0.9363 - val_loss: 1.4752 - val_accuracy: 0.7370\n",
            "Epoch 589/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1799 - accuracy: 0.9382 - val_loss: 1.5562 - val_accuracy: 0.7376\n",
            "Epoch 590/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1785 - accuracy: 0.9398 - val_loss: 1.4601 - val_accuracy: 0.7423\n",
            "Epoch 591/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1774 - accuracy: 0.9395 - val_loss: 1.5021 - val_accuracy: 0.7377\n",
            "Epoch 592/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1736 - accuracy: 0.9390 - val_loss: 1.4011 - val_accuracy: 0.7382\n",
            "Epoch 593/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1809 - accuracy: 0.9380 - val_loss: 1.5184 - val_accuracy: 0.7352\n",
            "Epoch 594/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1901 - accuracy: 0.9346 - val_loss: 1.4734 - val_accuracy: 0.7311\n",
            "Epoch 595/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1773 - accuracy: 0.9370 - val_loss: 1.4367 - val_accuracy: 0.7360\n",
            "Epoch 596/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1862 - accuracy: 0.9388 - val_loss: 1.5286 - val_accuracy: 0.7304\n",
            "Epoch 597/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1824 - accuracy: 0.9365 - val_loss: 1.4841 - val_accuracy: 0.7393\n",
            "Epoch 598/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1778 - accuracy: 0.9388 - val_loss: 1.4828 - val_accuracy: 0.7294\n",
            "Epoch 599/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1829 - accuracy: 0.9351 - val_loss: 1.4360 - val_accuracy: 0.7351\n",
            "Epoch 600/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1797 - accuracy: 0.9401 - val_loss: 1.5107 - val_accuracy: 0.7368\n",
            "Epoch 601/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1858 - accuracy: 0.9372 - val_loss: 1.4238 - val_accuracy: 0.7403\n",
            "Epoch 602/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1973 - accuracy: 0.9349 - val_loss: 1.4349 - val_accuracy: 0.7343\n",
            "Epoch 603/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1900 - accuracy: 0.9348 - val_loss: 1.5686 - val_accuracy: 0.7287\n",
            "Epoch 604/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1798 - accuracy: 0.9381 - val_loss: 1.4970 - val_accuracy: 0.7291\n",
            "Epoch 605/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1826 - accuracy: 0.9384 - val_loss: 1.4837 - val_accuracy: 0.7345\n",
            "Epoch 606/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1797 - accuracy: 0.9367 - val_loss: 1.3978 - val_accuracy: 0.7353\n",
            "Epoch 607/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1865 - accuracy: 0.9370 - val_loss: 1.4687 - val_accuracy: 0.7276\n",
            "Epoch 608/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1806 - accuracy: 0.9394 - val_loss: 1.4582 - val_accuracy: 0.7354\n",
            "Epoch 609/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1823 - accuracy: 0.9386 - val_loss: 1.5512 - val_accuracy: 0.7323\n",
            "Epoch 610/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1870 - accuracy: 0.9364 - val_loss: 1.4736 - val_accuracy: 0.7308\n",
            "Epoch 611/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1833 - accuracy: 0.9379 - val_loss: 1.4047 - val_accuracy: 0.7319\n",
            "Epoch 612/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1789 - accuracy: 0.9392 - val_loss: 1.4655 - val_accuracy: 0.7327\n",
            "Epoch 613/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1795 - accuracy: 0.9404 - val_loss: 1.4714 - val_accuracy: 0.7322\n",
            "Epoch 614/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1903 - accuracy: 0.9359 - val_loss: 1.5625 - val_accuracy: 0.7353\n",
            "Epoch 615/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1790 - accuracy: 0.9383 - val_loss: 1.4810 - val_accuracy: 0.7260\n",
            "Epoch 616/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1821 - accuracy: 0.9386 - val_loss: 1.5102 - val_accuracy: 0.7338\n",
            "Epoch 617/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1753 - accuracy: 0.9407 - val_loss: 1.5107 - val_accuracy: 0.7352\n",
            "Epoch 618/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1813 - accuracy: 0.9384 - val_loss: 1.5564 - val_accuracy: 0.7284\n",
            "Epoch 619/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1917 - accuracy: 0.9353 - val_loss: 1.5981 - val_accuracy: 0.7340\n",
            "Epoch 620/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1882 - accuracy: 0.9381 - val_loss: 1.5284 - val_accuracy: 0.7350\n",
            "Epoch 621/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1837 - accuracy: 0.9373 - val_loss: 1.4914 - val_accuracy: 0.7382\n",
            "Epoch 622/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1816 - accuracy: 0.9381 - val_loss: 1.6099 - val_accuracy: 0.7373\n",
            "Epoch 623/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1856 - accuracy: 0.9380 - val_loss: 1.4136 - val_accuracy: 0.7272\n",
            "Epoch 624/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1860 - accuracy: 0.9363 - val_loss: 1.5744 - val_accuracy: 0.7334\n",
            "Epoch 625/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1897 - accuracy: 0.9356 - val_loss: 1.5575 - val_accuracy: 0.7330\n",
            "Epoch 626/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1823 - accuracy: 0.9386 - val_loss: 1.4620 - val_accuracy: 0.7284\n",
            "Epoch 627/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1851 - accuracy: 0.9358 - val_loss: 1.4554 - val_accuracy: 0.7372\n",
            "Epoch 628/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1840 - accuracy: 0.9386 - val_loss: 1.5153 - val_accuracy: 0.7328\n",
            "Epoch 629/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1849 - accuracy: 0.9357 - val_loss: 1.5227 - val_accuracy: 0.7316\n",
            "Epoch 630/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1813 - accuracy: 0.9387 - val_loss: 1.5265 - val_accuracy: 0.7320\n",
            "Epoch 631/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1858 - accuracy: 0.9368 - val_loss: 1.5131 - val_accuracy: 0.7332\n",
            "Epoch 632/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1895 - accuracy: 0.9349 - val_loss: 1.4415 - val_accuracy: 0.7323\n",
            "Epoch 633/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1800 - accuracy: 0.9382 - val_loss: 1.4977 - val_accuracy: 0.7306\n",
            "Epoch 634/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1875 - accuracy: 0.9370 - val_loss: 1.4823 - val_accuracy: 0.7346\n",
            "Epoch 635/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1898 - accuracy: 0.9366 - val_loss: 1.5349 - val_accuracy: 0.7304\n",
            "Epoch 636/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1792 - accuracy: 0.9390 - val_loss: 1.4359 - val_accuracy: 0.7247\n",
            "Epoch 637/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1800 - accuracy: 0.9385 - val_loss: 1.4649 - val_accuracy: 0.7324\n",
            "Epoch 638/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1877 - accuracy: 0.9353 - val_loss: 1.4969 - val_accuracy: 0.7337\n",
            "Epoch 639/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1880 - accuracy: 0.9364 - val_loss: 1.5567 - val_accuracy: 0.7352\n",
            "Epoch 640/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1797 - accuracy: 0.9390 - val_loss: 1.5458 - val_accuracy: 0.7241\n",
            "Epoch 641/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1877 - accuracy: 0.9356 - val_loss: 1.4250 - val_accuracy: 0.7340\n",
            "Epoch 642/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1826 - accuracy: 0.9383 - val_loss: 1.6588 - val_accuracy: 0.7356\n",
            "Epoch 643/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1860 - accuracy: 0.9375 - val_loss: 1.4665 - val_accuracy: 0.7345\n",
            "Epoch 644/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1851 - accuracy: 0.9384 - val_loss: 1.4243 - val_accuracy: 0.7348\n",
            "Epoch 645/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1808 - accuracy: 0.9384 - val_loss: 1.5145 - val_accuracy: 0.7386\n",
            "Epoch 646/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1715 - accuracy: 0.9415 - val_loss: 1.5273 - val_accuracy: 0.7388\n",
            "Epoch 647/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1854 - accuracy: 0.9364 - val_loss: 1.5021 - val_accuracy: 0.7337\n",
            "Epoch 648/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1767 - accuracy: 0.9401 - val_loss: 1.4847 - val_accuracy: 0.7287\n",
            "Epoch 649/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1903 - accuracy: 0.9347 - val_loss: 1.5077 - val_accuracy: 0.7346\n",
            "Epoch 650/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1797 - accuracy: 0.9413 - val_loss: 1.5592 - val_accuracy: 0.7356\n",
            "Epoch 651/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1846 - accuracy: 0.9383 - val_loss: 1.4728 - val_accuracy: 0.7405\n",
            "Epoch 652/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1748 - accuracy: 0.9402 - val_loss: 1.5512 - val_accuracy: 0.7386\n",
            "Epoch 653/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1813 - accuracy: 0.9363 - val_loss: 1.5269 - val_accuracy: 0.7375\n",
            "Epoch 654/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1801 - accuracy: 0.9385 - val_loss: 1.4920 - val_accuracy: 0.7354\n",
            "Epoch 655/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1813 - accuracy: 0.9380 - val_loss: 1.5421 - val_accuracy: 0.7366\n",
            "Epoch 656/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1838 - accuracy: 0.9397 - val_loss: 1.4808 - val_accuracy: 0.7366\n",
            "Epoch 657/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1856 - accuracy: 0.9365 - val_loss: 1.5483 - val_accuracy: 0.7346\n",
            "Epoch 658/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1902 - accuracy: 0.9350 - val_loss: 1.5229 - val_accuracy: 0.7189\n",
            "Epoch 659/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1807 - accuracy: 0.9369 - val_loss: 1.4202 - val_accuracy: 0.7282\n",
            "Epoch 660/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1744 - accuracy: 0.9396 - val_loss: 1.5289 - val_accuracy: 0.7310\n",
            "Epoch 661/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1836 - accuracy: 0.9372 - val_loss: 1.4920 - val_accuracy: 0.7292\n",
            "Epoch 662/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1844 - accuracy: 0.9357 - val_loss: 1.5095 - val_accuracy: 0.7357\n",
            "Epoch 663/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1871 - accuracy: 0.9368 - val_loss: 1.4561 - val_accuracy: 0.7358\n",
            "Epoch 664/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1791 - accuracy: 0.9400 - val_loss: 1.5147 - val_accuracy: 0.7279\n",
            "Epoch 665/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1763 - accuracy: 0.9399 - val_loss: 1.5988 - val_accuracy: 0.7363\n",
            "Epoch 666/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1845 - accuracy: 0.9371 - val_loss: 1.4767 - val_accuracy: 0.7366\n",
            "Epoch 667/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1881 - accuracy: 0.9367 - val_loss: 1.5644 - val_accuracy: 0.7376\n",
            "Epoch 668/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1848 - accuracy: 0.9356 - val_loss: 1.5999 - val_accuracy: 0.7381\n",
            "Epoch 669/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1852 - accuracy: 0.9366 - val_loss: 1.4971 - val_accuracy: 0.7364\n",
            "Epoch 670/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1812 - accuracy: 0.9387 - val_loss: 1.5653 - val_accuracy: 0.7352\n",
            "Epoch 671/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1904 - accuracy: 0.9360 - val_loss: 1.4546 - val_accuracy: 0.7219\n",
            "Epoch 672/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1764 - accuracy: 0.9385 - val_loss: 1.5652 - val_accuracy: 0.7326\n",
            "Epoch 673/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1933 - accuracy: 0.9357 - val_loss: 1.4754 - val_accuracy: 0.7348\n",
            "Epoch 674/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1854 - accuracy: 0.9379 - val_loss: 1.5890 - val_accuracy: 0.7381\n",
            "Epoch 675/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1821 - accuracy: 0.9381 - val_loss: 1.5225 - val_accuracy: 0.7295\n",
            "Epoch 676/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1875 - accuracy: 0.9357 - val_loss: 1.5216 - val_accuracy: 0.7333\n",
            "Epoch 677/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1925 - accuracy: 0.9341 - val_loss: 1.5580 - val_accuracy: 0.7310\n",
            "Epoch 678/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1813 - accuracy: 0.9372 - val_loss: 1.5970 - val_accuracy: 0.7365\n",
            "Epoch 679/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1915 - accuracy: 0.9366 - val_loss: 1.5448 - val_accuracy: 0.7333\n",
            "Epoch 680/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1803 - accuracy: 0.9387 - val_loss: 1.5174 - val_accuracy: 0.7334\n",
            "Epoch 681/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1837 - accuracy: 0.9385 - val_loss: 1.5193 - val_accuracy: 0.7383\n",
            "Epoch 682/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1865 - accuracy: 0.9354 - val_loss: 1.5260 - val_accuracy: 0.7248\n",
            "Epoch 683/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1781 - accuracy: 0.9380 - val_loss: 1.6059 - val_accuracy: 0.7417\n",
            "Epoch 684/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1817 - accuracy: 0.9379 - val_loss: 1.5727 - val_accuracy: 0.7370\n",
            "Epoch 685/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1879 - accuracy: 0.9375 - val_loss: 1.6367 - val_accuracy: 0.7376\n",
            "Epoch 686/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1858 - accuracy: 0.9369 - val_loss: 1.4894 - val_accuracy: 0.7347\n",
            "Epoch 687/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1821 - accuracy: 0.9367 - val_loss: 1.4970 - val_accuracy: 0.7365\n",
            "Epoch 688/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1946 - accuracy: 0.9377 - val_loss: 1.4786 - val_accuracy: 0.7346\n",
            "Epoch 689/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1821 - accuracy: 0.9379 - val_loss: 1.5553 - val_accuracy: 0.7287\n",
            "Epoch 690/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1784 - accuracy: 0.9391 - val_loss: 1.5205 - val_accuracy: 0.7255\n",
            "Epoch 691/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1898 - accuracy: 0.9345 - val_loss: 1.4836 - val_accuracy: 0.7345\n",
            "Epoch 692/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1871 - accuracy: 0.9376 - val_loss: 1.6093 - val_accuracy: 0.7329\n",
            "Epoch 693/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1895 - accuracy: 0.9364 - val_loss: 1.6121 - val_accuracy: 0.7363\n",
            "Epoch 694/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1857 - accuracy: 0.9372 - val_loss: 1.4634 - val_accuracy: 0.7317\n",
            "Epoch 695/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1895 - accuracy: 0.9355 - val_loss: 1.5258 - val_accuracy: 0.7401\n",
            "Epoch 696/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1888 - accuracy: 0.9370 - val_loss: 1.5103 - val_accuracy: 0.7339\n",
            "Epoch 697/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1907 - accuracy: 0.9348 - val_loss: 1.5371 - val_accuracy: 0.7369\n",
            "Epoch 698/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1850 - accuracy: 0.9377 - val_loss: 1.5036 - val_accuracy: 0.7350\n",
            "Epoch 699/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1817 - accuracy: 0.9368 - val_loss: 1.4899 - val_accuracy: 0.7300\n",
            "Epoch 700/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1935 - accuracy: 0.9344 - val_loss: 1.5139 - val_accuracy: 0.7334\n",
            "Epoch 701/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1855 - accuracy: 0.9383 - val_loss: 1.5335 - val_accuracy: 0.7349\n",
            "Epoch 702/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1841 - accuracy: 0.9375 - val_loss: 1.5737 - val_accuracy: 0.7255\n",
            "Epoch 703/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1881 - accuracy: 0.9345 - val_loss: 1.5123 - val_accuracy: 0.7353\n",
            "Epoch 704/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1865 - accuracy: 0.9370 - val_loss: 1.5001 - val_accuracy: 0.7309\n",
            "Epoch 705/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1881 - accuracy: 0.9356 - val_loss: 1.4389 - val_accuracy: 0.7366\n",
            "Epoch 706/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1838 - accuracy: 0.9374 - val_loss: 1.5740 - val_accuracy: 0.7340\n",
            "Epoch 707/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1887 - accuracy: 0.9379 - val_loss: 1.5072 - val_accuracy: 0.7302\n",
            "Epoch 708/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1743 - accuracy: 0.9400 - val_loss: 1.5262 - val_accuracy: 0.7331\n",
            "Epoch 709/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1965 - accuracy: 0.9317 - val_loss: 1.5213 - val_accuracy: 0.7333\n",
            "Epoch 710/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1842 - accuracy: 0.9384 - val_loss: 1.4800 - val_accuracy: 0.7359\n",
            "Epoch 711/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1848 - accuracy: 0.9358 - val_loss: 1.5357 - val_accuracy: 0.7332\n",
            "Epoch 712/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1883 - accuracy: 0.9359 - val_loss: 1.5788 - val_accuracy: 0.7358\n",
            "Epoch 713/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1893 - accuracy: 0.9367 - val_loss: 1.5576 - val_accuracy: 0.7272\n",
            "Epoch 714/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1862 - accuracy: 0.9362 - val_loss: 1.6194 - val_accuracy: 0.7370\n",
            "Epoch 715/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1896 - accuracy: 0.9373 - val_loss: 1.6130 - val_accuracy: 0.7325\n",
            "Epoch 716/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1811 - accuracy: 0.9392 - val_loss: 1.4642 - val_accuracy: 0.7253\n",
            "Epoch 717/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1931 - accuracy: 0.9356 - val_loss: 1.5866 - val_accuracy: 0.7355\n",
            "Epoch 718/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1890 - accuracy: 0.9361 - val_loss: 1.5971 - val_accuracy: 0.7351\n",
            "Epoch 719/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1883 - accuracy: 0.9345 - val_loss: 1.5894 - val_accuracy: 0.7389\n",
            "Epoch 720/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1839 - accuracy: 0.9372 - val_loss: 1.6645 - val_accuracy: 0.7311\n",
            "Epoch 721/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1917 - accuracy: 0.9357 - val_loss: 1.4609 - val_accuracy: 0.7251\n",
            "Epoch 722/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1837 - accuracy: 0.9379 - val_loss: 1.4331 - val_accuracy: 0.7309\n",
            "Epoch 723/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1894 - accuracy: 0.9361 - val_loss: 1.5322 - val_accuracy: 0.7346\n",
            "Epoch 724/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1860 - accuracy: 0.9375 - val_loss: 1.4703 - val_accuracy: 0.7371\n",
            "Epoch 725/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1839 - accuracy: 0.9362 - val_loss: 1.5563 - val_accuracy: 0.7328\n",
            "Epoch 726/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1882 - accuracy: 0.9373 - val_loss: 1.5585 - val_accuracy: 0.7290\n",
            "Epoch 727/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1842 - accuracy: 0.9394 - val_loss: 1.4704 - val_accuracy: 0.7311\n",
            "Epoch 728/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1827 - accuracy: 0.9397 - val_loss: 1.4523 - val_accuracy: 0.7319\n",
            "Epoch 729/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1873 - accuracy: 0.9365 - val_loss: 1.5495 - val_accuracy: 0.7346\n",
            "Epoch 730/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1886 - accuracy: 0.9366 - val_loss: 1.5884 - val_accuracy: 0.7340\n",
            "Epoch 731/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1959 - accuracy: 0.9356 - val_loss: 1.6048 - val_accuracy: 0.7373\n",
            "Epoch 732/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1933 - accuracy: 0.9357 - val_loss: 1.4987 - val_accuracy: 0.7331\n",
            "Epoch 733/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1783 - accuracy: 0.9381 - val_loss: 1.5650 - val_accuracy: 0.7334\n",
            "Epoch 734/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1859 - accuracy: 0.9373 - val_loss: 1.5448 - val_accuracy: 0.7401\n",
            "Epoch 735/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1878 - accuracy: 0.9367 - val_loss: 1.5138 - val_accuracy: 0.7325\n",
            "Epoch 736/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1803 - accuracy: 0.9365 - val_loss: 1.5267 - val_accuracy: 0.7330\n",
            "Epoch 737/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1862 - accuracy: 0.9356 - val_loss: 1.5391 - val_accuracy: 0.7354\n",
            "Epoch 738/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1884 - accuracy: 0.9365 - val_loss: 1.5353 - val_accuracy: 0.7299\n",
            "Epoch 739/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1880 - accuracy: 0.9379 - val_loss: 1.6097 - val_accuracy: 0.7287\n",
            "Epoch 740/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1886 - accuracy: 0.9357 - val_loss: 1.5469 - val_accuracy: 0.7317\n",
            "Epoch 741/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1942 - accuracy: 0.9356 - val_loss: 1.5702 - val_accuracy: 0.7372\n",
            "Epoch 742/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1847 - accuracy: 0.9377 - val_loss: 1.4236 - val_accuracy: 0.7323\n",
            "Epoch 743/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1892 - accuracy: 0.9363 - val_loss: 1.6314 - val_accuracy: 0.7363\n",
            "Epoch 744/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1912 - accuracy: 0.9363 - val_loss: 1.5590 - val_accuracy: 0.7274\n",
            "Epoch 745/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1812 - accuracy: 0.9407 - val_loss: 1.6570 - val_accuracy: 0.7352\n",
            "Epoch 746/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1919 - accuracy: 0.9370 - val_loss: 1.5193 - val_accuracy: 0.7321\n",
            "Epoch 747/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1928 - accuracy: 0.9356 - val_loss: 1.6082 - val_accuracy: 0.7212\n",
            "Epoch 748/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1891 - accuracy: 0.9369 - val_loss: 1.5300 - val_accuracy: 0.7207\n",
            "Epoch 749/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1913 - accuracy: 0.9372 - val_loss: 1.5932 - val_accuracy: 0.7276\n",
            "Epoch 750/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1872 - accuracy: 0.9370 - val_loss: 1.4847 - val_accuracy: 0.7322\n",
            "Epoch 751/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1869 - accuracy: 0.9351 - val_loss: 1.5478 - val_accuracy: 0.7346\n",
            "Epoch 752/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1805 - accuracy: 0.9387 - val_loss: 1.5566 - val_accuracy: 0.7351\n",
            "Epoch 753/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1877 - accuracy: 0.9353 - val_loss: 1.4814 - val_accuracy: 0.7242\n",
            "Epoch 754/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1916 - accuracy: 0.9355 - val_loss: 1.5928 - val_accuracy: 0.7346\n",
            "Epoch 755/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1895 - accuracy: 0.9369 - val_loss: 1.5405 - val_accuracy: 0.7281\n",
            "Epoch 756/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1913 - accuracy: 0.9349 - val_loss: 1.5306 - val_accuracy: 0.7327\n",
            "Epoch 757/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1883 - accuracy: 0.9383 - val_loss: 1.4878 - val_accuracy: 0.7326\n",
            "Epoch 758/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1901 - accuracy: 0.9369 - val_loss: 1.5355 - val_accuracy: 0.7328\n",
            "Epoch 759/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1852 - accuracy: 0.9366 - val_loss: 1.5312 - val_accuracy: 0.7309\n",
            "Epoch 760/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1933 - accuracy: 0.9344 - val_loss: 1.5289 - val_accuracy: 0.7318\n",
            "Epoch 761/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1901 - accuracy: 0.9354 - val_loss: 1.5294 - val_accuracy: 0.7287\n",
            "Epoch 762/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1893 - accuracy: 0.9347 - val_loss: 1.4877 - val_accuracy: 0.7312\n",
            "Epoch 763/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1782 - accuracy: 0.9380 - val_loss: 1.4026 - val_accuracy: 0.7300\n",
            "Epoch 764/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1860 - accuracy: 0.9352 - val_loss: 1.5185 - val_accuracy: 0.7263\n",
            "Epoch 765/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1882 - accuracy: 0.9378 - val_loss: 1.4877 - val_accuracy: 0.7188\n",
            "Epoch 766/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1894 - accuracy: 0.9363 - val_loss: 1.4766 - val_accuracy: 0.7228\n",
            "Epoch 767/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1822 - accuracy: 0.9398 - val_loss: 1.5241 - val_accuracy: 0.7325\n",
            "Epoch 768/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1882 - accuracy: 0.9374 - val_loss: 1.6132 - val_accuracy: 0.7328\n",
            "Epoch 769/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1889 - accuracy: 0.9368 - val_loss: 1.5171 - val_accuracy: 0.7334\n",
            "Epoch 770/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1849 - accuracy: 0.9379 - val_loss: 1.5602 - val_accuracy: 0.7357\n",
            "Epoch 771/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1775 - accuracy: 0.9388 - val_loss: 1.5255 - val_accuracy: 0.7373\n",
            "Epoch 772/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1758 - accuracy: 0.9401 - val_loss: 1.5758 - val_accuracy: 0.7322\n",
            "Epoch 773/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1811 - accuracy: 0.9383 - val_loss: 1.5217 - val_accuracy: 0.7275\n",
            "Epoch 774/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1919 - accuracy: 0.9363 - val_loss: 1.5923 - val_accuracy: 0.7347\n",
            "Epoch 775/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1775 - accuracy: 0.9387 - val_loss: 1.5181 - val_accuracy: 0.7367\n",
            "Epoch 776/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1850 - accuracy: 0.9371 - val_loss: 1.6099 - val_accuracy: 0.7250\n",
            "Epoch 777/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1814 - accuracy: 0.9400 - val_loss: 1.4766 - val_accuracy: 0.7283\n",
            "Epoch 778/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1883 - accuracy: 0.9381 - val_loss: 1.5414 - val_accuracy: 0.7369\n",
            "Epoch 779/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1862 - accuracy: 0.9371 - val_loss: 1.4539 - val_accuracy: 0.7338\n",
            "Epoch 780/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1841 - accuracy: 0.9363 - val_loss: 1.4955 - val_accuracy: 0.7273\n",
            "Epoch 781/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1914 - accuracy: 0.9380 - val_loss: 1.6096 - val_accuracy: 0.7351\n",
            "Epoch 782/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1957 - accuracy: 0.9353 - val_loss: 1.5042 - val_accuracy: 0.7335\n",
            "Epoch 783/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1817 - accuracy: 0.9371 - val_loss: 1.5145 - val_accuracy: 0.7284\n",
            "Epoch 784/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1871 - accuracy: 0.9366 - val_loss: 1.5357 - val_accuracy: 0.7329\n",
            "Epoch 785/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1835 - accuracy: 0.9357 - val_loss: 1.5113 - val_accuracy: 0.7293\n",
            "Epoch 786/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1883 - accuracy: 0.9373 - val_loss: 1.4871 - val_accuracy: 0.7345\n",
            "Epoch 787/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1874 - accuracy: 0.9365 - val_loss: 1.4697 - val_accuracy: 0.7313\n",
            "Epoch 788/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1829 - accuracy: 0.9390 - val_loss: 1.5870 - val_accuracy: 0.7312\n",
            "Epoch 789/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1927 - accuracy: 0.9368 - val_loss: 1.6086 - val_accuracy: 0.7251\n",
            "Epoch 790/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1928 - accuracy: 0.9352 - val_loss: 1.6025 - val_accuracy: 0.7340\n",
            "Epoch 791/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1957 - accuracy: 0.9342 - val_loss: 1.5435 - val_accuracy: 0.7242\n",
            "Epoch 792/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1861 - accuracy: 0.9380 - val_loss: 1.6215 - val_accuracy: 0.7319\n",
            "Epoch 793/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1883 - accuracy: 0.9358 - val_loss: 1.4929 - val_accuracy: 0.7361\n",
            "Epoch 794/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1885 - accuracy: 0.9367 - val_loss: 1.6080 - val_accuracy: 0.7359\n",
            "Epoch 795/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1812 - accuracy: 0.9387 - val_loss: 1.6072 - val_accuracy: 0.7339\n",
            "Epoch 796/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1864 - accuracy: 0.9374 - val_loss: 1.5991 - val_accuracy: 0.7305\n",
            "Epoch 797/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1954 - accuracy: 0.9363 - val_loss: 1.5030 - val_accuracy: 0.7317\n",
            "Epoch 798/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.2025 - accuracy: 0.9358 - val_loss: 1.5349 - val_accuracy: 0.7338\n",
            "Epoch 799/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1852 - accuracy: 0.9355 - val_loss: 1.5566 - val_accuracy: 0.7261\n",
            "Epoch 800/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1836 - accuracy: 0.9362 - val_loss: 1.5809 - val_accuracy: 0.7309\n",
            "Epoch 801/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1853 - accuracy: 0.9371 - val_loss: 1.5258 - val_accuracy: 0.7319\n",
            "Epoch 802/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1947 - accuracy: 0.9335 - val_loss: 1.5530 - val_accuracy: 0.7400\n",
            "Epoch 803/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1915 - accuracy: 0.9380 - val_loss: 1.5929 - val_accuracy: 0.7330\n",
            "Epoch 804/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1883 - accuracy: 0.9361 - val_loss: 1.5453 - val_accuracy: 0.7399\n",
            "Epoch 805/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1900 - accuracy: 0.9375 - val_loss: 1.4872 - val_accuracy: 0.7244\n",
            "Epoch 806/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1944 - accuracy: 0.9348 - val_loss: 1.5293 - val_accuracy: 0.7322\n",
            "Epoch 807/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1873 - accuracy: 0.9360 - val_loss: 1.5185 - val_accuracy: 0.7352\n",
            "Epoch 808/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1957 - accuracy: 0.9350 - val_loss: 1.5971 - val_accuracy: 0.7365\n",
            "Epoch 809/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1861 - accuracy: 0.9371 - val_loss: 1.5579 - val_accuracy: 0.7390\n",
            "Epoch 810/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1851 - accuracy: 0.9395 - val_loss: 1.6018 - val_accuracy: 0.7329\n",
            "Epoch 811/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1908 - accuracy: 0.9360 - val_loss: 1.5829 - val_accuracy: 0.7359\n",
            "Epoch 812/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1889 - accuracy: 0.9377 - val_loss: 1.6509 - val_accuracy: 0.7323\n",
            "Epoch 813/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1869 - accuracy: 0.9360 - val_loss: 1.4900 - val_accuracy: 0.7376\n",
            "Epoch 814/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1930 - accuracy: 0.9352 - val_loss: 1.5098 - val_accuracy: 0.7392\n",
            "Epoch 815/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1882 - accuracy: 0.9355 - val_loss: 1.5240 - val_accuracy: 0.7311\n",
            "Epoch 816/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1877 - accuracy: 0.9371 - val_loss: 1.5970 - val_accuracy: 0.7360\n",
            "Epoch 817/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1882 - accuracy: 0.9371 - val_loss: 1.5242 - val_accuracy: 0.7388\n",
            "Epoch 818/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1862 - accuracy: 0.9352 - val_loss: 1.4812 - val_accuracy: 0.7261\n",
            "Epoch 819/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1885 - accuracy: 0.9373 - val_loss: 1.5454 - val_accuracy: 0.7347\n",
            "Epoch 820/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1863 - accuracy: 0.9359 - val_loss: 1.5115 - val_accuracy: 0.7358\n",
            "Epoch 821/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1849 - accuracy: 0.9371 - val_loss: 1.5623 - val_accuracy: 0.7361\n",
            "Epoch 822/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1798 - accuracy: 0.9386 - val_loss: 1.4962 - val_accuracy: 0.7328\n",
            "Epoch 823/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1836 - accuracy: 0.9366 - val_loss: 1.5200 - val_accuracy: 0.7280\n",
            "Epoch 824/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1850 - accuracy: 0.9381 - val_loss: 1.5350 - val_accuracy: 0.7333\n",
            "Epoch 825/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1876 - accuracy: 0.9370 - val_loss: 1.5035 - val_accuracy: 0.7320\n",
            "Epoch 826/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1945 - accuracy: 0.9362 - val_loss: 1.5398 - val_accuracy: 0.7385\n",
            "Epoch 827/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1932 - accuracy: 0.9354 - val_loss: 1.5656 - val_accuracy: 0.7315\n",
            "Epoch 828/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1856 - accuracy: 0.9373 - val_loss: 1.5877 - val_accuracy: 0.7320\n",
            "Epoch 829/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1961 - accuracy: 0.9348 - val_loss: 1.5211 - val_accuracy: 0.7321\n",
            "Epoch 830/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1884 - accuracy: 0.9376 - val_loss: 1.5542 - val_accuracy: 0.7269\n",
            "Epoch 831/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1913 - accuracy: 0.9343 - val_loss: 1.5892 - val_accuracy: 0.7370\n",
            "Epoch 832/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1946 - accuracy: 0.9373 - val_loss: 1.6184 - val_accuracy: 0.7359\n",
            "Epoch 833/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1897 - accuracy: 0.9361 - val_loss: 1.5079 - val_accuracy: 0.7378\n",
            "Epoch 834/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1914 - accuracy: 0.9368 - val_loss: 1.5458 - val_accuracy: 0.7306\n",
            "Epoch 835/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1906 - accuracy: 0.9365 - val_loss: 1.5208 - val_accuracy: 0.7346\n",
            "Epoch 836/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1816 - accuracy: 0.9386 - val_loss: 1.5870 - val_accuracy: 0.7299\n",
            "Epoch 837/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1898 - accuracy: 0.9360 - val_loss: 1.5495 - val_accuracy: 0.7348\n",
            "Epoch 838/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1880 - accuracy: 0.9384 - val_loss: 1.4423 - val_accuracy: 0.7329\n",
            "Epoch 839/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1968 - accuracy: 0.9328 - val_loss: 1.5511 - val_accuracy: 0.7313\n",
            "Epoch 840/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1846 - accuracy: 0.9375 - val_loss: 1.5448 - val_accuracy: 0.7328\n",
            "Epoch 841/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1826 - accuracy: 0.9380 - val_loss: 1.6145 - val_accuracy: 0.7178\n",
            "Epoch 842/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1963 - accuracy: 0.9352 - val_loss: 1.5339 - val_accuracy: 0.7312\n",
            "Epoch 843/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1933 - accuracy: 0.9351 - val_loss: 1.5958 - val_accuracy: 0.7319\n",
            "Epoch 844/1080\n",
            "183/183 [==============================] - 4s 20ms/step - loss: 0.1947 - accuracy: 0.9337 - val_loss: 1.5195 - val_accuracy: 0.7328\n",
            "Epoch 845/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1918 - accuracy: 0.9364 - val_loss: 1.5562 - val_accuracy: 0.7246\n",
            "Epoch 846/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1915 - accuracy: 0.9375 - val_loss: 1.5903 - val_accuracy: 0.7352\n",
            "Epoch 847/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1871 - accuracy: 0.9366 - val_loss: 1.5529 - val_accuracy: 0.7330\n",
            "Epoch 848/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1864 - accuracy: 0.9379 - val_loss: 1.5165 - val_accuracy: 0.7342\n",
            "Epoch 849/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1807 - accuracy: 0.9394 - val_loss: 1.5179 - val_accuracy: 0.7354\n",
            "Epoch 850/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1865 - accuracy: 0.9390 - val_loss: 1.5478 - val_accuracy: 0.7288\n",
            "Epoch 851/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1869 - accuracy: 0.9372 - val_loss: 1.5606 - val_accuracy: 0.7331\n",
            "Epoch 852/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1908 - accuracy: 0.9364 - val_loss: 1.4902 - val_accuracy: 0.7301\n",
            "Epoch 853/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1952 - accuracy: 0.9344 - val_loss: 1.5415 - val_accuracy: 0.7346\n",
            "Epoch 854/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1905 - accuracy: 0.9360 - val_loss: 1.5641 - val_accuracy: 0.7340\n",
            "Epoch 855/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1889 - accuracy: 0.9370 - val_loss: 1.5480 - val_accuracy: 0.7261\n",
            "Epoch 856/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1892 - accuracy: 0.9358 - val_loss: 1.6273 - val_accuracy: 0.7359\n",
            "Epoch 857/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1908 - accuracy: 0.9361 - val_loss: 1.5753 - val_accuracy: 0.7320\n",
            "Epoch 858/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1880 - accuracy: 0.9364 - val_loss: 1.6294 - val_accuracy: 0.7327\n",
            "Epoch 859/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1864 - accuracy: 0.9376 - val_loss: 1.6730 - val_accuracy: 0.7361\n",
            "Epoch 860/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1936 - accuracy: 0.9356 - val_loss: 1.5346 - val_accuracy: 0.7356\n",
            "Epoch 861/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1857 - accuracy: 0.9387 - val_loss: 1.5525 - val_accuracy: 0.7351\n",
            "Epoch 862/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1941 - accuracy: 0.9352 - val_loss: 1.5930 - val_accuracy: 0.7353\n",
            "Epoch 863/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1864 - accuracy: 0.9360 - val_loss: 1.5516 - val_accuracy: 0.7340\n",
            "Epoch 864/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1951 - accuracy: 0.9369 - val_loss: 1.5669 - val_accuracy: 0.7352\n",
            "Epoch 865/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1908 - accuracy: 0.9361 - val_loss: 1.5954 - val_accuracy: 0.7320\n",
            "Epoch 866/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1876 - accuracy: 0.9365 - val_loss: 1.5729 - val_accuracy: 0.7270\n",
            "Epoch 867/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1879 - accuracy: 0.9392 - val_loss: 1.5227 - val_accuracy: 0.7343\n",
            "Epoch 868/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1846 - accuracy: 0.9386 - val_loss: 1.5330 - val_accuracy: 0.7334\n",
            "Epoch 869/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1831 - accuracy: 0.9384 - val_loss: 1.4577 - val_accuracy: 0.7372\n",
            "Epoch 870/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1866 - accuracy: 0.9369 - val_loss: 1.5180 - val_accuracy: 0.7339\n",
            "Epoch 871/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.2024 - accuracy: 0.9337 - val_loss: 1.5373 - val_accuracy: 0.7240\n",
            "Epoch 872/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1929 - accuracy: 0.9361 - val_loss: 1.5595 - val_accuracy: 0.7334\n",
            "Epoch 873/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.2000 - accuracy: 0.9344 - val_loss: 1.5034 - val_accuracy: 0.7330\n",
            "Epoch 874/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1882 - accuracy: 0.9375 - val_loss: 1.6744 - val_accuracy: 0.7370\n",
            "Epoch 875/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1920 - accuracy: 0.9371 - val_loss: 1.5927 - val_accuracy: 0.7301\n",
            "Epoch 876/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1876 - accuracy: 0.9358 - val_loss: 1.5529 - val_accuracy: 0.7321\n",
            "Epoch 877/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1877 - accuracy: 0.9350 - val_loss: 1.5683 - val_accuracy: 0.7299\n",
            "Epoch 878/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1976 - accuracy: 0.9339 - val_loss: 1.5844 - val_accuracy: 0.7293\n",
            "Epoch 879/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1862 - accuracy: 0.9374 - val_loss: 1.5446 - val_accuracy: 0.7331\n",
            "Epoch 880/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1906 - accuracy: 0.9349 - val_loss: 1.5342 - val_accuracy: 0.7355\n",
            "Epoch 881/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1907 - accuracy: 0.9352 - val_loss: 1.6152 - val_accuracy: 0.7290\n",
            "Epoch 882/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1889 - accuracy: 0.9376 - val_loss: 1.5891 - val_accuracy: 0.7382\n",
            "Epoch 883/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1895 - accuracy: 0.9379 - val_loss: 1.6037 - val_accuracy: 0.7390\n",
            "Epoch 884/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1822 - accuracy: 0.9387 - val_loss: 1.6404 - val_accuracy: 0.7381\n",
            "Epoch 885/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1893 - accuracy: 0.9349 - val_loss: 1.6509 - val_accuracy: 0.7330\n",
            "Epoch 886/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1887 - accuracy: 0.9352 - val_loss: 1.6031 - val_accuracy: 0.7263\n",
            "Epoch 887/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1888 - accuracy: 0.9371 - val_loss: 1.5808 - val_accuracy: 0.7355\n",
            "Epoch 888/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1869 - accuracy: 0.9378 - val_loss: 1.5716 - val_accuracy: 0.7350\n",
            "Epoch 889/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1891 - accuracy: 0.9370 - val_loss: 1.6033 - val_accuracy: 0.7326\n",
            "Epoch 890/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1844 - accuracy: 0.9383 - val_loss: 1.6762 - val_accuracy: 0.7352\n",
            "Epoch 891/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1885 - accuracy: 0.9358 - val_loss: 1.5571 - val_accuracy: 0.7323\n",
            "Epoch 892/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1908 - accuracy: 0.9362 - val_loss: 1.5808 - val_accuracy: 0.7220\n",
            "Epoch 893/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.2003 - accuracy: 0.9350 - val_loss: 1.4836 - val_accuracy: 0.7317\n",
            "Epoch 894/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1944 - accuracy: 0.9340 - val_loss: 1.5448 - val_accuracy: 0.7301\n",
            "Epoch 895/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1958 - accuracy: 0.9372 - val_loss: 1.4786 - val_accuracy: 0.7310\n",
            "Epoch 896/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1919 - accuracy: 0.9361 - val_loss: 1.5368 - val_accuracy: 0.7276\n",
            "Epoch 897/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1882 - accuracy: 0.9361 - val_loss: 1.5895 - val_accuracy: 0.7247\n",
            "Epoch 898/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1934 - accuracy: 0.9357 - val_loss: 1.4842 - val_accuracy: 0.7350\n",
            "Epoch 899/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1978 - accuracy: 0.9338 - val_loss: 1.6398 - val_accuracy: 0.7366\n",
            "Epoch 900/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1910 - accuracy: 0.9348 - val_loss: 1.4881 - val_accuracy: 0.7325\n",
            "Epoch 901/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1955 - accuracy: 0.9342 - val_loss: 1.5650 - val_accuracy: 0.7341\n",
            "Epoch 902/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1820 - accuracy: 0.9376 - val_loss: 1.6284 - val_accuracy: 0.7287\n",
            "Epoch 903/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1949 - accuracy: 0.9348 - val_loss: 1.5234 - val_accuracy: 0.7331\n",
            "Epoch 904/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1906 - accuracy: 0.9364 - val_loss: 1.6339 - val_accuracy: 0.7275\n",
            "Epoch 905/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1885 - accuracy: 0.9362 - val_loss: 1.5741 - val_accuracy: 0.7316\n",
            "Epoch 906/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1939 - accuracy: 0.9348 - val_loss: 1.6278 - val_accuracy: 0.7333\n",
            "Epoch 907/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1918 - accuracy: 0.9347 - val_loss: 1.6127 - val_accuracy: 0.7326\n",
            "Epoch 908/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1888 - accuracy: 0.9357 - val_loss: 1.4762 - val_accuracy: 0.7309\n",
            "Epoch 909/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1935 - accuracy: 0.9366 - val_loss: 1.6179 - val_accuracy: 0.7332\n",
            "Epoch 910/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1875 - accuracy: 0.9371 - val_loss: 1.6329 - val_accuracy: 0.7340\n",
            "Epoch 911/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1965 - accuracy: 0.9363 - val_loss: 1.5514 - val_accuracy: 0.7303\n",
            "Epoch 912/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1851 - accuracy: 0.9386 - val_loss: 1.5077 - val_accuracy: 0.7300\n",
            "Epoch 913/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1838 - accuracy: 0.9403 - val_loss: 1.6048 - val_accuracy: 0.7322\n",
            "Epoch 914/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1962 - accuracy: 0.9348 - val_loss: 1.5644 - val_accuracy: 0.7237\n",
            "Epoch 915/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1862 - accuracy: 0.9368 - val_loss: 1.5614 - val_accuracy: 0.7306\n",
            "Epoch 916/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1838 - accuracy: 0.9394 - val_loss: 1.5357 - val_accuracy: 0.7240\n",
            "Epoch 917/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1880 - accuracy: 0.9357 - val_loss: 1.5504 - val_accuracy: 0.7311\n",
            "Epoch 918/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1896 - accuracy: 0.9366 - val_loss: 1.4982 - val_accuracy: 0.7265\n",
            "Epoch 919/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1981 - accuracy: 0.9334 - val_loss: 1.7462 - val_accuracy: 0.7314\n",
            "Epoch 920/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1889 - accuracy: 0.9375 - val_loss: 1.5676 - val_accuracy: 0.7247\n",
            "Epoch 921/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1973 - accuracy: 0.9353 - val_loss: 1.5468 - val_accuracy: 0.7307\n",
            "Epoch 922/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1886 - accuracy: 0.9363 - val_loss: 1.5438 - val_accuracy: 0.7327\n",
            "Epoch 923/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1920 - accuracy: 0.9367 - val_loss: 1.7590 - val_accuracy: 0.7301\n",
            "Epoch 924/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1931 - accuracy: 0.9358 - val_loss: 1.5357 - val_accuracy: 0.7293\n",
            "Epoch 925/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1948 - accuracy: 0.9348 - val_loss: 1.5099 - val_accuracy: 0.7267\n",
            "Epoch 926/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1893 - accuracy: 0.9353 - val_loss: 1.5732 - val_accuracy: 0.7283\n",
            "Epoch 927/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1827 - accuracy: 0.9399 - val_loss: 1.5368 - val_accuracy: 0.7257\n",
            "Epoch 928/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1986 - accuracy: 0.9334 - val_loss: 1.5326 - val_accuracy: 0.7326\n",
            "Epoch 929/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1976 - accuracy: 0.9348 - val_loss: 1.5860 - val_accuracy: 0.7341\n",
            "Epoch 930/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1876 - accuracy: 0.9359 - val_loss: 1.5280 - val_accuracy: 0.7351\n",
            "Epoch 931/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1994 - accuracy: 0.9332 - val_loss: 1.5368 - val_accuracy: 0.7311\n",
            "Epoch 932/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1921 - accuracy: 0.9357 - val_loss: 1.5921 - val_accuracy: 0.7342\n",
            "Epoch 933/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1925 - accuracy: 0.9345 - val_loss: 1.6435 - val_accuracy: 0.7311\n",
            "Epoch 934/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1942 - accuracy: 0.9342 - val_loss: 1.6402 - val_accuracy: 0.7311\n",
            "Epoch 935/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1849 - accuracy: 0.9381 - val_loss: 1.5661 - val_accuracy: 0.7346\n",
            "Epoch 936/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1923 - accuracy: 0.9361 - val_loss: 1.5687 - val_accuracy: 0.7382\n",
            "Epoch 937/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1923 - accuracy: 0.9357 - val_loss: 1.6199 - val_accuracy: 0.7275\n",
            "Epoch 938/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1774 - accuracy: 0.9395 - val_loss: 1.5747 - val_accuracy: 0.7336\n",
            "Epoch 939/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1949 - accuracy: 0.9364 - val_loss: 1.5495 - val_accuracy: 0.7330\n",
            "Epoch 940/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1869 - accuracy: 0.9376 - val_loss: 1.5125 - val_accuracy: 0.7308\n",
            "Epoch 941/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1817 - accuracy: 0.9383 - val_loss: 1.5250 - val_accuracy: 0.7362\n",
            "Epoch 942/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1913 - accuracy: 0.9359 - val_loss: 1.6178 - val_accuracy: 0.7337\n",
            "Epoch 943/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1919 - accuracy: 0.9339 - val_loss: 1.6037 - val_accuracy: 0.7346\n",
            "Epoch 944/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1946 - accuracy: 0.9352 - val_loss: 1.6753 - val_accuracy: 0.7297\n",
            "Epoch 945/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1927 - accuracy: 0.9342 - val_loss: 1.5458 - val_accuracy: 0.7340\n",
            "Epoch 946/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1893 - accuracy: 0.9361 - val_loss: 1.6369 - val_accuracy: 0.7334\n",
            "Epoch 947/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1915 - accuracy: 0.9369 - val_loss: 1.6257 - val_accuracy: 0.7301\n",
            "Epoch 948/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1898 - accuracy: 0.9375 - val_loss: 1.5825 - val_accuracy: 0.7319\n",
            "Epoch 949/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1865 - accuracy: 0.9367 - val_loss: 1.6715 - val_accuracy: 0.7340\n",
            "Epoch 950/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1950 - accuracy: 0.9342 - val_loss: 1.5597 - val_accuracy: 0.7291\n",
            "Epoch 951/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1906 - accuracy: 0.9361 - val_loss: 1.5176 - val_accuracy: 0.7343\n",
            "Epoch 952/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1900 - accuracy: 0.9359 - val_loss: 1.5618 - val_accuracy: 0.7310\n",
            "Epoch 953/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1933 - accuracy: 0.9350 - val_loss: 1.5635 - val_accuracy: 0.7334\n",
            "Epoch 954/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1865 - accuracy: 0.9381 - val_loss: 1.5558 - val_accuracy: 0.7321\n",
            "Epoch 955/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1941 - accuracy: 0.9336 - val_loss: 1.5811 - val_accuracy: 0.7315\n",
            "Epoch 956/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1985 - accuracy: 0.9341 - val_loss: 1.6324 - val_accuracy: 0.7330\n",
            "Epoch 957/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1927 - accuracy: 0.9357 - val_loss: 1.5326 - val_accuracy: 0.7286\n",
            "Epoch 958/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.2051 - accuracy: 0.9345 - val_loss: 1.6042 - val_accuracy: 0.7367\n",
            "Epoch 959/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1905 - accuracy: 0.9343 - val_loss: 1.6343 - val_accuracy: 0.7336\n",
            "Epoch 960/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1888 - accuracy: 0.9359 - val_loss: 1.5198 - val_accuracy: 0.7305\n",
            "Epoch 961/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1925 - accuracy: 0.9378 - val_loss: 1.4887 - val_accuracy: 0.7346\n",
            "Epoch 962/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1961 - accuracy: 0.9354 - val_loss: 1.5103 - val_accuracy: 0.7358\n",
            "Epoch 963/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1785 - accuracy: 0.9394 - val_loss: 1.5289 - val_accuracy: 0.7255\n",
            "Epoch 964/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1948 - accuracy: 0.9354 - val_loss: 1.5210 - val_accuracy: 0.7326\n",
            "Epoch 965/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1847 - accuracy: 0.9380 - val_loss: 1.5495 - val_accuracy: 0.7326\n",
            "Epoch 966/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1910 - accuracy: 0.9368 - val_loss: 1.6264 - val_accuracy: 0.7296\n",
            "Epoch 967/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1974 - accuracy: 0.9378 - val_loss: 1.6072 - val_accuracy: 0.7338\n",
            "Epoch 968/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1908 - accuracy: 0.9355 - val_loss: 1.6074 - val_accuracy: 0.7346\n",
            "Epoch 969/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1914 - accuracy: 0.9377 - val_loss: 1.5405 - val_accuracy: 0.7281\n",
            "Epoch 970/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1886 - accuracy: 0.9356 - val_loss: 1.5061 - val_accuracy: 0.7354\n",
            "Epoch 971/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1945 - accuracy: 0.9364 - val_loss: 1.5702 - val_accuracy: 0.7301\n",
            "Epoch 972/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1915 - accuracy: 0.9349 - val_loss: 1.6414 - val_accuracy: 0.7358\n",
            "Epoch 973/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1903 - accuracy: 0.9372 - val_loss: 1.6530 - val_accuracy: 0.7300\n",
            "Epoch 974/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1943 - accuracy: 0.9354 - val_loss: 1.5709 - val_accuracy: 0.7329\n",
            "Epoch 975/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1871 - accuracy: 0.9384 - val_loss: 1.5799 - val_accuracy: 0.7330\n",
            "Epoch 976/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1930 - accuracy: 0.9346 - val_loss: 1.6397 - val_accuracy: 0.7301\n",
            "Epoch 977/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1960 - accuracy: 0.9358 - val_loss: 1.5522 - val_accuracy: 0.7346\n",
            "Epoch 978/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1888 - accuracy: 0.9360 - val_loss: 1.6199 - val_accuracy: 0.7382\n",
            "Epoch 979/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1853 - accuracy: 0.9385 - val_loss: 1.6742 - val_accuracy: 0.7281\n",
            "Epoch 980/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1938 - accuracy: 0.9351 - val_loss: 1.6103 - val_accuracy: 0.7209\n",
            "Epoch 981/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1983 - accuracy: 0.9366 - val_loss: 1.5471 - val_accuracy: 0.7347\n",
            "Epoch 982/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1926 - accuracy: 0.9344 - val_loss: 1.5577 - val_accuracy: 0.7220\n",
            "Epoch 983/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1990 - accuracy: 0.9335 - val_loss: 1.5411 - val_accuracy: 0.7376\n",
            "Epoch 984/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1903 - accuracy: 0.9378 - val_loss: 1.6254 - val_accuracy: 0.7370\n",
            "Epoch 985/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1932 - accuracy: 0.9360 - val_loss: 1.5619 - val_accuracy: 0.7320\n",
            "Epoch 986/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1844 - accuracy: 0.9380 - val_loss: 1.5610 - val_accuracy: 0.7318\n",
            "Epoch 987/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1953 - accuracy: 0.9342 - val_loss: 1.5734 - val_accuracy: 0.7328\n",
            "Epoch 988/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1988 - accuracy: 0.9345 - val_loss: 1.5731 - val_accuracy: 0.7311\n",
            "Epoch 989/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1961 - accuracy: 0.9325 - val_loss: 1.5404 - val_accuracy: 0.7260\n",
            "Epoch 990/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1838 - accuracy: 0.9373 - val_loss: 1.6209 - val_accuracy: 0.7326\n",
            "Epoch 991/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1921 - accuracy: 0.9370 - val_loss: 1.6892 - val_accuracy: 0.7299\n",
            "Epoch 992/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1905 - accuracy: 0.9367 - val_loss: 1.6816 - val_accuracy: 0.7358\n",
            "Epoch 993/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1897 - accuracy: 0.9362 - val_loss: 1.7029 - val_accuracy: 0.7357\n",
            "Epoch 994/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1960 - accuracy: 0.9352 - val_loss: 1.5688 - val_accuracy: 0.7321\n",
            "Epoch 995/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1983 - accuracy: 0.9346 - val_loss: 1.5107 - val_accuracy: 0.7337\n",
            "Epoch 996/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1937 - accuracy: 0.9327 - val_loss: 1.5952 - val_accuracy: 0.7304\n",
            "Epoch 997/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1888 - accuracy: 0.9370 - val_loss: 1.5669 - val_accuracy: 0.7328\n",
            "Epoch 998/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1868 - accuracy: 0.9367 - val_loss: 1.5699 - val_accuracy: 0.7323\n",
            "Epoch 999/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1881 - accuracy: 0.9370 - val_loss: 1.5931 - val_accuracy: 0.7318\n",
            "Epoch 1000/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1941 - accuracy: 0.9341 - val_loss: 1.6155 - val_accuracy: 0.7310\n",
            "Epoch 1001/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1917 - accuracy: 0.9334 - val_loss: 1.5653 - val_accuracy: 0.7308\n",
            "Epoch 1002/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.2009 - accuracy: 0.9350 - val_loss: 1.6614 - val_accuracy: 0.7320\n",
            "Epoch 1003/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1891 - accuracy: 0.9366 - val_loss: 1.5881 - val_accuracy: 0.7314\n",
            "Epoch 1004/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1925 - accuracy: 0.9353 - val_loss: 1.5486 - val_accuracy: 0.7314\n",
            "Epoch 1005/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1899 - accuracy: 0.9372 - val_loss: 1.5683 - val_accuracy: 0.7360\n",
            "Epoch 1006/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1931 - accuracy: 0.9348 - val_loss: 1.6003 - val_accuracy: 0.7243\n",
            "Epoch 1007/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1823 - accuracy: 0.9383 - val_loss: 1.5811 - val_accuracy: 0.7325\n",
            "Epoch 1008/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1938 - accuracy: 0.9341 - val_loss: 1.6133 - val_accuracy: 0.7309\n",
            "Epoch 1009/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1913 - accuracy: 0.9356 - val_loss: 1.6626 - val_accuracy: 0.7311\n",
            "Epoch 1010/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1991 - accuracy: 0.9322 - val_loss: 1.6526 - val_accuracy: 0.7298\n",
            "Epoch 1011/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1850 - accuracy: 0.9373 - val_loss: 1.6392 - val_accuracy: 0.7325\n",
            "Epoch 1012/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1914 - accuracy: 0.9370 - val_loss: 1.5573 - val_accuracy: 0.7346\n",
            "Epoch 1013/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1891 - accuracy: 0.9359 - val_loss: 1.5460 - val_accuracy: 0.7361\n",
            "Epoch 1014/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1910 - accuracy: 0.9351 - val_loss: 1.5991 - val_accuracy: 0.7284\n",
            "Epoch 1015/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1968 - accuracy: 0.9342 - val_loss: 1.6143 - val_accuracy: 0.7253\n",
            "Epoch 1016/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1976 - accuracy: 0.9341 - val_loss: 1.6637 - val_accuracy: 0.7334\n",
            "Epoch 1017/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.2012 - accuracy: 0.9323 - val_loss: 1.5804 - val_accuracy: 0.7340\n",
            "Epoch 1018/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1969 - accuracy: 0.9355 - val_loss: 1.5874 - val_accuracy: 0.7315\n",
            "Epoch 1019/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1847 - accuracy: 0.9389 - val_loss: 1.6213 - val_accuracy: 0.7342\n",
            "Epoch 1020/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1932 - accuracy: 0.9376 - val_loss: 1.5713 - val_accuracy: 0.7263\n",
            "Epoch 1021/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1935 - accuracy: 0.9363 - val_loss: 1.5608 - val_accuracy: 0.7318\n",
            "Epoch 1022/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1974 - accuracy: 0.9342 - val_loss: 1.5958 - val_accuracy: 0.7336\n",
            "Epoch 1023/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1950 - accuracy: 0.9346 - val_loss: 1.6081 - val_accuracy: 0.7359\n",
            "Epoch 1024/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1939 - accuracy: 0.9361 - val_loss: 1.5979 - val_accuracy: 0.7335\n",
            "Epoch 1025/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1960 - accuracy: 0.9361 - val_loss: 1.6517 - val_accuracy: 0.7368\n",
            "Epoch 1026/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.2010 - accuracy: 0.9325 - val_loss: 1.6537 - val_accuracy: 0.7359\n",
            "Epoch 1027/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1908 - accuracy: 0.9356 - val_loss: 1.7127 - val_accuracy: 0.7376\n",
            "Epoch 1028/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.2047 - accuracy: 0.9341 - val_loss: 1.6071 - val_accuracy: 0.7314\n",
            "Epoch 1029/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1875 - accuracy: 0.9377 - val_loss: 1.6791 - val_accuracy: 0.7313\n",
            "Epoch 1030/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1889 - accuracy: 0.9363 - val_loss: 1.6924 - val_accuracy: 0.7234\n",
            "Epoch 1031/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1991 - accuracy: 0.9351 - val_loss: 1.5164 - val_accuracy: 0.7326\n",
            "Epoch 1032/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1965 - accuracy: 0.9357 - val_loss: 1.5289 - val_accuracy: 0.7353\n",
            "Epoch 1033/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1911 - accuracy: 0.9381 - val_loss: 1.5859 - val_accuracy: 0.7250\n",
            "Epoch 1034/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1967 - accuracy: 0.9359 - val_loss: 1.6052 - val_accuracy: 0.7389\n",
            "Epoch 1035/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1904 - accuracy: 0.9375 - val_loss: 1.5976 - val_accuracy: 0.7306\n",
            "Epoch 1036/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1873 - accuracy: 0.9360 - val_loss: 1.5425 - val_accuracy: 0.7305\n",
            "Epoch 1037/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1980 - accuracy: 0.9346 - val_loss: 1.5792 - val_accuracy: 0.7376\n",
            "Epoch 1038/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1943 - accuracy: 0.9340 - val_loss: 1.5939 - val_accuracy: 0.7311\n",
            "Epoch 1039/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1879 - accuracy: 0.9361 - val_loss: 1.6491 - val_accuracy: 0.7302\n",
            "Epoch 1040/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.2062 - accuracy: 0.9322 - val_loss: 1.5607 - val_accuracy: 0.7270\n",
            "Epoch 1041/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1956 - accuracy: 0.9342 - val_loss: 1.7168 - val_accuracy: 0.7351\n",
            "Epoch 1042/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1975 - accuracy: 0.9351 - val_loss: 1.6293 - val_accuracy: 0.7237\n",
            "Epoch 1043/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1958 - accuracy: 0.9340 - val_loss: 1.5962 - val_accuracy: 0.7296\n",
            "Epoch 1044/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1918 - accuracy: 0.9356 - val_loss: 1.5891 - val_accuracy: 0.7334\n",
            "Epoch 1045/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1988 - accuracy: 0.9349 - val_loss: 1.5563 - val_accuracy: 0.7363\n",
            "Epoch 1046/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.2020 - accuracy: 0.9340 - val_loss: 1.5849 - val_accuracy: 0.7328\n",
            "Epoch 1047/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1996 - accuracy: 0.9319 - val_loss: 1.6315 - val_accuracy: 0.7269\n",
            "Epoch 1048/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1997 - accuracy: 0.9352 - val_loss: 1.6773 - val_accuracy: 0.7312\n",
            "Epoch 1049/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1935 - accuracy: 0.9347 - val_loss: 1.6625 - val_accuracy: 0.7293\n",
            "Epoch 1050/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.2053 - accuracy: 0.9327 - val_loss: 1.6191 - val_accuracy: 0.7270\n",
            "Epoch 1051/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1947 - accuracy: 0.9364 - val_loss: 1.5982 - val_accuracy: 0.7334\n",
            "Epoch 1052/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1881 - accuracy: 0.9366 - val_loss: 1.6480 - val_accuracy: 0.7222\n",
            "Epoch 1053/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1907 - accuracy: 0.9363 - val_loss: 1.5271 - val_accuracy: 0.7314\n",
            "Epoch 1054/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1929 - accuracy: 0.9351 - val_loss: 1.7036 - val_accuracy: 0.7333\n",
            "Epoch 1055/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1964 - accuracy: 0.9345 - val_loss: 1.5687 - val_accuracy: 0.7344\n",
            "Epoch 1056/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1885 - accuracy: 0.9360 - val_loss: 1.5991 - val_accuracy: 0.7346\n",
            "Epoch 1057/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1973 - accuracy: 0.9357 - val_loss: 1.6360 - val_accuracy: 0.7304\n",
            "Epoch 1058/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1977 - accuracy: 0.9329 - val_loss: 1.6023 - val_accuracy: 0.7298\n",
            "Epoch 1059/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1991 - accuracy: 0.9332 - val_loss: 1.6245 - val_accuracy: 0.7327\n",
            "Epoch 1060/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1922 - accuracy: 0.9371 - val_loss: 1.6129 - val_accuracy: 0.7329\n",
            "Epoch 1061/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1972 - accuracy: 0.9328 - val_loss: 1.6278 - val_accuracy: 0.7349\n",
            "Epoch 1062/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1921 - accuracy: 0.9380 - val_loss: 1.6417 - val_accuracy: 0.7335\n",
            "Epoch 1063/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.2075 - accuracy: 0.9321 - val_loss: 1.6174 - val_accuracy: 0.7300\n",
            "Epoch 1064/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1913 - accuracy: 0.9356 - val_loss: 1.6395 - val_accuracy: 0.7328\n",
            "Epoch 1065/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1902 - accuracy: 0.9346 - val_loss: 1.6694 - val_accuracy: 0.7338\n",
            "Epoch 1066/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1875 - accuracy: 0.9369 - val_loss: 1.6908 - val_accuracy: 0.7266\n",
            "Epoch 1067/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1925 - accuracy: 0.9352 - val_loss: 1.7041 - val_accuracy: 0.7311\n",
            "Epoch 1068/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1891 - accuracy: 0.9381 - val_loss: 1.6062 - val_accuracy: 0.7308\n",
            "Epoch 1069/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1893 - accuracy: 0.9352 - val_loss: 1.7252 - val_accuracy: 0.7228\n",
            "Epoch 1070/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1998 - accuracy: 0.9349 - val_loss: 1.6426 - val_accuracy: 0.7307\n",
            "Epoch 1071/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1920 - accuracy: 0.9346 - val_loss: 1.6438 - val_accuracy: 0.7342\n",
            "Epoch 1072/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1895 - accuracy: 0.9371 - val_loss: 1.7118 - val_accuracy: 0.7324\n",
            "Epoch 1073/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.2011 - accuracy: 0.9351 - val_loss: 1.6350 - val_accuracy: 0.7303\n",
            "Epoch 1074/1080\n",
            "183/183 [==============================] - 4s 21ms/step - loss: 0.1942 - accuracy: 0.9354 - val_loss: 1.6725 - val_accuracy: 0.7333\n",
            "Epoch 1075/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1877 - accuracy: 0.9373 - val_loss: 1.6760 - val_accuracy: 0.7324\n",
            "Epoch 1076/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1972 - accuracy: 0.9365 - val_loss: 1.6293 - val_accuracy: 0.7378\n",
            "Epoch 1077/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.2026 - accuracy: 0.9328 - val_loss: 1.6939 - val_accuracy: 0.7322\n",
            "Epoch 1078/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1907 - accuracy: 0.9365 - val_loss: 1.5226 - val_accuracy: 0.7330\n",
            "Epoch 1079/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1845 - accuracy: 0.9394 - val_loss: 1.5870 - val_accuracy: 0.7342\n",
            "Epoch 1080/1080\n",
            "183/183 [==============================] - 4s 22ms/step - loss: 0.1876 - accuracy: 0.9385 - val_loss: 1.6568 - val_accuracy: 0.7333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8140312210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vni_9AwmaOq2",
        "outputId": "b964daf8-eeee-4def-d5bb-f226e12d0a37"
      },
      "source": [
        "# Test set\n",
        "accr = model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "366/366 [==============================] - 1s 4ms/step - loss: 1.6568 - accuracy: 0.7333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMNjclmTFZDl",
        "outputId": "81d5ca8b-70d2-4f3b-eba2-1f6c54b52822"
      },
      "source": [
        "# Macro F1 score\n",
        "y_pred = np.around(model.predict(x_test))\n",
        "f1_score(y_test, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6499364290004981"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTpOlmGqa6Kp"
      },
      "source": [
        "def classify_string(input):\n",
        "  lyric = [str(input)]\n",
        "  seq = tk.texts_to_sequences(lyric)\n",
        "  pred = model.predict(seq)\n",
        "  labels = ['rock', 'country', 'pop', 'rap']\n",
        "  print(labels[np.argmax(pred)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGxIQstjbBjj"
      },
      "source": [
        "def classify_list(input):\n",
        "  for lyric in input:\n",
        "    classify_string(lyric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIgVJW1gJjME"
      },
      "source": [
        "def classify_perc(input):\n",
        "  def cla(input):\n",
        "    lyric = [str(input)]\n",
        "    seq = tk.texts_to_sequences(lyric)\n",
        "    pred = model.predict(seq)\n",
        "    labels = ['rock', 'country', 'pop', 'rap']\n",
        "    return str(labels[np.argmax(pred)])\n",
        "  results = list(map(cla, input))\n",
        "  return (results.count('rap'))/400"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGPXLCrKbD_5",
        "outputId": "4cc06252-a65c-48a6-8b79-73ca371613b6"
      },
      "source": [
        "# markov generated lyrics sample\n",
        "lyrics = ['Bumpin i meant for you call my ninja like',\n",
        " 'Biz dont take their baby mommas ninja frick you nasty boy you',\n",
        " 'Shifty sticks and pray and flee the frick all of you',\n",
        " 'Glocks but all ill die slow',\n",
        " 'Wondering if im askin blunt sip champagne range rover been outside for',\n",
        " 'And youre so take that crown two pounds you know',\n",
        " 'Publishing i thought i get witcha can i could cop',\n",
        " 'Miss the more cause you in the right one',\n",
        " 'Onyx and them hoes i love',\n",
        " 'Gat call me puff daddy biggie gots ta like',\n",
        " 'Everything around me shit b***** in ya imma stay yappin when',\n",
        " 'Hum all about fingers in the loot im',\n",
        " 'Rollem up heard whos this yeah keep on top sky is',\n",
        " 'Drunk of ninjaz from now drop to',\n",
        " 'Declinin windin like flypaper neighbor slow down',\n",
        " 'Expensive cars i tote my crew i only got enough heart',\n",
        " 'Lame dudes whos next move but the drugs to spit phrases thatll',\n",
        " 'Guy well its cool and your poop so hard to',\n",
        " 'Clap wit my life in ma little nasty boy',\n",
        " 'Dial you should too much better man played',\n",
        " 'Lali like that you frick doin all mcs have']\n",
        "\n",
        "classify_list(lyrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 201) for input KerasTensor(type_spec=TensorSpec(shape=(None, 201), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rock\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "pop\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CR5PqhObFrp",
        "outputId": "45f19d32-c627-461f-d8df-13e565b46393"
      },
      "source": [
        "# lstm generated lyrics sample\n",
        "lyrics2 = ['in the veins hard to explain how i maintain', \n",
        "  'to put my back in the house so i can i wanna flaunt you thats right', \n",
        "  'with the grime of my ninja frick',\n",
        "  'with the ds crept in blastin him you dont want to slit the clits alot',\n",
        "  'used to lick the clits a lot of problems never be the beamer with the goldie sound',\n",
        "  'like a steelo not my steelo oh no thats not my my steelo oh i steelo not my steelo oh no',\n",
        "  'thats not my no steelo bust my no dough day but this sittin bodies not my']\n",
        "\n",
        "classify_list(lyrics2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rock\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n",
            "rap\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFcWTo_bJUiV"
      },
      "source": [
        "# Our two tests for Markov generated and RNN generated lyrics are below - each 400 lines worth\n",
        "# Lyrics included so that they can be seen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D3KObmKJUwV",
        "outputId": "e06b640f-baf2-49f3-98f7-c05e97a71d0f"
      },
      "source": [
        "# Markov\n",
        "markov_lyrics = ['Come here sit on a spot up out with em',\n",
        " 'Put the game ninja cause please believe it was way',\n",
        " 'Brought the golf hat the one eight seven kidnaps and',\n",
        " 'Guns  yall a read yall a gangsta bedtime story',\n",
        " 'You better have you need a gangsta bedtime story by',\n",
        " 'Ever slapped a gangsta bedtime story  great scotts its',\n",
        " 'Here sit on a kit kat  great scotts its',\n",
        " 'Bedtime story by saying goodnight  yall get em frick',\n",
        " 'Upon a trip up in town my ninja even if',\n",
        " 'Do my ninja caught up on a trip up to',\n",
        " 'All the downlow oh once upon a trip up on',\n",
        " 'Do nothing to get a gangsta bedtime story  yall',\n",
        " 'Grease strikes you need a gangsta bedtime story  and',\n",
        " 'To stay on some traffic behind some traffic behind some',\n",
        " 'Can ride on some traffic behind some traffic behind some',\n",
        " 'What time it was way to him cause please believe',\n",
        " 'Couldnt do my lap  to him cause please believe',\n",
        " 'S-n double o-p fa sho i had to real i',\n",
        " 'Gotta end this muthafricka cuz i had to real i',\n",
        " 'In the women stayed true to get your b***** aint',\n",
        " 'Chest he was we got thugs cons drugs and i',\n",
        " 'Your sack and jacks i gotta end this story ',\n",
        " 'Stick ninja and then i gotta end this story ',\n",
        " 'Ride on deck so i ran up in his hands',\n",
        " 'Eatin on deck so i ran up in his hands',\n",
        " 'Spot up in his hands in this ninja and this',\n",
        " 'End this story by saying goodnight  and jacks i',\n",
        " 'Thugs cons drugs and your grip or better yet strapped',\n",
        " 'Brought snaps to mack your grip or better yet strapped',\n",
        " 'Today he ran up in some traffic behind some hood',\n",
        " 'Muthafrickin vietnam vet riding on some traffic behind some hood',\n",
        " 'Kids looked up in some ninjas for heater  could',\n",
        " 'From the one eight seven kidnaps and doves have you',\n",
        " 'Vet riding on this ninja im that ninja raps to',\n",
        " 'Way to the little homie hit that ninja raps to',\n",
        " 'Drop you read us a bedtime story by saying goodnight',\n",
        " 'Strikes you need a bedtime story by saying goodnight ',\n",
        " 'Sack before i shot him because he tried to do',\n",
        " 'Sack before i do my ninja even if we cool',\n",
        " 'Its hot anybody can go down my ash tray get',\n",
        " 'Sho i brought snaps to do my ash tray get',\n",
        " 'Slapped a steak eatin on this ninja even if we',\n",
        " 'Women stayed true to stay on this ninja even dimes',\n",
        " 'Homie hit that big rap name ninja caught up on',\n",
        " 'Floor with me we claiming everything ninja caught up to',\n",
        " 'One eight seven kidnaps and go get back and your',\n",
        " 'Skandelous raps to the black poker sack and your b*****',\n",
        " 'Brought the dpg and jacks i came out  yall',\n",
        " 'Stranger to him but i gotta end this skandelous raps',\n",
        " 'Danger aint no stranger to him cause hes like me',\n",
        " 'Vietnam vet riding on this ninja cause hes like me',\n",
        " 'Stainless steel and guns  okay check it was wearing',\n",
        " 'Lighter  and doves have a time it was wearing',\n",
        " 'Show these ninjas for a clip  okay check it',\n",
        " 'Whassup  and guns  alright  okay check it',\n",
        " 'Have you need a kit kat  come here sit',\n",
        " 'Frick em lets go get back  come here sit',\n",
        " 'Cut throat on the curl back and jacks i brought',\n",
        " 'Thugs cons drugs and this ninja and jacks i brought',\n",
        " 'Who brought the black poker sack before i gotta end',\n",
        " 'True to the black poker sack before i gotta end',\n",
        " 'Didnt care peck he ran up on deck so fly',\n",
        " 'Dont know why but i ran up on deck so',\n",
        " 'Cool with his vision gettin blurry but hes like a',\n",
        " 'Rat grease strikes you need a ninja even dimes and',\n",
        " 'Cuz i came out with em frick em lets go',\n",
        " 'Tray get back and all the game like me to',\n",
        " 'Cuz i shot him because he ran up on the',\n",
        " 'Vision gettin hot today he ran up on the lbc',\n",
        " 'Could get a b***** aint no get my ninja s-n',\n",
        " 'Stayed true to him in his hands in some ninjas',\n",
        " 'Or better yet strapped a stick ninja caught up to',\n",
        " 'Need a read yall a stick ninja caught up to',\n",
        " 'Me lets go get my ninja like a bedtime story',\n",
        " 'Og from the lbc there lived a bedtime story by',\n",
        " 'Town my ash tray get my ninja and all the',\n",
        " 'Here sit back wishing for that ninja and all they',\n",
        " 'Eatin on him in his hands in his hands in',\n",
        " 'Skandelous raps the golf hat the air his hands in',\n",
        " 'Pat your grip or better have a muthafrickin vietnam vet',\n",
        " 'Your grip or better yet strapped a muthafrickin vietnam vet',\n",
        " 'Before i shot him all even dimes and this ninja',\n",
        " 'Lap  to him cause hes like a stick ninja',\n",
        " 'Because he fell to do my set no stranger to',\n",
        " 'Air his hands in town my set no stranger to',\n",
        " 'Brought the air his chest he was way to do',\n",
        " 'Shot him in his chest he was way to do',\n",
        " 'Smack for that im that sit on this story by',\n",
        " 'Ash tray get a steak eatin on this story ',\n",
        " 'That sit back  okay check it it it was',\n",
        " 'Riding on some ninjas for a time in this ninja',\n",
        " 'Em lets go get a gangsta bedtime story  okay',\n",
        " 'Ran up to him police tried to do my lap',\n",
        " 'Story  and i turn around and the downlow oh',\n",
        " 'Stainless steel and your b***** aint poop the downlow oh',\n",
        " 'Stay on the little kids looked up on the hood',\n",
        " 'This ninja who brought snaps to him in some hood',\n",
        " 'Saying goodnight  could you read us a trip up',\n",
        " 'Wearing slack i do my ninja like a trip up',\n",
        " 'Poop the game ninja who brought the dpg and guns',\n",
        " 'Dont know why but you better have you read us',\n",
        " 'Cut throat on the ride down my lap  okay',\n",
        " 'No warning shots on some hood gettin hot anybody can',\n",
        " 'Better yet strapped a time in his hands in the',\n",
        " 'Tried to the floor with his hands in the dpg',\n",
        " 'Great scotts its hot today he ran up with me',\n",
        " 'Great scotts its hot today he ran up in the',\n",
        " 'Warning shots on the afro back and snatch your back',\n",
        " 'Og from the afro back  and pat your sack',\n",
        " 'Wearing slack i shot him because he was wearing slack',\n",
        " 'Warning shots on this ninja you ever slapped a ninja',\n",
        " 'Hated on some hood gettin blurry but i brought the',\n",
        " 'Wearing slack i dont know why but i brought the',\n",
        " 'Who brought snaps to show these ninjas what time in',\n",
        " 'So i had to show these ninjas what time it',\n",
        " 'His hands in the little kids looked up out of',\n",
        " 'Dpg and the little kids looked up out  to',\n",
        " 'For heater  great scotts its hot today he fell',\n",
        " 'Kat  and the hood gettin hot today he fell',\n",
        " 'Like stainless steel and i didnt care peck he tried',\n",
        " 'On this muthafricka cuz i didnt care peck he tried',\n",
        " 'Whassup whassup  yall a clip  we cool with',\n",
        " 'At all the air his hands in the floor with',\n",
        " 'Claiming everything ninja disrepectin my ninja disrepectin my lap ',\n",
        " 'Riding on this ninja disrepectin my ninja disrepectin my lap',\n",
        " 'Of g two seater you out  we can drop',\n",
        " 'Heater  we can drop you could get a spot',\n",
        " 'Shot him in his neck shooting like that im a',\n",
        " 'Trip up in his neck shooting like that im a',\n",
        " 'Tried to mack your game ninja cause hes like stainless',\n",
        " 'Millimeter for that young ninja even if we can ride',\n",
        " 'Raps the little kids looked up on deck so fly',\n",
        " 'Could you better have a trip up on deck so',\n",
        " 'Just so i do him in town my thang way',\n",
        " 'Have a muthafrickin vietnam vet riding on my ash tray',\n",
        " 'Him all the floor with em lbc there lived a',\n",
        " 'Before i ran up with em lbc there lived a',\n",
        " 'Goodnight  and jacks i ran up in this ninja',\n",
        " 'Me lets go get a spot up in this ninja',\n",
        " 'Danger aint poop the afro back wishing for that young',\n",
        " 'Neck shooting like that sit back wishing for that young',\n",
        " 'At all the afro back wishing for that young ninja',\n",
        " 'Shots on a muthafrickin nine millimeter for that young ninja',\n",
        " 'Wishing for nuthin at all they hated on deck so',\n",
        " 'Young ninja and all they hated on deck so fly',\n",
        " 'Vet riding on a time in the game ninja you',\n",
        " 'Got thugs cons drugs and put the game ninja you',\n",
        " 'Riding on this story by saying goodnight  great scotts',\n",
        " 'Eatin on this story by saying goodnight  great scotts',\n",
        " 'Even dimes and then i came out of g two',\n",
        " 'Aint no get a trip up out of g two',\n",
        " 'It can go get a steak eatin on this ninja',\n",
        " 'Check it out  come here sit on this ninja',\n",
        " 'Why but couldnt do him but hes like me we',\n",
        " 'Here sit on this ninja cause hes like me lets',\n",
        " 'Bedtime story  to the golf hat the women stayed',\n",
        " 'The afro back  to him all the women stayed',\n",
        " 'Know why but i had to the ride down out',\n",
        " 'There lived a b***** aint poop the ride down out',\n",
        " 'Stranger to a clip  and then i ran up',\n",
        " 'Shot him all even dimes and then i ran up',\n",
        " 'Who brought the little kids looked up out ninjas what',\n",
        " 'Back wishing for heater  could you out ninjas was',\n",
        " 'Turn around and guns  okay check it out of',\n",
        " 'Wishing for a clip  okay check it out of',\n",
        " 'Fa sho i ran up on this muthafricka cuz i',\n",
        " 'Floor with no warning shots on this muthafricka cuz i',\n",
        " 'Eight seven kidnaps and snatch your sack and all they',\n",
        " 'Turn around and snatch your back  and all the',\n",
        " 'True to the curl back  im a ninja s-n',\n",
        " 'Vision gettin hot today he was wearing slack i had',\n",
        " 'Today he fell to him cause please believe it was',\n",
        " 'Vietnam vet riding on him cause please believe it can',\n",
        " 'B***** aint no warning shots on the little kids looked',\n",
        " 'Police tried to a og from the little kids looked',\n",
        " 'Brought the little homie hit that ninja raps the lbc',\n",
        " 'Stay on the little homie hit that big rap name',\n",
        " 'On a og from the game ninja and snatch your',\n",
        " 'Golf hat the one eight seven kidnaps and pat your',\n",
        " 'Could you need a time in his chest he fell',\n",
        " 'Sit on the air his neck shooting like me lets',\n",
        " 'End this ninja and your grip or better yet strapped',\n",
        " 'Afro back and snatch your grip or better yet strapped',\n",
        " 'Know why but you need a smack for that im',\n",
        " 'We cool with no get a smack for that big',\n",
        " 'Fell to the one eight seven kidnaps and then i',\n",
        " 'Cons drugs and all the curl back and then i',\n",
        " 'Can drop you out of g two seater you could',\n",
        " 'Time it out of g two seater you out ',\n",
        " 'Turn around and jacks i came out  okay check',\n",
        " 'Down out  and go down out  okay check',\n",
        " 'These ninjas what time in town my set no get',\n",
        " 'Cons drugs and snatch your b***** aint poop the one',\n",
        " 'Riding on my ninja and put the women stayed true',\n",
        " 'Got thugs cons drugs and put the women stayed true',\n",
        " 'Ever slapped a muthafrickin vietnam vet riding on a kit',\n",
        " 'Ever slapped a muthafrickin vietnam vet riding on a clip',\n",
        " 'Before i turn around and your grip or better yet',\n",
        " 'Because he fell to mack your grip or better yet',\n",
        " 'Your game like a read yall a kit kat ',\n",
        " 'Oh once upon a read yall a kit kat ',\n",
        " 'He ran up out with me lets go down my',\n",
        " 'Steel and doves have you out with me we cool',\n",
        " 'Real i shot him in his neck shooting like stainless',\n",
        " 'Thang way to the air his neck shooting like stainless',\n",
        " 'Lbc there lived a gangsta bedtime story  okay check',\n",
        " 'Curl back  im a bedtime story  okay check',\n",
        " 'Show these ninjas what time it can ride down my',\n",
        " 'Clip  im a time it can ride down my',\n",
        " 'Cons drugs and then i gotta end this muthafricka cuz',\n",
        " 'Even dimes and jacks i gotta end this muthafricka cuz',\n",
        " 'Like stainless steel and all the black poker sack and',\n",
        " 'Homie hit that ninja raps the black poker sack and',\n",
        " 'Doves have a og from the black poker sack and',\n",
        " 'Wearing slack i had to the black poker sack and',\n",
        " 'Turn around and go see take a b***** aint no',\n",
        " 'Muthafricka cuz i brought the dpg and jacks i do',\n",
        " 'Og from the game ninja you need a og from',\n",
        " 'Snaps to the game ninja you need a og from',\n",
        " 'Go down out ninjas was wearing slack i didnt care',\n",
        " 'In the women stayed true to real i didnt care',\n",
        " 'Afro back  we cool with his chest he tried',\n",
        " 'Sack before i do him in his chest he tried',\n",
        " 'Blurry but you read us a read yall get back',\n",
        " 'See take a smack for a read yall get a',\n",
        " 'Snatch your game ninja im that young ninja who brought',\n",
        " 'A muthafrickin nine millimeter for that young ninja who brought',\n",
        " 'They hated on some traffic behind some ninjas was wearing',\n",
        " 'Vet riding on some traffic behind some ninjas was wearing',\n",
        " 'Floor with me we claiming everything ninja caught up in',\n",
        " 'Young ninja im that im that ninja caught up with',\n",
        " 'Behind some traffic behind some ninjas what time it it',\n",
        " 'Stayed true to show these ninjas what time it it',\n",
        " 'Disrepectin my ash tray get em lets go down out',\n",
        " 'Steel and this story  and go down out ',\n",
        " ' to do him all even if we got thugs',\n",
        " 'That big rap name ninja even if we got thugs',\n",
        " 'Kidnaps and all the floor with em lets go get',\n",
        " 'The floor with his neck shooting like me to the',\n",
        " 'Cool with no get my ninja like me to him',\n",
        " 'Dont know i didnt care peck he fell to him',\n",
        " 'Kit kat  okay check it was we cool with',\n",
        " 'Heater  okay check it it was we cool with',\n",
        " 'Dimes and i shot him police tried to the little',\n",
        " 'Know i shot him because he fell to the little',\n",
        " 'On this story  and pat your grip or better',\n",
        " 'Name ninja even dimes and snatch your grip or better',\n",
        " 'Came out of bullets so fly but you could get',\n",
        " 'Pat your grip or better have you out of bullets',\n",
        " 'Me lets go get your back and put the ride',\n",
        " 'Clip  yall get back  and put the little',\n",
        " 'From the golf hat the curl back and your b*****',\n",
        " 'One eight seven kidnaps and guns  and pat your',\n",
        " 'To the dpg and doves have you could you could',\n",
        " 'Disrepectin my lighter  could you know why but you',\n",
        " 'By saying goodnight  and guns  we cool with',\n",
        " 'Game ninja raps to real i brought the floor with',\n",
        " 'Didnt care peck he ran up with me lets go',\n",
        " 'We claiming everything ninja caught up with me we got',\n",
        " 'Curl back and all they hated on deck so i',\n",
        " 'Wearing slack i brought the ride on deck so i',\n",
        " 'Fly but couldnt do him because he was we can',\n",
        " 'Women stayed true to him but you need a steak',\n",
        " 'Its hot anybody can go get my ninja like me',\n",
        " 'Cuz i shot him in the game ninja like me',\n",
        " 'Aint no get a steak eatin on deck so i',\n",
        " 'Strikes you need a steak eatin on deck so i',\n",
        " 'Can go see take a og from the air his',\n",
        " 'Kat  could get a bedtime story  we claiming',\n",
        " 'Fly but couldnt do my lighter  alright  okay',\n",
        " 'Game ninja disrepectin my ninja like that sit on a',\n",
        " 'Throat on a stick ninja like a time it was',\n",
        " 'Ninja disrepectin my ash tray get a time it was',\n",
        " 'Take a og from the little kids looked up out',\n",
        " 'Afro back and put the little kids looked up out',\n",
        " 'B***** to the curl back and jacks i gotta end',\n",
        " 'Can drop you ever slapped a b***** aint no stranger',\n",
        " 'Thang way to stay on my set no get a',\n",
        " 'Why but couldnt do my set no get my lap',\n",
        " 'Poop the golf hat the golf hat the floor with',\n",
        " 'Around and i brought the golf hat the floor with',\n",
        " 'Came out with me lets go get back wishing for',\n",
        " 'Yet strapped a spot up to get back wishing for',\n",
        " 'Gotta end this muthafricka cuz i brought the ride down',\n",
        " 'Town my lap  and put the ride down my',\n",
        " 'Great scotts its hot anybody can go get a clip',\n",
        " 'Snatch your back  and go get a clip ',\n",
        " 'From the downlow oh once upon a og from the',\n",
        " 'Because he ran up to a og from the lbc',\n",
        " 'Stay on deck so fly but i brought the game',\n",
        " 'Real i dont know why but i brought the game',\n",
        " 'Kidnaps and snatch your game like that young ninja like',\n",
        " 'Mack your grip or better yet strapped a ninja like',\n",
        " 'Shots on this skandelous raps the lbc there lived a',\n",
        " 'Ride down my ninja raps the lbc there lived a',\n",
        " 'Golf hat the afro back and all even if we',\n",
        " 'Hands in town my lap  and all even dimes',\n",
        " 'At all the game ninja dip with em frick em',\n",
        " 'Didnt care peck he tried to him in the little',\n",
        " 'Aint no warning shots on some ninjas what time in',\n",
        " 'Set no warning shots on some ninjas what time it',\n",
        " 'S-n double o-p fa sho i shot him but hes',\n",
        " 'S-n double o-p fa sho i shot him but hes',\n",
        " 'Have you better yet strapped a og from the afro',\n",
        " 'Us a spot up to a og from the afro',\n",
        " 'Claiming everything ninja disrepectin my thang way to the dpg',\n",
        " 'Kit kat  come here sit back and go get',\n",
        " 'Tray get my lighter  and all the afro back',\n",
        " 'Snatch your grip or better have a b***** to a',\n",
        " 'Here sit on my set no stranger to stay on',\n",
        " 'Vet riding on my ninja s-n double o-p fa sho',\n",
        " 'There lived a spot up on the curl back and',\n",
        " 'My set no warning shots on the curl back and',\n",
        " 'Hood rat grease strikes you read us a time in',\n",
        " 'I shot him in some traffic behind some traffic behind',\n",
        " 'Throat on the afro back and pat your sack before',\n",
        " 'Who brought the afro back and pat your sack before',\n",
        " 'And i gotta end this ninja s-n double o-p fa',\n",
        " 'Sit on him in this ninja s-n double o-p fa',\n",
        " 'Cut throat on this story  alright alright alright alright',\n",
        " 'Steel and guns  alright alright alright alright alright ',\n",
        " 'So i ran up in this ninja im a ninja',\n",
        " 'Ninjas what time in this ninja im that im a',\n",
        " 'Check it out of g two seater you ever slapped',\n",
        " 'Looked up out of g two seater you ever slapped',\n",
        " 'Ran up out of g two seater you know i',\n",
        " 'Drop you out of g two seater you know i',\n",
        " 'And snatch your b***** aint poop the little homie hit',\n",
        " 'Kat  yall a og from the little homie hit',\n",
        " 'Everything ninja dip with me we got thugs cons drugs',\n",
        " 'Jacks i came out of bullets so fly but you',\n",
        " 'Skandelous raps to him but couldnt do him because he',\n",
        " 'Gotta end this story  to do him because he',\n",
        " 'Tray get a clip  im that ninja raps the',\n",
        " 'Yet strapped a clip  im that big rap name',\n",
        " 'Show these ninjas for nuthin at all the one eight',\n",
        " 'Hat the black poker sack and all the one eight',\n",
        " 'Whassup  alright alright  and go get my ninja',\n",
        " 'At all the lbc in some traffic behind some ninjas',\n",
        " 'Had to stay on a bedtime story  we got',\n",
        " 'Had to real i brought the ride on deck so',\n",
        " 'Homie hit that sit on my ninja who brought the',\n",
        " 'Just so i brought the game ninja who brought the',\n",
        " 'Seater you read yall a trip up with his neck',\n",
        " 'Aint poop the little kids looked up in his chest',\n",
        " 'Spot up out of bullets so fly but couldnt do',\n",
        " 'Traffic behind some hood rat grease strikes you out of',\n",
        " 'But couldnt do nothing to him in some ninjas what',\n",
        " 'Behind some traffic behind some traffic behind some ninjas what',\n",
        " 'Game ninja im that big rap name ninja disrepectin my',\n",
        " 'Young ninja im that big rap name ninja disrepectin my',\n",
        " 'O whassup whassup  im that im that sit on',\n",
        " 'From the little homie hit that im that sit on',\n",
        " 'Millimeter for nuthin at all they hated on the dpg',\n",
        " 'Young ninja even dimes and all they hated on the',\n",
        " 'Oh once upon a b***** to him in town my',\n",
        " 'Big rap name ninja raps to him in town my',\n",
        " 'Us a ninja s-n double o-p fa sho i ran',\n",
        " 'Take a ninja s-n double o-p fa sho i ran',\n",
        " 'Tray get my thang way to stay on some hood',\n",
        " 'Because he ran up to danger aint poop the downlow',\n",
        " 'Town my thang way to the dpg and the air',\n",
        " 'Stay on the curl back and doves have a trip',\n",
        " 'Take a clip  yall get a ninja dip with',\n",
        " 'Jacks i came out ninjas was wearing slack i didnt',\n",
        " 'Lap  yall a time in the game like stainless',\n",
        " 'Shots on my ninja who brought the game like stainless',\n",
        " 'Rap name ninja disrepectin my set no get your back',\n",
        " 'His neck shooting like me lets go get your sack',\n",
        " 'Kids looked up in town my lighter  could you',\n",
        " 'Looked up in some hood rat grease strikes you out',\n",
        " 'Eatin on a muthafrickin vietnam vet riding on the downlow',\n",
        " 'Once upon a muthafrickin vietnam vet riding on the downlow',\n",
        " 'Jacks i brought the women stayed true to him because',\n",
        " 'His hands in his chest he tried to him because',\n",
        " 'Air his chest he ran up with his neck shooting',\n",
        " 'Lighter  yall a trip up in his neck shooting',\n",
        " 'Doves have you ever slapped a muthafrickin nine millimeter for',\n",
        " 'Fly but you better have a muthafrickin nine millimeter for',\n",
        " 'Stainless steel and jacks i had to him because he',\n",
        " 'Warning shots on this skandelous raps to him because he',\n",
        " 'Have a steak eatin on some traffic behind some ninjas',\n",
        " 'Stayed true to real i ran up in some ninjas',\n",
        " 'To mack your b***** aint poop the lbc in town',\n",
        " 'Warning shots on some traffic behind some hood gettin hot',\n",
        " 'Like stainless steel and snatch your back wishing for heater',\n",
        " 'Thugs cons drugs and pat your back wishing for heater',\n",
        " 'Slapped a og from the ride down out of g',\n",
        " 'Thang way cut throat on the ride down out of',\n",
        " 'Snatch your back  could you know i shot him',\n",
        " 'Some hood gettin blurry but you know i shot him',\n",
        " 'Hood gettin hot anybody can drop you know why but',\n",
        " 'Around and all even if we can drop you could',\n",
        " 'Skandelous raps the ride down my set no get a',\n",
        " 'Everything ninja dip with me lets go get a b*****',\n",
        " 'Story  im a muthafrickin nine millimeter for a kit',\n",
        " 'To do my ash tray get my set no warning',\n",
        " 'Real i shot him in the floor with em lets',\n",
        " 'Claiming everything ninja even if we cool with me lets',\n",
        " 'Brought snaps to him because he fell to him police',\n",
        " 'Sack and i shot him police tried to him police']\n",
        "\n",
        "classify_perc(markov_lyrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8025"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "tp0_Vb2DJZ2R",
        "outputId": "72d0c1ea-178a-4a92-e7f6-6a80e8fe1e52"
      },
      "source": [
        "# RNN\n",
        "RNN_lyrics = ['And i got to split ya',\n",
        "'Then i get witcha can i get witcha',\n",
        "'To all my queensbridge nixgas nixgas',\n",
        "'Im a bad bad boy',\n",
        "'When i was young in the gray uhhuh',\n",
        "'Also known as your cherry they been through the waist',\n",
        "'Now i dont know what they want from me',\n",
        "'You nasty boy you nasty',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'What you want nixga what you what you want nixga',\n",
        "'Lyin to pray for my downfall',\n",
        "'Yes i got a gun on you',\n",
        "'Get high get high get high',\n",
        "'Call me evil at my bridge',\n",
        "'But i dont care what nobody say',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'Smith you know what they want from me',\n",
        "'frickin sayin',\n",
        "'When i was young in the gray uhhuh',\n",
        "'Jazze you get to get the new d*ck,'\n",
        "'And i got to split ya',\n",
        "'It aint no one but i got a d*ck and puffed me',\n",
        "'And i got to split ya',\n",
        "'Thats the nixga size in these karl kani jeans',\n",
        "'Smoke a stone eggs and wednesdays',\n",
        "'Off the hands high like youse a true player',\n",
        "'Youre dead wrong',\n",
        "'A notorious big',\n",
        "'Biggie smalls the rap phenomenon',\n",
        "'Drunk by a daily crackin',\n",
        "'See i dont know what they want from me',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'Cause i get witcha can i get witcha',\n",
        "'But i dont care what nobody say',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'Keep on pressin on',\n",
        "'If you got a gun in your waist please dont shoot up the place',\n",
        "'Beef is when your moms is poppa',\n",
        "'Can i get witcha can i get witcha',\n",
        "'To all my queensbridge nixgas nixgas',\n",
        "'As i kiss your bum goodnight',\n",
        "'As i kiss your bum goodnight',\n",
        "'You nasty boy you nasty',\n",
        "'Squeeze your clip hit the right one pass that sandwhiches i got to light one',\n",
        "'Is the bad bad boy',\n",
        "'Stepped to police when i proceed',\n",
        "'Look at the streets to the phone to the door',\n",
        "'Televisions believable believable believable',\n",
        "'Verse the more money we come across',\n",
        "'And i got to split ya',\n",
        "'If you got a gun in your waist please dont shoot up the place',\n",
        "'All the ladies if you hear me',\n",
        "'What you want nixga what you what you want nixga',\n",
        "'All the ladies if you hear me',\n",
        "'Meshed on the bronx back to cali cali going back to cali',\n",
        "'When i was young in the gray uhhuh',\n",
        "'You nasty boy you nasty',\n",
        "'Sex is all i get witcha can i get witcha',\n",
        "'Matter of fact Im sick of blue',\n",
        "'Sixtynine code',\n",
        "'Ya aint no dough and squeeze and Im sniff me',\n",
        "'Jm motherfrickers',\n",
        "'Nobody gotta die',\n",
        "'To all my queensbridge nixgas nixgas',\n",
        "'Word to be over new york',\n",
        "'Im a bad bad boy',\n",
        "'My notorious big',\n",
        "'Michelle i dont get witcha can i get witcha',\n",
        "'You nasty boy you nasty',\n",
        "'One in the chamber the streets that',\n",
        "'And i got to split ya',\n",
        "'Rubberband d havin nightmares of a melon of frickin',\n",
        "'The weak or the strong who got it goin on',\n",
        "'Make the cherokee to the frick to the d*ck',\n",
        "'Time to be a worthless kid she damage and check it',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'All the ladies if you hear me',\n",
        "'frickin sayin',\n",
        "'Who rock around my d*ck than the waist please dont shoot to the thriller',\n",
        "'What you want nixga what you what you want nixga',\n",
        "'Its bone and biggie biggie',\n",
        "'Just bone and biggie biggie',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'Nixga please be cool but they know we go',\n",
        "'Sometimes your words just hypnotize me',\n",
        "'Beef is when your moms is poppa',\n",
        "'Im a bad bad boy',\n",
        "'To all my queensbridge nixgas nixgas',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'You nasty boy you nasty',\n",
        "'Smokin blunts in your passenger dream',\n",
        "'Way it to the frick to the d*ck',\n",
        "'Everything you be styling on you',\n",
        "'Pull the gstring in your bed',\n",
        "'Bought the cherokee to the crib unless they bonin',\n",
        "'Still tote a purpose on the bladder and gentlemen with these elevated world',\n",
        "'Only i get witcha can i get witcha',\n",
        "'Why you wanna get with me',\n",
        "'Gats and pray for my downfall',\n",
        "'Dont stop Im not finished yet',\n",
        "'Slugs missed ya',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'You nasty boy you nasty',\n",
        "'Before i get witcha can i get witcha',\n",
        "'Get high get high get high',\n",
        "'Gettin physical like olivia newt',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'Damagin i release the cherry they been through the floor',\n",
        "'Hah i got the funk flow to make your drawers drop slow',\n",
        "'Das the more problems we see i dont know what they want from me',\n",
        "'Nixgas aint got a gun up in your waist please dont shoot up the place',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'You nasty boy you nasty',\n",
        "'Guess thats why they broke and youre so paid uh biggie biggie uhhuh',\n",
        "'For the mac in the ac d*ck',\n",
        "'Cause i get witcha can i get witcha',\n",
        "'Im a bad bad boy',\n",
        "'Gimme the loot gimme the loot',\n",
        "'Id probably do real things',\n",
        "'Beef is when your moms is poppa',\n",
        "'Sky is the limit and you know that you can have',\n",
        "'Turn it to die with the wall to me',\n",
        "'It aint no one but i got a d*ck and puffed me',\n",
        "'Rip in the mac of the house of paradise',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'Even all my bronx nixgas nixgas',\n",
        "'Im a bad bad boy',\n",
        "'Im a bad bad boy',\n",
        "'Lunches bone and biggie biggie',\n",
        "'Why you wanna get with me',\n",
        "'For the mac in the ac d*ck',\n",
        "'We dont get witcha can i get witcha',\n",
        "'Buy the nixga chic we get witcha can i get witcha',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'Im a bad bad boy',\n",
        "'Dont stop Im not finished yet',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'At the mariott we go to give me what you need',\n",
        "'Nixga please be cool but they know we go',\n",
        "'And i got to split ya',\n",
        "'Goin somewhere let me to be in icu ya',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'Man i got my position and died',\n",
        "'When i was young in the gray uhhuh',\n",
        "'Slam larry johnson and your dogs love to die',\n",
        "'Seen the frick you got a d*ck with the waist please dont shoot up the place',\n",
        "'Ima know that p**sy many girl',\n",
        "'Bought the cherokee to the crib unless they bonin',\n",
        "'Just bone and biggie biggie',\n",
        "'It aint no one but i got a d*ck and puffed me',\n",
        "'And i got to split ya',\n",
        "'The weak or the strong who got it goin on',\n",
        "'Pussy crusher the game talk your poop grab your gat call your clicks',\n",
        "'That i killed the spot',\n",
        "'Im a bad bad boy',\n",
        "'Can i get witcha can i get witcha',\n",
        "'Sky is the limit and you know that you can have',\n",
        "'She know you used to me',\n",
        "'All the ladies if you hear me',\n",
        "'Far up in the caribbean white sand my lyrical shift',\n",
        "'They know what we mean',\n",
        "'Peeps to cop when i hit my ass',\n",
        "'Hit the gunshots poop',\n",
        "'But i dont care what nobody say',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'Them nixgaz do real things',\n",
        "'Whoever i kiss your bum goodnight',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'Nixgas aint got a gun up in your waist please dont shoot up the place',\n",
        "'Every blunts in your kitchen screamin eggs and tear',\n",
        "'The weak or the strong who got it goin on',\n",
        "'Bitches aint no mother wished they got to split',\n",
        "'Come on motherfrickers come on',\n",
        "'frick tae kwon do i get witcha can i get witcha',\n",
        "'So i dont wanna get witcha can i get witcha',\n",
        "'The weak or the strong who got it goin on',\n",
        "'Lookin on the ave Im a man girlfriend',\n",
        "'Whats goin on',\n",
        "'And i got to split ya',\n",
        "'Make the cherokee to the frick to the d*ck',\n",
        "'Gettin physical like olivia newt',\n",
        "'Whats goin on',\n",
        "'And i got to split ya',\n",
        "'Fulfillin dead wrong',\n",
        "'By the cherokee to the beds droptop',\n",
        "'Instead of a mac of the house of girls karl jeans',\n",
        "'Smokin blunts in your passenger dream',\n",
        "'Take the beatdown if i bust to the life',\n",
        "'Real nixgaz do real things',\n",
        "'Thug one',\n",
        "'No no notorious',\n",
        "'Sometimes your words just hypnotize me',\n",
        "'Make the cherokee to the frick to the d*ck',\n",
        "'Lean back lean back lean',\n",
        "'frick tae kwon do i get witcha can i get witcha',\n",
        "'Sky is the limit and you know that you can have',\n",
        "'And i got to split ya',\n",
        "'Im a bad bad boy',\n",
        "'Im a bad bad boy',\n",
        "'Shoulda sensamelia can i get witcha can i get witcha',\n",
        "'Apologies in fact Im sick of blue',\n",
        "'You nasty boy you nasty',\n",
        "'Can i get witcha can i get witcha',\n",
        "'And i got to split ya',\n",
        "'Im a bad bad boy',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'Whyall believable believable',\n",
        "'The weak or the strong who got it goin on',\n",
        "'Like i got to be a d*ck and t',\n",
        "'That i killed the spot',\n",
        "'Its bone and biggie biggie',\n",
        "'Think i kiss your bum goodnight',\n",
        "'Now i dont know what they want from me',\n",
        "'Mad dead wrong',\n",
        "'Whats goin on',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'Federal is when i was shot',\n",
        "'Sex is all i get witcha can i get witcha',\n",
        "'Squeeze your clip hit the right one pass that sandwhiches i got to light one',\n",
        "'Why you wanna get with me',\n",
        "'Sing on motherfrickers come on',\n",
        "'Aint no one and the gray uhhuh',\n",
        "'Breakin up out a bladder they touched up the grill',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'Find the hands in the air if youse a true player',\n",
        "'So i dont wanna get witcha can i get witcha',\n",
        "'Im a bad bad boy',\n",
        "'Jack the nixga but i got a d*ck and puffed me',\n",
        "'Yall aint no mother wished they got to split',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'See i dont know what they want from me',\n",
        "'frick tae kwon do i get witcha can i get witcha',\n",
        "'Pop in the chamber the streets and the phone',\n",
        "'Smiles is the drugs baby i got to split',\n",
        "'Thou larry johnson from the bridge three bricks',\n",
        "'Before i get witcha can i get witcha',\n",
        "'Sometimes your words just hypnotize me',\n",
        "'Spit your game talk your poop grab your gat call your clicks',\n",
        "'Whats goin on',\n",
        "'Years is about the block and Im sonning you know that i wont stop',\n",
        "'Meet the cherokee to the beds droptop',\n",
        "'Peep the funk flow really though',\n",
        "'Straight to cop a gun in the house',\n",
        "'The weak or the strong who got it goin on',\n",
        "'Keep on pressin on',\n",
        "'Get high get high get high',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'Nixgaz is the nixga but i got a d*ck and puffed me',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'Im a bad bad boy',\n",
        "'Why you wanna get with me',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'Sky is the limit and you know that you can have',\n",
        "'You nasty boy you nasty',\n",
        "'Let me to all my frick is the d*ck',\n",
        "'Smiles is the drugs baby i got to split',\n",
        "'Ten years',\n",
        "'Put the hands in the air if youse a true player',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'Just bone and biggie biggie',\n",
        "'Grab your titties for the funk ill die for the funk',\n",
        "'Bought the cherokee to the crib unless they bonin',\n",
        "'To all my queensbridge nixgas nixgas',\n",
        "'All the ladies if you hear me',\n",
        "'Mr passes turner she thinks she dont be a glock in my waist',\n",
        "'Hanging wit the b*****es is the song i sing',\n",
        "'If you got a gun in your waist please dont shoot up the place',\n",
        "'Uh i get witcha can i get witcha',\n",
        "'Long as i got my d*ck but we dont shoot to the door',\n",
        "'Representing the more problems we see i dont know what they want from me',\n",
        "'Bleed just like us',\n",
        "'Man i got my position and died',\n",
        "'To all my queensbridge nixgas nixgas',\n",
        "'Now i dont know what they want from me',\n",
        "'The weak or the strong who got it goin on',\n",
        "'Tell me why you wanna get with me',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'Im a bad bad boy',\n",
        "'Lets ride lets ride lets ride',\n",
        "'Lets ride lets ride lets ride',\n",
        "'Nixga please be cool but they know we go',\n",
        "'The weak or the strong who got it goin on',\n",
        "'The weak or the strong who got it goin on',\n",
        "'Steps just like us',\n",
        "'Its bone and biggie biggie',\n",
        "'The weak or the strong who got it goin on',\n",
        "'One in the chamber the streets that',\n",
        "'And i got to split ya',\n",
        "'Bite your hands in the air if youse a true player',\n",
        "'Stupid the strong who got my d*ck but t',\n",
        "'Man i got my position and died',\n",
        "'Swig the wrist buttercrunch',\n",
        "'Says me for the condom filler',\n",
        "'Moet yah Im awake man',\n",
        "'All the ladies if you hear me',\n",
        "'Pissy nixgaz go from the bridge',\n",
        "'Then i get witcha can i get witcha',\n",
        "'We dont get witcha can i get witcha',\n",
        "'Cristyle no no notorious',\n",
        "'Mcs rock around my d*ck but the e',\n",
        "'The weak or the strong who got it goin on',\n",
        "'Slugs missed ya',\n",
        "'Oh i dont wanna get witcha can i get witcha',\n",
        "'Ima know that p**sy many girl',\n",
        "'Whos the hands in the air if youse a true player',\n",
        "'All the ladies if you hear me',\n",
        "'Nia to the mac make the kidneys shift',\n",
        "'Drop the truck of new york',\n",
        "'Pimpin up in your caribbean but she was mackin and the hibby you was a lot',\n",
        "'Im a bad bad boy',\n",
        "'Shits groups and spending and left your world',\n",
        "'Fk to all my new nixgas nixgas',\n",
        "'Oe in the chamber the streets that',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'Sky is the limit and you know that you can have',\n",
        "'N the nixga is chocolate my shift',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'What you want nixga what you what you want nixga',\n",
        "'Willie d havin nightmares of girls',\n",
        "'For the mac in the ac d*ck',\n",
        "'Until i get witcha can i get witcha',\n",
        "'If you got a gun in your waist please dont shoot up the place',\n",
        "'Cause i get witcha can i get witcha',\n",
        "'It aint no one but i got a d*ck and puffed me',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'And i got to split ya',\n",
        "'Sky is the limit and you know that you can have',\n",
        "'Thought i was young in the gray uhhuh',\n",
        "'What you want nixga what you what you want nixga',\n",
        "'Nobody gotta die',\n",
        "'The weak or the strong who got it goin on',\n",
        "'Yall aint no mother wished they got to split',\n",
        "'In the cherokee to the beds droptop',\n",
        "'Im a bad bad boy',\n",
        "'Still tote a purpose on the bladder and gentlemen with these elevated world',\n",
        "'Thats the nixga size in these karl kani jeans',\n",
        "'Told me why you frick doin when i call me when i call me and the scrolls',\n",
        "'Its bone and biggie biggie',\n",
        "'She know you used to me',\n",
        "'If you got a gun in your waist please dont shoot up the place',\n",
        "'Tell me why you wanna get with me',\n",
        "'You nasty boy you nasty',\n",
        "'And i got to split ya',\n",
        "'Approach me to all my new nixgas',\n",
        "'Eatin passes turner dinin classes squeezing asses',\n",
        "'What you want nixga what you what you want nixga',\n",
        "'Oh i dont wanna get witcha can i get witcha',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'Free passes screamin aiy papi',\n",
        "'What you want nixga what you what you want nixga',\n",
        "'Frank d havin nightmares of a melon of girls',\n",
        "'Nixga please be cool but they know we go',\n",
        "'Sex is all i get witcha can i get witcha',\n",
        "'N the nixga is chocolate my shift',\n",
        "'Remember i kiss your bum goodnight',\n",
        "'The weak or the strong who got it goin on',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'In the cherokee to the beds droptop',\n",
        "'Throw your hands in the air if youse a true player',\n",
        "'Scream you know what you need to do',\n",
        "'Mc yah Im awake man',\n",
        "'Loungin at the truck up in your bridge',\n",
        "'Do you got a gun in your waist please dont shoot up the place',\n",
        "'When i was young in the gray uhhuh',\n",
        "'Just bone and biggie biggie',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'They know what we mean',\n",
        "'And i got to split ya',\n",
        "'Look at the streets to the phone to the door',\n",
        "'Givin in the club sippin moet in benjamins',\n",
        "'Cintamelia all you wannah do is touch ya',\n",
        "'You nasty boy you nasty',\n",
        "'Just bone and biggie biggie',\n",
        "'Throw your hands in the air if youse a true player',\n",
        "'Imma want to die for the paper',\n",
        "'Hit the gunshots poop',\n",
        "'To all my queensbridge nixgas nixgas',\n",
        "'And i got to split ya',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'While i just love your flashy ways',\n",
        "'Oh i dont wanna get witcha can i get witcha',\n",
        "'If you got a gun in your waist please dont shoot up the place',\n",
        "'Betcha biggie biggie',\n",
        "'Youll see youll see',\n",
        "'That i killed the spot',\n",
        "'I got the funk flow to make your drawers drop slow',\n",
        "'Man i got my position and died',\n",
        "'Bitches aint no mother wished they got to split',\n",
        "'We dont get witcha can i get witcha',\n",
        "'All the ladies if you hear me',\n",
        "'Bring the hands high in a air in your notorous',\n",
        "'The weak or the strong who got it goin on']\n",
        "\n",
        "classify_perc(RNN_lyrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-e3c240a6ea28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    398\u001b[0m 'The weak or the strong who got it goin on']\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m \u001b[0mclassify_perc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN_lyrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-76906550db3b>\u001b[0m in \u001b[0;36mclassify_perc\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'rock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'country'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rap'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcla\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rap'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-76906550db3b>\u001b[0m in \u001b[0;36mcla\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlyric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlyric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'rock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'country'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rap'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1606\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1608\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1097\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m   \u001b[0;34m\"\"\"Selects a data adapter than can handle a given x and y.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m   \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mALL_ADAPTER_CLS\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m   \u001b[0;34m\"\"\"Selects a data adapter than can handle a given x and y.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m   \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mALL_ADAPTER_CLS\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mcan_handle\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    610\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcan_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m     \u001b[0mhandles_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_list_of_scalars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m     \u001b[0mhandles_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_is_list_of_scalars\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m    621\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_list_of_scalars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_is_list_of_scalars\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m    621\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_list_of_scalars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJs6g9MVgIbc"
      },
      "source": [
        "# With error codes repeatedly showing I have had to do this manually and manipulate data so that each line contains exactly ten words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7k8y_2McUY-"
      },
      "source": [
        "def classify_str(input):\n",
        "  lyric = [str(input)]\n",
        "  seq = tk.texts_to_sequences(lyric)\n",
        "  pred = model.predict(seq)\n",
        "  labels = ['rock', 'country', 'pop', 'rap']\n",
        "  return labels[np.argmax(pred)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D8DT5Qvduy4",
        "outputId": "87a700c9-e506-4712-87c5-060dbd68c44c"
      },
      "source": [
        "full = ' '.join(RNN_lyrics)\n",
        "split = full.split()\n",
        "RNN_lyrics_ten = [split[i*10:(i+1)*10] for i in range(0,int(len(split)/int(10)))]\n",
        "RNN_ten = [' '.join(RNN_lyrics_ten[i]) for i in range(len(RNN_lyrics_ten))]\n",
        "len(RNN_ten)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "315"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vW8nSleafhB5",
        "outputId": "8a18dd8c-68ea-44f2-dd34-840c7f5fc847"
      },
      "source": [
        "qq = map(classify_str, RNN_ten)\n",
        "list(qq).count('rap')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "279"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV3Zbw4Jf2Nu",
        "outputId": "323dc650-27ea-4a68-9a39-ce93e8ed6701"
      },
      "source": [
        "279/315"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8857142857142857"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoVODfqBf8Iu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
