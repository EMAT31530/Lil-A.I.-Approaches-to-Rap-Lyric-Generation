{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MarkovSyllables3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsnsZh72-hH0"
      },
      "source": [
        "# Markov with Syllable Counter\n",
        "# Same rhyme ranker as MikesVersion1\n",
        "# Changelog: \n",
        "# - Lines should now be exactly the number of syllables specified (however, may still be slightly off due to Pyphen mistakes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQph78-g-hIE",
        "outputId": "2065bd13-a801-4d6d-f2ba-8bc217912478"
      },
      "source": [
        "#@title Import Statements\n",
        "!pip install PyGithub\n",
        "!pip install pyphen\n",
        "\n",
        "# Package Imports\n",
        "import random\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "from urllib.request import urlopen # The default requests package\n",
        "import requests # For making GitHub requests\n",
        "from pprint import pprint # For pretty printing\n",
        "from pathlib import Path # The Path class\n",
        "import pyphen\n",
        "\n",
        "# For the more advanced requests\n",
        "import base64\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"./PyGithub\");\n",
        "from github import Github\n",
        "from getpass import getpass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyGithub in /usr/local/lib/python3.6/dist-packages (1.54.1)\n",
            "Requirement already satisfied: pyjwt<2.0 in /usr/local/lib/python3.6/dist-packages (from PyGithub) (1.7.1)\n",
            "Requirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.6/dist-packages (from PyGithub) (2.23.0)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.6/dist-packages (from PyGithub) (1.2.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.14.0->PyGithub) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.14.0->PyGithub) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.14.0->PyGithub) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.14.0->PyGithub) (2020.12.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated->PyGithub) (1.12.1)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.6/dist-packages (0.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1mSpF18iij9",
        "outputId": "25a044eb-3795-41a6-a957-6faec5c6ac60"
      },
      "source": [
        "help(pyphen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on package pyphen:\n",
            "\n",
            "NAME\n",
            "    pyphen\n",
            "\n",
            "DESCRIPTION\n",
            "    Pyphen\n",
            "    ======\n",
            "    \n",
            "    Pure Python module to hyphenate text, inspired by Ruby's Text::Hyphen.\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "\n",
            "\n",
            "CLASSES\n",
            "    builtins.object\n",
            "        Pyphen\n",
            "    \n",
            "    class Pyphen(builtins.object)\n",
            "     |  Hyphenation class, with methods to hyphenate strings in various ways.\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __call__ = iterate(self, word)\n",
            "     |  \n",
            "     |  __init__(self, filename=None, lang=None, left=2, right=2, cache=True)\n",
            "     |      Create an hyphenation instance for given lang or filename.\n",
            "     |      \n",
            "     |      :param filename: filename of hyph_*.dic to read\n",
            "     |      :param lang: lang of the included dict to use if no filename is given\n",
            "     |      :param left: minimum number of characters of the first syllabe\n",
            "     |      :param right: minimum number of characters of the last syllabe\n",
            "     |      :param cache: if ``True``, use cached copy of the hyphenation patterns\n",
            "     |  \n",
            "     |  inserted(self, word, hyphen='-')\n",
            "     |      Get the word as a string with all the possible hyphens inserted.\n",
            "     |      \n",
            "     |      :param word: unicode string of the word to hyphenate\n",
            "     |      :param hyphen: unicode string used as hyphen character\n",
            "     |      \n",
            "     |      E.g. for the dutch word ``'lettergrepen'``, this method returns the\n",
            "     |      unicode string ``'let-ter-gre-pen'``. The hyphen string to use can be\n",
            "     |      given as the second parameter, that defaults to ``'-'``.\n",
            "     |  \n",
            "     |  iterate(self, word)\n",
            "     |      Iterate over all hyphenation possibilities, the longest first.\n",
            "     |      \n",
            "     |      :param word: unicode string of the word to hyphenate\n",
            "     |  \n",
            "     |  positions(self, word)\n",
            "     |      Get a list of positions where the word can be hyphenated.\n",
            "     |      \n",
            "     |      :param word: unicode string of the word to hyphenate\n",
            "     |      \n",
            "     |      See also ``HyphDict.positions``. The points that are too far to the\n",
            "     |      left or right are removed.\n",
            "     |  \n",
            "     |  wrap(self, word, width, hyphen='-')\n",
            "     |      Get the longest possible first part and the last part of a word.\n",
            "     |      \n",
            "     |      :param word: unicode string of the word to hyphenate\n",
            "     |      :param width: maximum length of the first part\n",
            "     |      :param hyphen: unicode string used as hyphen character\n",
            "     |      \n",
            "     |      The first part has the hyphen already attached.\n",
            "     |      \n",
            "     |      Returns ``None`` if there is no hyphenation point before ``width``, or\n",
            "     |      if the word could not be hyphenated.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors defined here:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables (if defined)\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object (if defined)\n",
            "\n",
            "FUNCTIONS\n",
            "    language_fallback(language)\n",
            "        Get a fallback language available in our dictionaries.\n",
            "        \n",
            "        http://www.unicode.org/reports/tr35/#Locale_Inheritance\n",
            "        \n",
            "        We use the normal truncation inheritance. This function needs aliases\n",
            "        including scripts for languages with multiple regions available.\n",
            "\n",
            "DATA\n",
            "    LANGUAGES = {'af': '/usr/local/lib/python3.6/dist-packages/pyphen/dict...\n",
            "    __all__ = ('Pyphen', 'LANGUAGES', 'language_fallback')\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.6/dist-packages/pyphen/__init__.py\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N624BVtBsmy"
      },
      "source": [
        "#@title Function Definitions\n",
        "# Recursively Import the Data (AUTOMATIC)\n",
        "\n",
        "def _decode_and_write(file__, path_):\n",
        "    data = file__.decoded_content\n",
        "    data = data.decode('utf-8')[1:]\n",
        "    with open(path_, 'w') as writefile:\n",
        "        writefile.write(data) \n",
        "    data = data.splitlines()\n",
        "    data_rows = []\n",
        "    for count, word in enumerate(data):\n",
        "        if count>0:\n",
        "            data_rows.append(word.split(','))\n",
        "    data = pd.DataFrame(data_rows)\n",
        "    data = data.to_numpy()\n",
        "    return data\n",
        "\n",
        "\n",
        "def import_github(path_name=\"AllLyrics.txt\"):\n",
        "    \"\"\"\n",
        "    Function for importing the github file\n",
        "    path_name: str\n",
        "    output: None\n",
        "    \"\"\"\n",
        "    g = Github(getpass(\"Enter your PAT key \")) # Enter your PAT Key.\n",
        "    username = \"MikeMNelhams\"\n",
        "    main_branch_bool = input(\"Main Branch: Yes or No? \")\n",
        "    yes_synonyms = [\"yes\", \"y\", \"yh\", \"1\", \"true\"]\n",
        "    if main_branch_bool.lower() in yes_synonyms: \n",
        "        branch = \"master\" \n",
        "    else: \n",
        "        branch = \"PROTOTYPE\"\n",
        "\n",
        "    user = g.get_user(username)\n",
        "    r_proj_clone = 0\n",
        "    for repo in g.get_user().get_repos():\n",
        "        if repo.name == \"ai-group-project-Team-JMJM\":\n",
        "            r_proj_clone = repo\n",
        "            break\n",
        "        # To see all the available attributes and methods\n",
        "        print(dir(repo))\n",
        "    if not r_proj_clone:\n",
        "        print(\"ai-group-project-Team-JMJM not found\")\n",
        "        sys.exit()\n",
        "    print(\"Importing Github cleaned text files...\")\n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/CLEAN\", ref=branch)\n",
        "    RAP_DATA = []\n",
        "    for file_ in contents:\n",
        "        path = file_.path\n",
        "        path = str(path) \n",
        "        # Only choose the .txt files\n",
        "        if path[-4:] == '.txt':\n",
        "            # Append the Lyrics\n",
        "            RAP_DATA.append(file_.decoded_content.decode(\"utf-8\")) \n",
        "    \n",
        "    temp_path = Path(path_name)\n",
        "    if temp_path.is_file(): \n",
        "        if os.stat(path_name).st_size == 0:\n",
        "            write_bool2 = True\n",
        "        else: \n",
        "            write_bool2 = False\n",
        "    else: \n",
        "        write_bool2 = True\n",
        "    \n",
        "    if write_bool2: \n",
        "        for lyric in RAP_DATA: \n",
        "            try:\n",
        "                with open(path_name, 'w') as writefile: \n",
        "                    writefile.write(lyric)\n",
        "            except: \n",
        "                print(\"Error, file moved/deleted during write\")\n",
        "        print(\"{} is now up to date!\".format(path_name))\n",
        "    else: \n",
        "        print(\"{} is already up to date!\".format(path_name))\n",
        "    \n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/Other\", ref=branch)\n",
        "    for counter, file_ in enumerate(contents):\n",
        "        path = file_.path\n",
        "        path = str(path) \n",
        "\n",
        "        title_start = path.find('Other')\n",
        "        title_len = path[title_start:].find('.')\n",
        "        path = path[title_start + 6:title_start + title_len + 4]\n",
        "\n",
        "        print(\"Writing file {} {}\".format(counter, path))\n",
        "        temp_path = Path(path)\n",
        "        if temp_path.is_file():\n",
        "            with open(path,'w'): pass # Cheeky way to clear the file if it exists\n",
        "        \n",
        "        # Split the long string into a list of lines, then split by words, then put into a csv, then to numpy array \n",
        "        data = file_.decoded_content\n",
        "        data = data.decode('utf-8')[1:]\n",
        "\n",
        "        with open(path, 'w') as writefile:\n",
        "            writefile.write(data) \n",
        "        print(\"All files now up to date!\")\n",
        "\n",
        "\n",
        "def update_github(write_bool=False, path_name=\"AllLyrics.txt\"):\n",
        "    \"\"\"\n",
        "    Function for updating the github file, by cleaning the lyrics, optional write to txt file. \n",
        "    write_bool: bool\n",
        "    path_name: str\n",
        "    output: None\n",
        "    \"\"\"\n",
        "    g = Github(getpass(\"Enter your PAT key \")) # Enter your PAT Key.\n",
        "    username = \"MikeMNelhams\"\n",
        "    main_branch_bool = input(\"Main Branch: Yes or No? \")\n",
        "    yes_synonyms = [\"yes\", \"y\", \"yh\", \"1\", \"true\"]\n",
        "    if main_branch_bool.lower() in yes_synonyms: \n",
        "        branch = \"master\" \n",
        "    else: \n",
        "        branch = \"PROTOTYPE\"\n",
        "\n",
        "    user = g.get_user(username)\n",
        "    r_proj_clone = 0\n",
        "    for repo in g.get_user().get_repos():\n",
        "        if repo.name == \"ai-group-project-Team-JMJM\":\n",
        "            r_proj_clone = repo\n",
        "            break\n",
        "        # To see all the available attributes and methods\n",
        "        print(dir(repo))\n",
        "    \n",
        "    if not r_proj_clone:\n",
        "        print(\"ai-group-project-Team-JMJM not found\")\n",
        "        sys.exit()\n",
        "\n",
        "    print(\"Importing editing csv files...\")\n",
        "\n",
        "    # Split the long string into a list of lines, then split by words, then put into a csv, then to numpy arr\n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/Other\", ref=branch)\n",
        "    for counter, file_ in enumerate(contents):\n",
        "        path = file_.path \n",
        "        path = str(path)\n",
        "        title_start = path.find('Other')\n",
        "        title_len = path[title_start:].find('.')\n",
        "        name = path[title_start + 6:title_start + title_len + 4]\n",
        "        print(\"Writing file {} {}\".format(counter, name))\n",
        "        if name.lower() == \"censors.csv\":\n",
        "            censors = _decode_and_write(file_, path)\n",
        "        elif name.lower() == \"capitals.csv\":\n",
        "            capitals = _decode_and_write(file_, path)\n",
        "        else: \n",
        "            _decode_and_write(file_, path)\n",
        "    print(\"All editing csv files are up to date!\")\n",
        "\n",
        "    print(\"Importing Github uncleaned text files...\")\n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/UNCLEAN\", ref=branch)\n",
        "\n",
        "    RAP_DATA = []\n",
        "    rap_lyric_names = []\n",
        "\n",
        "    for file_ in contents:\n",
        "        path = file_.path\n",
        "        path = str(path) \n",
        "        # Only choose the .txt files\n",
        "        if path[-4:] == '.txt':\n",
        "            # Append the name\n",
        "            title_start = path.find('UNCLEAN')\n",
        "            title_len = path[title_start:].find('.')\n",
        "            name = path[title_start + 8:title_start + title_len]\n",
        "            if name[-2:] == 'UC':\n",
        "                name = name[:-2]\n",
        "            rap_lyric_names.append(name) \n",
        "\n",
        "        # Append the Lyrics\n",
        "        RAP_DATA.append(file_.decoded_content.decode(\"utf-8\")) \n",
        "        \n",
        "    # Remove the \\ufeff at the beginning O(n)\n",
        "    for count, lyric in enumerate(RAP_DATA): \n",
        "        RAP_DATA[count] = lyric[1:]\n",
        "\n",
        "    # Censor the profanities O(n*m + n*m2) m > m2 xor m2 > m\n",
        "    for count in range(len(RAP_DATA)): \n",
        "        for i in range(len(censors[0:])):\n",
        "            RAP_DATA[count] = RAP_DATA[count].replace(str(censors[i, 0]), str(censors[i, 1]))\n",
        "        for i in range(len(capitals[0:])):\n",
        "            RAP_DATA[count] = RAP_DATA[count].replace(str(capitals[i, 0]), str(capitals[i, 1]))\n",
        "\n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/CLEAN\", ref=branch)\n",
        "    cleaned_names = []\n",
        "    for counter, file_ in enumerate(contents):\n",
        "        path = file_.path\n",
        "        path = str(path) \n",
        "        print(\"File {} \".format(counter + 1) + path)\n",
        "        # Only choose the .txt files\n",
        "        if path[-4:] == '.txt':\n",
        "            # Append the name\n",
        "            title_start = path.find('CLEAN')\n",
        "            title_len = path[title_start:].find('.')\n",
        "        name = path[title_start + 6:title_start + title_len]\n",
        "        if name[-2:] == 'CL':\n",
        "            name = name[:-2]\n",
        "        cleaned_names.append(name) \n",
        "\n",
        "    # ALL OF THE EDITING IS DONE IN THE 'PROTOTYPE BRANCH' to avoid overwriting import changes\n",
        "    # If the (now cleaned) rap_lyrics name is new (not in cleaned_names), then we want to create that as a new file \n",
        "    # If the (now cleaned) rap_lyrics name is NOT new (not in cleaned_names), then we want to update the file\n",
        "    # print(rap_lyric_names)\n",
        "    # print(cleaned_names)\n",
        "    print(\"Committing files to github...\")\n",
        "    for counter, new_name in enumerate(rap_lyric_names): \n",
        "        if new_name in cleaned_names: \n",
        "            duplicate = r_proj_clone.get_contents(\"RapLyrics/CLEAN/{}CL.txt\".format(new_name), ref=branch)\n",
        "            r_proj_clone.update_file(\"RapLyrics/CLEAN/{}CL.txt\".format(new_name), \"This was uploaded automatically via pipeline\", RAP_DATA[counter], duplicate.sha, branch=branch)\n",
        "        else:\n",
        "            r_proj_clone.create_file(\"RapLyrics/CLEAN/{}CL.txt\".format(new_name), \"This was uploaded automatically via pipeline\", RAP_DATA[counter], branch=branch)\n",
        "\n",
        "    if write_bool: \n",
        "        print(\"Writing text file to: {}\".format(path_name))\n",
        "        with open(path_name, 'w') as writefile:\n",
        "            for lyric in RAP_DATA:\n",
        "                writefile.write(lyric)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lyVu1J_Djjt",
        "outputId": "c2448440-4de5-45b3-cf7c-543ff6e0fca4"
      },
      "source": [
        "count = int(input(\"How many syllables per line? \"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "How many syllables per line? 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3WahREYjCV6"
      },
      "source": [
        "dic = pyphen.Pyphen(lang='en_EN') # set pyphen dictionary to English\r\n",
        "\r\n",
        "def generate_rap(Vocabulary):\r\n",
        "    start_line = line_generator(Vocabulary)\r\n",
        "    all_other_lines = [line_generator(Vocabulary) for i in range(999)]\r\n",
        "    rap = [start_line]\r\n",
        "    \r\n",
        "    for i in range (19):\r\n",
        "        next_line = next_line_stop_count(rap[len(rap) - 1], all_other_lines)\r\n",
        "        all_other_lines.remove(next_line)\r\n",
        "        rap.append(next_line)\r\n",
        "    return rap\r\n",
        "\r\n",
        "\r\n",
        "# Generate text\r\n",
        "def line_generator(Vocabulary):\r\n",
        "    index = 1\r\n",
        "    chain = {}\r\n",
        "    # count = 16 # https://colemizestudios.com/rap-lyrics-syllables/, apparently rappers usually use semiquavers\r\n",
        "    linecount = 0\r\n",
        "    n = 0\r\n",
        "    \r\n",
        "    for word in Vocabulary[index:]:\r\n",
        "        key = Vocabulary[index-1]\r\n",
        "        if key in chain:\r\n",
        "            chain[key].append(word)\r\n",
        "        else:\r\n",
        "            chain[key] = [word]\r\n",
        "        index += 1\r\n",
        "        \r\n",
        "    word1 = random.choice(list(chain.keys()))\r\n",
        "    line = word1.capitalize()\r\n",
        "    wordsyllables = dic.inserted(word1)\r\n",
        "    wordcount = len(wordsyllables.split('-'))\r\n",
        "    linecount += wordcount\r\n",
        "\r\n",
        "    while linecount < count:\r\n",
        "      n += 1\r\n",
        "      word2 = random.choice(chain[word1])\r\n",
        "      wordsyllables = dic.inserted(word2)\r\n",
        "      wordcount = len(wordsyllables.split('-'))\r\n",
        "      linecount += wordcount\r\n",
        "      # print(n)\r\n",
        "      if linecount > count: # don't include word if it makes line go over syllable count\r\n",
        "        linecount -= wordcount\r\n",
        "      else:\r\n",
        "        word1 = word2\r\n",
        "        line += ' ' + word2.lower()\r\n",
        "      if n > 99: # if not finding a word with right number of syllables, stop trying and print an error\r\n",
        "        line += ' ERROR FINDING CORRECT SYLLABLE WORD'\r\n",
        "        linecount = count\r\n",
        "    return line\r\n",
        "\r\n",
        "\r\n",
        "# Rhyme Functions\r\n",
        "def reverse_syllable_extract(text):\r\n",
        "    sy_form = []\r\n",
        "    characters = [char for char in text]\r\n",
        "    sylls = ['a', 'e', 'i', 'o', 'u']\r\n",
        "    for x in characters:\r\n",
        "        if x in sylls:\r\n",
        "            sy_form.append(x)\r\n",
        "    sy_form.reverse()\r\n",
        "    return sy_form\r\n",
        "\r\n",
        "\r\n",
        "def rev_syllable_stop_count(text1, text2):\r\n",
        "    count = True \r\n",
        "    i = 0\r\n",
        "    counter = 0\r\n",
        "    syll1 = reverse_syllable_extract(text1)\r\n",
        "    syll2 = reverse_syllable_extract(text2)\r\n",
        "    while count == True:\r\n",
        "        if i < min(len(syll1), len(syll2)) and syll1[i] == syll2[i]:\r\n",
        "            counter += 1\r\n",
        "            i += 1\r\n",
        "        else:\r\n",
        "            count = False\r\n",
        "    return counter\r\n",
        "\r\n",
        "\r\n",
        "def next_line_stop_count(start_line, lines):\r\n",
        "    sy_lines = []\r\n",
        "    for i in lines:\r\n",
        "        sy_lines.append(rev_syllable_stop_count(start_line, i))\r\n",
        "    choice = sy_lines[0]\r\n",
        "    count = 0\r\n",
        "    for i in range(len(sy_lines)):\r\n",
        "        if sy_lines[i] > choice:\r\n",
        "            choice = sy_lines[i]\r\n",
        "    return lines[sy_lines.index(choice)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5On3o1fS-hIG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4155c50c-b1ac-4e0a-aab2-b3407bca6705"
      },
      "source": [
        "# Import all of Mike's lyrics.\n",
        "import_github()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your PAT key ··········\n",
            "Main Branch: Yes or No? No\n",
            "Importing Github cleaned text files...\n",
            "AllLyrics.txt is already up to date!\n",
            "Writing file 0 capitals.csv\n",
            "All files now up to date!\n",
            "Writing file 1 censors.csv\n",
            "All files now up to date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWGUsctgpGVp"
      },
      "source": [
        "# Extract all of Mike's lyrics. \n",
        "Text = open(\"AllLyrics.txt\", \"r\").read()\n",
        "Vocabulary = ''.join([i for i in Text if not i.isdigit()]).replace(\"\\n\", \" \").split(' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0WbObRPyyIy",
        "outputId": "738bf0b6-f26d-48fa-8680-51df5f65eda0"
      },
      "source": [
        "for line in generate_rap(Vocabulary):\n",
        "    print(line)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shot at your clicks squeeze your gat call me and said frick without your bum while\n",
            "Collaboration yall know is he dont you rest of you quicker\n",
            "Discussing plans with the loot gimme one of your clicks squeeze your bum like\n",
            "Candles and pray for twenty gs flat sweetness where the gray uhhuh i get\n",
            "Bulletproof glass is fricking fight in his name brand em all you like\n",
            "Bacardi dark blue steel feel him slipping and aint had me you fricked\n",
            "Slightly blue land smoke blunts sparked finger lovin you make her cousin let\n",
            "Cheers to riches and pray and pops mixed up in the deal go through with they\n",
            "Deck cause one i knew what you swear they be scramblin gamblin up out like\n",
            "Long time before this motherfricker we need oxygen steadily countin them\n",
            "Eye baby burn when they weight on it you frick around i got fricked up like\n",
            "Brooklyn crew flippin over here for royalties and bruises blunts with the\n",
            "Chump you what they b***** is immaculate my life endin injuries\n",
            "Breathless pull your seats for a lot gonja sensamelia can bring your hearts in the\n",
            "Lavender and how im intrrupted by your words just be grabbing me\n",
            "Buyers jet fuel abusers sippin remy in your main thug but they painted\n",
            "Popo its bone and dimes i put bombs in order to the beat it get\n",
            "Smacked b*****es be kickin you seasoned picatti or be on the man after death give\n",
            "Individual small frame buck i know he was poppa i flow really missed\n",
            "Gates snatch initial name id probably go in here come on the pathfinder\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW9SRl8X-hIQ"
      },
      "source": [
        "# Now takes longer to load due to iterating through words until finding word with the right number of syllables"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
