{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-basic2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGMDajrg_Oa1"
      },
      "source": [
        "LSTM model architecture 2:\n",
        "\n",
        "First working model (previous one didn't produce lyrics correctly) with and Embedding layer, a Bidirectional LSTM layer, a dropout layers to avoid overfitting and a dense layer.\n",
        "\n",
        "\n",
        "\n",
        "Also includes function that outputs most used words in the Vocabulary.\n",
        "\n",
        "Has a basic lyric generator that can be improved. Maybe we can create a loss function which favours rhyme or look at creating bars line by line. The problem with this was bars ending in words like 'i' and 'the' as lines were getting cut short.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyEQkMNVxPS7",
        "outputId": "e06571cd-2653-476a-92ca-d30719f4894f"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import LSTM\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "#@title Import Statements`\n",
        "!pip install PyGithub\n",
        "\n",
        "# Package Imports\n",
        "import random\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "from urllib.request import urlopen # The default requests package\n",
        "import requests # For making GitHub requests\n",
        "from pprint import pprint # For pretty printing\n",
        "from pathlib import Path # The Path class\n",
        "\n",
        "# For the more advanced requests\n",
        "import base64\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"./PyGithub\");\n",
        "from github import Github\n",
        "from getpass import getpass\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyGithub in /usr/local/lib/python3.7/dist-packages (1.54.1)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.7/dist-packages (from PyGithub) (1.2.11)\n",
            "Requirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.7/dist-packages (from PyGithub) (2.23.0)\n",
            "Requirement already satisfied: pyjwt<2.0 in /usr/local/lib/python3.7/dist-packages (from PyGithub) (1.7.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated->PyGithub) (1.12.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.14.0->PyGithub) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.14.0->PyGithub) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.14.0->PyGithub) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.14.0->PyGithub) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HfS1LmNxiMp"
      },
      "source": [
        "#@title Function Definitions\n",
        "# Recursively Import the Data (AUTOMATIC)\n",
        "\n",
        "def _decode_and_write(file__, path_):\n",
        "    data = file__.decoded_content\n",
        "    data = data.decode('utf-8')[1:]\n",
        "    with open(path_, 'w') as writefile:\n",
        "        writefile.write(data) \n",
        "    data = data.splitlines()\n",
        "    data_rows = []\n",
        "    for count, word in enumerate(data):\n",
        "        if count>0:\n",
        "            data_rows.append(word.split(','))\n",
        "    data = pd.DataFrame(data_rows)\n",
        "    data = data.to_numpy()\n",
        "    return data\n",
        "\n",
        "\n",
        "def import_github(path_name=\"AllLyrics.txt\"):\n",
        "    \"\"\"\n",
        "    Function for importing the github file\n",
        "    path_name: str\n",
        "    output: None\n",
        "    \"\"\"\n",
        "    g = Github(getpass(\"Enter your PAT key \")) # Enter your PAT Key.\n",
        "    username = \"MikeMNelhams\"\n",
        "    main_branch_bool = input(\"Main Branch: Yes or No? \")\n",
        "    yes_synonyms = [\"yes\", \"y\", \"yh\", \"1\", \"true\"]\n",
        "    if main_branch_bool.lower() in yes_synonyms: \n",
        "        branch = \"master\" \n",
        "    else: \n",
        "        branch = \"PROTOTYPE\"\n",
        "\n",
        "    user = g.get_user(username)\n",
        "    r_proj_clone = 0\n",
        "    for repo in g.get_user().get_repos():\n",
        "        if repo.name == \"ai-group-project-Team-JMJM\":\n",
        "            r_proj_clone = repo\n",
        "            break\n",
        "        # To see all the available attributes and methods\n",
        "        print(dir(repo))\n",
        "    if not r_proj_clone:\n",
        "        print(\"ai-group-project-Team-JMJM not found\")\n",
        "        sys.exit()\n",
        "    print(\"Importing Github cleaned text files...\")\n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/CLEAN\", ref=branch)\n",
        "    RAP_DATA = []\n",
        "    for file_ in contents:\n",
        "        path = file_.path\n",
        "        path = str(path) \n",
        "        # Only choose the .txt files\n",
        "        if path[-4:] == '.txt':\n",
        "            # Append the Lyrics\n",
        "            RAP_DATA.append(file_.decoded_content.decode(\"utf-8\")) \n",
        "    \n",
        "    temp_path = Path(path_name)\n",
        "    if temp_path.is_file(): \n",
        "        if os.stat(path_name).st_size == 0:\n",
        "            write_bool2 = True\n",
        "        else: \n",
        "            write_bool2 = False\n",
        "    else: \n",
        "        write_bool2 = True\n",
        "    \n",
        "    if write_bool2: \n",
        "        for lyric in RAP_DATA: \n",
        "            try:\n",
        "                with open(path_name, 'w') as writefile: \n",
        "                    writefile.write(lyric)\n",
        "            except: \n",
        "                print(\"Error, file moved/deleted during write\")\n",
        "        print(\"{} is now up to date!\".format(path_name))\n",
        "    else: \n",
        "        print(\"{} is already up to date!\".format(path_name))\n",
        "    \n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/Other\", ref=branch)\n",
        "    for counter, file_ in enumerate(contents):\n",
        "        path = file_.path\n",
        "        path = str(path) \n",
        "\n",
        "        title_start = path.find('Other')\n",
        "        title_len = path[title_start:].find('.')\n",
        "        path = path[title_start + 6:title_start + title_len + 4]\n",
        "\n",
        "        print(\"Writing file {} {}\".format(counter, path))\n",
        "        temp_path = Path(path)\n",
        "        if temp_path.is_file():\n",
        "            with open(path,'w'): pass # Cheeky way to clear the file if it exists\n",
        "        \n",
        "        # Split the long string into a list of lines, then split by words, then put into a csv, then to numpy array \n",
        "        data = file_.decoded_content\n",
        "        data = data.decode('utf-8')[1:]\n",
        "\n",
        "        with open(path, 'w') as writefile:\n",
        "            writefile.write(data) \n",
        "        print(\"All files now up to date!\")\n",
        "\n",
        "\n",
        "def update_github(write_bool=False, path_name=\"AllLyrics.txt\"):\n",
        "    \"\"\"\n",
        "    Function for updating the github file, by cleaning the lyrics, optional write to txt file. \n",
        "    write_bool: bool\n",
        "    path_name: str\n",
        "    output: None\n",
        "    \"\"\"\n",
        "    g = Github(getpass(\"Enter your PAT key \")) # Enter your PAT Key.\n",
        "    username = \"MikeMNelhams\"\n",
        "    main_branch_bool = input(\"Main Branch: Yes or No? \")\n",
        "    yes_synonyms = [\"yes\", \"y\", \"yh\", \"1\", \"true\"]\n",
        "    if main_branch_bool.lower() in yes_synonyms: \n",
        "        branch = \"master\" \n",
        "    else: \n",
        "        branch = \"PROTOTYPE\"\n",
        "\n",
        "    user = g.get_user(username)\n",
        "    r_proj_clone = 0\n",
        "    for repo in g.get_user().get_repos():\n",
        "        if repo.name == \"ai-group-project-Team-JMJM\":\n",
        "            r_proj_clone = repo\n",
        "            break\n",
        "        # To see all the available attributes and methods\n",
        "        print(dir(repo))\n",
        "    \n",
        "    if not r_proj_clone:\n",
        "        print(\"ai-group-project-Team-JMJM not found\")\n",
        "        sys.exit()\n",
        "\n",
        "    print(\"Importing editing csv files...\")\n",
        "\n",
        "    # Split the long string into a list of lines, then split by words, then put into a csv, then to numpy arr\n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/Other\", ref=branch)\n",
        "    for counter, file_ in enumerate(contents):\n",
        "        path = file_.path \n",
        "        path = str(path)\n",
        "        title_start = path.find('Other')\n",
        "        title_len = path[title_start:].find('.')\n",
        "        name = path[title_start + 6:title_start + title_len + 4]\n",
        "        print(\"Writing file {} {}\".format(counter, name))\n",
        "        if name.lower() == \"censors.csv\":\n",
        "            censors = _decode_and_write(file_, path)\n",
        "        elif name.lower() == \"capitals.csv\":\n",
        "            capitals = _decode_and_write(file_, path)\n",
        "        else: \n",
        "            _decode_and_write(file_, path)\n",
        "    print(\"All editing csv files are up to date!\")\n",
        "\n",
        "    print(\"Importing Github uncleaned text files...\")\n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/UNCLEAN\", ref=branch)\n",
        "\n",
        "    RAP_DATA = []\n",
        "    rap_lyric_names = []\n",
        "\n",
        "    for file_ in contents:\n",
        "        path = file_.path\n",
        "        path = str(path) \n",
        "        # Only choose the .txt files\n",
        "        if path[-4:] == '.txt':\n",
        "            # Append the name\n",
        "            title_start = path.find('UNCLEAN')\n",
        "            title_len = path[title_start:].find('.')\n",
        "            name = path[title_start + 8:title_start + title_len]\n",
        "            if name[-2:] == 'UC':\n",
        "                name = name[:-2]\n",
        "            rap_lyric_names.append(name) \n",
        "\n",
        "        # Append the Lyrics\n",
        "        RAP_DATA.append(file_.decoded_content.decode(\"utf-8\")) \n",
        "        \n",
        "    # Remove the \\ufeff at the beginning O(n)\n",
        "    for count, lyric in enumerate(RAP_DATA): \n",
        "        RAP_DATA[count] = lyric[1:]\n",
        "\n",
        "    # Censor the profanities O(n*m + n*m2) m > m2 xor m2 > m\n",
        "    for count in range(len(RAP_DATA)): \n",
        "        for i in range(len(censors[0:])):\n",
        "            RAP_DATA[count] = RAP_DATA[count].replace(str(censors[i, 0]), str(censors[i, 1]))\n",
        "        for i in range(len(capitals[0:])):\n",
        "            RAP_DATA[count] = RAP_DATA[count].replace(str(capitals[i, 0]), str(capitals[i, 1]))\n",
        "\n",
        "    contents = r_proj_clone.get_contents(\"RapLyrics/CLEAN\", ref=branch)\n",
        "    cleaned_names = []\n",
        "    for counter, file_ in enumerate(contents):\n",
        "        path = file_.path\n",
        "        path = str(path) \n",
        "        print(\"File {} \".format(counter + 1) + path)\n",
        "        # Only choose the .txt files\n",
        "        if path[-4:] == '.txt':\n",
        "            # Append the name\n",
        "            title_start = path.find('CLEAN')\n",
        "            title_len = path[title_start:].find('.')\n",
        "        name = path[title_start + 6:title_start + title_len]\n",
        "        if name[-2:] == 'CL':\n",
        "            name = name[:-2]\n",
        "        cleaned_names.append(name) \n",
        "\n",
        "    # ALL OF THE EDITING IS DONE IN THE 'PROTOTYPE BRANCH' to avoid overwriting import changes\n",
        "    # If the (now cleaned) rap_lyrics name is new (not in cleaned_names), then we want to create that as a new file \n",
        "    # If the (now cleaned) rap_lyrics name is NOT new (not in cleaned_names), then we want to update the file\n",
        "    # print(rap_lyric_names)\n",
        "    # print(cleaned_names)\n",
        "    print(\"Commiting files to github...\")\n",
        "    for counter, new_name in enumerate(rap_lyric_names): \n",
        "        if new_name in cleaned_names: \n",
        "            duplicate = r_proj_clone.get_contents(\"RapLyrics/CLEAN/{}CL.txt\".format(new_name), ref=branch)\n",
        "            r_proj_clone.update_file(\"RapLyrics/CLEAN/{}CL.txt\".format(new_name), \"This was uploaded automatically via pipeline\", RAP_DATA[counter], duplicate.sha, branch=branch)\n",
        "        else:\n",
        "            r_proj_clone.create_file(\"RapLyrics/CLEAN/{}CL.txt\".format(new_name), \"This was uploaded automatically via pipeline\", RAP_DATA[counter], branch=branch)\n",
        "\n",
        "    if write_bool: \n",
        "        print(\"Writing text file to: {}\".format(path_name))\n",
        "        with open(path_name, 'w') as writefile:\n",
        "            for lyric in RAP_DATA:\n",
        "                writefile.write(lyric)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtfMMwOdxmt_",
        "outputId": "fa73eb84-047a-42d6-ed5f-81c100170575"
      },
      "source": [
        "# Import all of Mike's lyrics.\n",
        "import_github()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your PAT key ··········\n",
            "Main Branch: Yes or No? Yes\n",
            "Importing Github cleaned text files...\n",
            "AllLyrics.txt is already up to date!\n",
            "Writing file 0 capitals.csv\n",
            "All files now up to date!\n",
            "Writing file 1 censors.csv\n",
            "All files now up to date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VjURXnfxsKJ"
      },
      "source": [
        "Text = open(\"AllLyrics.txt\", \"r\").read()\n",
        "# turn text to lower case to reduce vocabulary\n",
        "Text = Text.lower()\n",
        "with open(\"AllLyrics.txt\", \"r\") as f:\n",
        "    content = f.readlines()\n",
        "# bars is a list containing each line in dataset in lowercase\n",
        "bars = [x.strip().lower() for x in content]\n",
        "stripped_bars = [word.split() for word in bars]\n",
        "# Vocabulary is a list of all words in the dataset\n",
        "Vocabulary = ''.join([i for i in Text if not i.isdigit()]).replace(\"\\n\",\" \").split(' ')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLpVvXPQ2rHL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "605fa31c-6da3-403c-f19a-a640b9f42c74"
      },
      "source": [
        "# The numbers of bars in our dataset, 5283\n",
        "no_of_bars = len(bars)\n",
        "print(no_of_bars)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5283\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIRyjmQeyaAG"
      },
      "source": [
        "# word_count is a function creating a list of words ranked in order of most used\n",
        "# could think about removing certain words to create more accurate raps as model won't learn well from words used very infrequently\n",
        "def word_count(lyrics):\n",
        "  a = {}\n",
        "  for word in Vocabulary:\n",
        "    if word in a:\n",
        "      a[word] += 1\n",
        "    else:\n",
        "      a[word] = 1\n",
        "  return a\n",
        "word_dict = word_count(Vocabulary)\n",
        "sort_dict = sorted(word_dict.items(), key = lambda x: x[1], reverse = True)\n",
        "# Top 20 words\n",
        "sort_dict1 = sort_dict[:40]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIweRLWJqfax"
      },
      "source": [
        "# Need to create dictionary listing the words in alphabetical order so we can assign unique integers to each word\n",
        "# Neural networks take in integers, not words\n",
        "words = sorted(list(set(Vocabulary)))\n",
        "# Create a dictionary whereby we can convert integers into words\n",
        "word_to_int = { words[i] : i for i in range(len(words))}\n",
        "# Need to reverse this at the end to reverse numbers back into words\n",
        "int_to_word = { i : words[i] for i in range(len(words))}"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzfKleYrygft"
      },
      "source": [
        "# create a function that converts bars into a sequence of unique integers\n",
        "def words_to_integers(bar, Vocabulary):\n",
        "  encode = []\n",
        "  # Need to strip bar into single list of words within bar\n",
        "  stripped_bar = [word.split() for word in bar]\n",
        "  for i in range(no_of_bars):\n",
        "    seq = []\n",
        "    seq.append([word_to_int[word] for word in stripped_bar[i]])\n",
        "    encode.append(seq)\n",
        "\n",
        "  encode = sum(encode, [])\n",
        "  return encode"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RHaklDv5tZN",
        "outputId": "e42665d8-517d-44c0-f350-5362322579ac"
      },
      "source": [
        "# Number of unique words in our dataset\n",
        "vocab_size = len(words) + 1\n",
        "print(vocab_size)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJs1kvSVAhZO"
      },
      "source": [
        "# Define a function that converts sentences into a sequence of corresponding integers\n",
        "def sentence_to_integer(bar):\n",
        "    stripped_bar = [word.split() for word in [bar]]\n",
        "    stripped_bar = sum(stripped_bar, [])\n",
        "    seq = []\n",
        "    seq.append([word_to_int[word] for word in stripped_bar])\n",
        "    seq = sum(seq, [])\n",
        "    return seq"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2Log92J2ZdU"
      },
      "source": [
        "# Want to convert bars into n-grams of increasing length\n",
        "# So we start with the first two words and create lists of increasing length after adding the next word\n",
        "sequences = []\n",
        "for line in bars:\n",
        "    token_list = sentence_to_integer(line)\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_seq = token_list[:i+1]\n",
        "        sequences.append(n_gram_seq)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABAKPmzErRT_",
        "outputId": "be2580c5-4d8b-4f66-875d-a5bcf88a3808"
      },
      "source": [
        "# We need to pad each line so that each line is of equal length for our model\n",
        "# Thus need to find max length of a bar so we can pad all bars to this length\n",
        "padding_length = max([len(line) for line in sequences])\n",
        "print(padding_length)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PV9FBI_EsEQ"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "sequences = np.array(pad_sequences(sequences, maxlen = padding_length, padding = 'pre'))\n",
        "# Remove last word from each line\n",
        "x_train = sequences[:,:-1]\n",
        "# Last word is used as the label\n",
        "y_train = sequences[:,-1]\n",
        "# one hot encode the the outputs \n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes = vocab_size)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWoLXV1Qr4E9",
        "outputId": "51e3934b-e8ba-4a52-f173-94051b13a42c"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout, Bidirectional\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 512, input_length = padding_length - 1))\n",
        "model.add(Bidirectional(LSTM(512)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(vocab_size, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 65, 512)           2593792   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 1024)              4198400   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5066)              5192650   \n",
            "=================================================================\n",
            "Total params: 11,984,842\n",
            "Trainable params: 11,984,842\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar4UNHRZtBrp",
        "outputId": "9d1963d2-a571-4a83-d6e2-fa91fa2c81c7"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs = 50, batch_size = 256)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "160/160 [==============================] - 30s 157ms/step - loss: 6.9229 - accuracy: 0.0433\n",
            "Epoch 2/50\n",
            "160/160 [==============================] - 25s 158ms/step - loss: 6.0348 - accuracy: 0.0800\n",
            "Epoch 3/50\n",
            "160/160 [==============================] - 25s 159ms/step - loss: 5.3762 - accuracy: 0.1439\n",
            "Epoch 4/50\n",
            "160/160 [==============================] - 25s 159ms/step - loss: 4.6989 - accuracy: 0.2138\n",
            "Epoch 5/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 4.1134 - accuracy: 0.2716\n",
            "Epoch 6/50\n",
            "160/160 [==============================] - 26s 161ms/step - loss: 3.5680 - accuracy: 0.3360\n",
            "Epoch 7/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 3.0611 - accuracy: 0.4120\n",
            "Epoch 8/50\n",
            "160/160 [==============================] - 26s 161ms/step - loss: 2.6243 - accuracy: 0.4808\n",
            "Epoch 9/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 2.3009 - accuracy: 0.5397\n",
            "Epoch 10/50\n",
            "160/160 [==============================] - 26s 161ms/step - loss: 1.9989 - accuracy: 0.5935\n",
            "Epoch 11/50\n",
            "160/160 [==============================] - 26s 161ms/step - loss: 1.7513 - accuracy: 0.6406\n",
            "Epoch 12/50\n",
            "160/160 [==============================] - 26s 161ms/step - loss: 1.5572 - accuracy: 0.6816\n",
            "Epoch 13/50\n",
            "160/160 [==============================] - 26s 161ms/step - loss: 1.4105 - accuracy: 0.7045\n",
            "Epoch 14/50\n",
            "160/160 [==============================] - 26s 161ms/step - loss: 1.2408 - accuracy: 0.7384\n",
            "Epoch 15/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 1.1293 - accuracy: 0.7607\n",
            "Epoch 16/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 1.0177 - accuracy: 0.7849\n",
            "Epoch 17/50\n",
            "160/160 [==============================] - 26s 161ms/step - loss: 0.9142 - accuracy: 0.8038\n",
            "Epoch 18/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.8487 - accuracy: 0.8200\n",
            "Epoch 19/50\n",
            "160/160 [==============================] - 26s 161ms/step - loss: 0.7932 - accuracy: 0.8274\n",
            "Epoch 20/50\n",
            "160/160 [==============================] - 26s 161ms/step - loss: 0.7513 - accuracy: 0.8379\n",
            "Epoch 21/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.7085 - accuracy: 0.8445\n",
            "Epoch 22/50\n",
            "160/160 [==============================] - 26s 161ms/step - loss: 0.6721 - accuracy: 0.8489\n",
            "Epoch 23/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.6486 - accuracy: 0.8541\n",
            "Epoch 24/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.6112 - accuracy: 0.8584\n",
            "Epoch 25/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.5941 - accuracy: 0.8623\n",
            "Epoch 26/50\n",
            "160/160 [==============================] - 26s 161ms/step - loss: 0.5625 - accuracy: 0.8657\n",
            "Epoch 27/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.5632 - accuracy: 0.8653\n",
            "Epoch 28/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.5503 - accuracy: 0.8658\n",
            "Epoch 29/50\n",
            "160/160 [==============================] - 26s 161ms/step - loss: 0.5237 - accuracy: 0.8702\n",
            "Epoch 30/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.5228 - accuracy: 0.8711\n",
            "Epoch 31/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.5148 - accuracy: 0.8708\n",
            "Epoch 32/50\n",
            "160/160 [==============================] - 26s 161ms/step - loss: 0.5038 - accuracy: 0.8716\n",
            "Epoch 33/50\n",
            "160/160 [==============================] - 26s 161ms/step - loss: 0.4860 - accuracy: 0.8754\n",
            "Epoch 34/50\n",
            "160/160 [==============================] - 26s 161ms/step - loss: 0.4860 - accuracy: 0.8749\n",
            "Epoch 35/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.4810 - accuracy: 0.8763\n",
            "Epoch 36/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.4899 - accuracy: 0.8717\n",
            "Epoch 37/50\n",
            "160/160 [==============================] - 26s 161ms/step - loss: 0.4846 - accuracy: 0.8733\n",
            "Epoch 38/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.4734 - accuracy: 0.8757\n",
            "Epoch 39/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.4622 - accuracy: 0.8776\n",
            "Epoch 40/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.4566 - accuracy: 0.8784\n",
            "Epoch 41/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.4591 - accuracy: 0.8779\n",
            "Epoch 42/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.4565 - accuracy: 0.8787\n",
            "Epoch 43/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.4568 - accuracy: 0.8770\n",
            "Epoch 44/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.4517 - accuracy: 0.8790\n",
            "Epoch 45/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.4582 - accuracy: 0.8760\n",
            "Epoch 46/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.4498 - accuracy: 0.8771\n",
            "Epoch 47/50\n",
            "160/160 [==============================] - 26s 159ms/step - loss: 0.4540 - accuracy: 0.8771\n",
            "Epoch 48/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.4498 - accuracy: 0.8790\n",
            "Epoch 49/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.4387 - accuracy: 0.8795\n",
            "Epoch 50/50\n",
            "160/160 [==============================] - 26s 160ms/step - loss: 0.4515 - accuracy: 0.8744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8VUqslB6kMO",
        "outputId": "1e38a94f-4c34-4aae-d848-107ebd29300a"
      },
      "source": [
        "model.save('/content/gdrive/MyDrive/lstm-basic2.1')\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/lstm-basic2.1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/lstm-basic2.1/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImBWp2JQtHYW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "c9e9f34f-0768-4ee9-e99f-33cfc262b583"
      },
      "source": [
        "# Plotting a loss curve to see if we need this many epochs\n",
        "# Looks to still be decreasing slowly\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBrQuS2jwU9F"
      },
      "source": [
        "new_model = tf.keras.models.load_model('/content/drive/MyDrive/lstm-basic2.1')\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO78Ex9O5lF_"
      },
      "source": [
        "\n",
        "# Create a function to generate 'next_words' number of words on top of the seeded bar\n",
        "def generateraplyrics():\n",
        "  seed_text  = random.choice(bars)\n",
        "  next_words = 100\n",
        "  token_list = sentence_to_integer(seed_text)\n",
        "  token_list = pad_sequences([token_list], maxlen = padding_length - 1, padding = 'pre')\n",
        "  predicted  = new_model.predict_classes(token_list, verbose = 0)\n",
        "  lyrics = int_to_word[predicted[0]]\n",
        "  for _ in range(next_words):\n",
        "      token_list = sentence_to_integer(lyrics)\n",
        "      token_list = pad_sequences([token_list], maxlen = padding_length - 1, padding = 'pre')\n",
        "      predicted  = new_model.predict_classes(token_list, verbose = 0)\n",
        "      lyrics += ' ' + int_to_word[predicted[0]]\n",
        "  return lyrics.capitalize()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsQYK-4RxjJB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "bb816081-f866-4d4e-b2c1-e46bbb882a5f"
      },
      "source": [
        "# Example of output with 100 words generated \n",
        "\n",
        "generateraplyrics()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'In the process i admit i tricked a little yeah yeah yeah yeah yeah yeah big be a question of my friend baby dont you know what you do i am i dont wanna live no mo as this is this motherfricker as me in a jackin and i aint know what you do i do a frickin abortion school aint a shame yo thats a frick with a butt of begin steelo now frick with the world steelo peopleeler steelo peopleeler steelo biggie biggie biggie cant you see uh uh yeah yeah yeah yeah yeah i baldhead steelo the steelo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv4PFZPT56Kh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
