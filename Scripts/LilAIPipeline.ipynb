{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LilAIPipeline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPoCdJS5vHYd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b488dca-10b6-42ae-94fc-22a5beae0d38"
      },
      "source": [
        "!pip install PyGithub\r\n",
        "\r\n",
        "# Package Imports\r\n",
        "import pandas as pd \r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt \r\n",
        "from urllib.request import urlopen # The default requests package\r\n",
        "import requests # For making GitHub requests\r\n",
        "from pprint import pprint # For pretty printing\r\n",
        "# from getpass import getpass # For keeping password typing a secret\r\n",
        "\r\n",
        "# For the more advanced requests\r\n",
        "import base64\r\n",
        "import os\r\n",
        "import sys\r\n",
        "sys.path.append(\"./PyGithub\");\r\n",
        "from github import Github\r\n",
        "from getpass import getpass"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyGithub in /usr/local/lib/python3.6/dist-packages (1.54)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.6/dist-packages (from PyGithub) (1.2.10)\n",
            "Requirement already satisfied: pyjwt in /usr/local/lib/python3.6/dist-packages (from PyGithub) (1.7.1)\n",
            "Requirement already satisfied: requests<2.25,>=2.14.0 in /usr/local/lib/python3.6/dist-packages (from PyGithub) (2.23.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated->PyGithub) (1.12.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<2.25,>=2.14.0->PyGithub) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<2.25,>=2.14.0->PyGithub) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<2.25,>=2.14.0->PyGithub) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<2.25,>=2.14.0->PyGithub) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwcqyUqc2Lk9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92b890ae-e208-429b-fbbc-c0e7f9677567"
      },
      "source": [
        "# Recursively Import the Data (AUTOMATIC)\r\n",
        "\r\n",
        "g = Github(getpass(\"Enter your PAT key\")) # Enter your PAT Key. A system which is so stupidly unsafe it's mindboggling\r\n",
        "\r\n",
        "user = g.get_user(username)\r\n",
        "for repo in g.get_user().get_repos():\r\n",
        "    if repo.name == \"ai-group-project-Team-JMJM\":\r\n",
        "      r_proj_clone = repo\r\n",
        "      break\r\n",
        "    # To see all the available attributes and methods\r\n",
        "    print(dir(repo))\r\n",
        "\r\n",
        "contents = repo.get_contents(\"RapLyrics/UNCLEAN\", ref='PROTOTYPE')\r\n",
        "\r\n",
        "RAP_DATA = []\r\n",
        "rap_lyric_names = []\r\n",
        "\r\n",
        "for file_ in contents:\r\n",
        "  path = file_.path\r\n",
        "  path = str(path) \r\n",
        "  # Only choose the .txt files\r\n",
        "  if path[-4:] == '.txt':\r\n",
        "    # Append the name\r\n",
        "    title_start = path_.find('UNCLEAN')\r\n",
        "    title_len = path[title_start:].find('.')\r\n",
        "    name = path[title_start + 8:title_start + title_len]\r\n",
        "    if name[-2:] == 'UC':\r\n",
        "      name = name[:-2]\r\n",
        "    rap_lyric_names.append(name) \r\n",
        "\r\n",
        "    # Append the Lyrics\r\n",
        "    RAP_DATA.append(file_.decoded_content.decode(\"utf-8\")) \r\n",
        "  elif path == 'RapLyrics/UNCLEAN/censors.csv':\r\n",
        "    censors = file_.decoded_content\r\n",
        "\r\n",
        "    # Split the long string into a list of lines, then split by words, then put into a csv, then to numpy arr\r\n",
        "    data = censors.decode('utf-8')[1:].splitlines()\r\n",
        "    data_rows = []\r\n",
        "    for count, word in enumerate(data):\r\n",
        "      if count>0:\r\n",
        "        data_rows.append(word.split(','))\r\n",
        "    censors = pd.DataFrame(data_rows)\r\n",
        "    censors = censors.to_numpy()\r\n",
        "    \r\n",
        "# Remove the \\ufeff at the beginning O(n)\r\n",
        "for count, lyric in enumerate(RAP_DATA): \r\n",
        "  RAP_DATA[count] = lyric[1:]\r\n",
        "\r\n",
        "# Censor the profanities O(n*m)\r\n",
        "for count in range(len(RAP_DATA)): \r\n",
        "  for i in range(len(censors[0:])):\r\n",
        "    RAP_DATA[count] = RAP_DATA[count].replace(str(censors[i, 0]), str(censors[i, 1]))\r\n",
        "\r\n",
        "contents = repo.get_contents(\"RapLyrics/CLEAN\", ref='PROTOTYPE')\r\n",
        "cleaned_names = []\r\n",
        "for file_ in contents:\r\n",
        "  path = file_.path\r\n",
        "  path = str(path) \r\n",
        "  print(path)\r\n",
        "  # Only choose the .txt files\r\n",
        "  if path[-4:] == '.txt':\r\n",
        "    # Append the name\r\n",
        "    title_start = path_.find('CLEAN')\r\n",
        "    title_len = path[title_start:].find('.')\r\n",
        "    name = path[title_start + 4:title_start + title_len]\r\n",
        "    if name[-2:] == 'CL':\r\n",
        "      name = name[:-2]\r\n",
        "    cleaned_names.append(name) \r\n",
        "\r\n",
        "# ALL OF THE EDITING IS DONE IN THE 'PROTOTYPE BRANCH'\r\n",
        "# If the (now cleaned) rap_lyrics name is new (not in cleaned_names), then we want to create that as a new file \r\n",
        "# If the (now cleaned) rap_lyrics name is NOT new (not in cleaned_names), then we want to update the file\r\n",
        "print(rap_lyric_names)\r\n",
        "print(cleaned_names)\r\n",
        "\r\n",
        "for counter, new_name in enumerate(rap_lyric_names): \r\n",
        "  if new_name in cleaned_names: \r\n",
        "    duplicate = repo.get_contents(\"RapLyrics/CLEAN/{}CL.txt\".format(new_name), ref='PROTOTYPE')\r\n",
        "    repo.update_file(\"RapLyrics/CLEAN/{}CL.txt\".format(new_name), \"This was uploaded automatically via pipeline\", RAP_DATA[counter], duplicate.sha, branch='PROTOTYPE')\r\n",
        "  else:\r\n",
        "    repo.create_file(\"RapLyrics/CLEAN/{}CL.txt\".format(new_name), \"This was uploaded automatically via pipeline\", RAP_DATA[counter], branch=\"PROTOTYPE\")"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RapLyrics/CLEAN/Kanye_WestCL.txt\n",
            "RapLyrics/CLEAN/Lil_WayneCL.txt\n",
            "['Kanye_West', 'Lil_Wayne', 'eminem', 'ludacris', 'nicki-minaj', 'notorious-big']\n",
            "['Kanye_West', 'Lil_Wayne']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3BgxNbWvR06"
      },
      "source": [
        "# Data Imports (MANUAL and requires publicising the project)\r\n",
        "URLS = ['https://raw.githubusercontent.com/EMAT31530/ai-group-project-Team-JMJM/master/RapLyrics/UNCLEAN/Kanye_WestUC.txt']\r\n",
        "censors = pd.read_csv(\"https://raw.githubusercontent.com/EMAT31530/ai-group-project-Team-JMJM/master/RapLyrics/UNCLEAN/censors.csv\").to_numpy()\r\n",
        "RAP_DATA = []\r\n",
        "rap_lyric_names = []\r\n",
        "for URL in URLS: \r\n",
        "  title_start = URL.find('UNCLEAN')\r\n",
        "  title_len = URL[title_start:].find('.')\r\n",
        "  rap_lyric_names.append(URL[title_start + 8:title_start + title_len])\r\n",
        "\r\n",
        "# Import all of the data through URLS O(n)\r\n",
        "for URL in URLS: \r\n",
        "  RAP_DATA.append(urlopen(URL).read().decode(\"utf-8\"))\r\n",
        "\r\n",
        "# Remove the \\ufeff at the beginning O(n)\r\n",
        "for count, lyric in enumerate(RAP_DATA): \r\n",
        "  RAP_DATA[count] = lyric[1:]\r\n",
        "\r\n",
        "# Censor the profanities O(n*m)\r\n",
        "for count, lyric in enumerate(RAP_DATA): \r\n",
        "  for i in range(len(censors[0:])):\r\n",
        "    RAP_DATA[count] = lyric.replace(censors[i, 0], censors[i, 1])\r\n",
        "\r\n",
        "print(RAP_DATA[0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}